{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "549a3d8c",
   "metadata": {},
   "source": [
    "# 0. Packages and Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7567ca2",
   "metadata": {},
   "source": [
    "## 0.1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "57bd2f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, pipeline, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pyarrow\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0aaaa2",
   "metadata": {},
   "source": [
    "## 0.2. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7ce24a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-process text for lexicon based approaches\n",
    "def preprocess_text(text):\n",
    "    # remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # convert to lower case\n",
    "    text = text.lower()\n",
    "    # remove blank spaces\n",
    "    text = ' '.join(text.split())\n",
    "    # remove newline characters\n",
    "    text = text.replace('\\n', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b22206e",
   "metadata": {},
   "source": [
    "### Absolute Count with Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "2495792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function that take the dataframe, lexicon and n-gram value (how many n-grams should be considered) and determine the \n",
    "#count of words in dataframe text that match the lexicon\n",
    "def count_lexicon_words_1(text_df, lexicon):\n",
    "    lexicon = lexicon[\"Lexicon\"]\n",
    "    count = []\n",
    "\n",
    "    for text in text_df[\"Text\"]:\n",
    "        lexicon_counts = 0\n",
    "\n",
    "        for word in lexicon:\n",
    "            lexicon_counts += text.lower().count(word.lower())\n",
    "            \n",
    "        count.append(lexicon_counts)\n",
    "        \n",
    "    text_df[\"Lexicon Count\"] = count\n",
    "    \n",
    "    return(text_df)\n",
    "\n",
    "#create a function that used the lexicon approach to determine with the target is yes or no\n",
    "def lexicon_target_classifier_1(df, treshold):\n",
    "    target = []\n",
    "    \n",
    "    count = df[\"Lexicon Count\"]\n",
    "    \n",
    "    for c in count:\n",
    "        if c < treshold:\n",
    "            target.append(\"No\")\n",
    "        else:\n",
    "            target.append(\"Yes\")\n",
    "            \n",
    "    df[\"Target Lexicon\"] = target\n",
    "    return(df)\n",
    "\n",
    "#Combine both functions to classify articles based on the lexicon\n",
    "def lexicon_climate_classifier_1(text_df, lexicon, treshold):\n",
    "    df = count_lexicon_words_1(text_df, lexicon)\n",
    "    \n",
    "    return(lexicon_target_classifier_1(df, treshold))\n",
    "\n",
    "def threshold_metrics_1(df_text, lexicon, min_treshhold, max_treshhold):\n",
    "    for i in range(min_treshhold, max_treshhold + 1):\n",
    "        df = lexicon_climate_classifier_1(df_text, lexicon, i)\n",
    "        cross_table = pd.crosstab(df['Target'], df['Target Lexicon'], margins=True)\n",
    "        \n",
    "        # calculate classification metrics using scikit-learn\n",
    "        accuracy = (cross_table.iloc[0, 0] + cross_table.iloc[1, 1]) / cross_table.loc['All', 'All'] if cross_table.shape == (3,3) else cross_table.iloc[1,0] / (cross_table.iloc[1, 0] + cross_table.iloc[0,0]) \n",
    "        precision = cross_table.iloc[1,1] / (cross_table.iloc[0,1] + cross_table.iloc[1,1]) if cross_table.shape == (3,3) else 0\n",
    "        recall = cross_table.iloc[1,1] / (cross_table.iloc[1,0] + cross_table.iloc[1,1]) if cross_table.shape == (3,3) != 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "        # print the metrics\n",
    "        print(\"Threshhold:\", i)\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall:\", recall)\n",
    "        print(\"F1 score:\", f1_score)\n",
    "        print(cross_table)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "def get_metrics_df_1(df_text, lexicon, min_treshhold, max_treshhold, Lexicon_name):    \n",
    "    Accuracy = []\n",
    "    Precision = []\n",
    "    Recall = []\n",
    "    F1_score = []\n",
    "    Name = []\n",
    "    Treshhold = []\n",
    "    Technique = []\n",
    "    \n",
    "    for i in range(min_treshhold, max_treshhold + 1):\n",
    "        df = lexicon_climate_classifier_1(df_text, lexicon, i)\n",
    "        cross_table = pd.crosstab(df['Target'], df['Target Lexicon'], margins=True)\n",
    "\n",
    "        # calculate classification metrics using scikit-learn\n",
    "        accuracy = (cross_table.iloc[0, 0] + cross_table.iloc[1, 1]) / cross_table.loc['All', 'All'] if cross_table.shape == (3,3) else cross_table.iloc[1,0] / (cross_table.iloc[1, 0] + cross_table.iloc[0,0]) \n",
    "        precision = cross_table.iloc[1,1] / (cross_table.iloc[0,1] + cross_table.iloc[1,1]) if cross_table.shape == (3,3) else 0\n",
    "        recall = cross_table.iloc[1,1] / (cross_table.iloc[1,0] + cross_table.iloc[1,1]) if cross_table.shape == (3,3) != 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "        Accuracy.append(accuracy)\n",
    "        Precision.append(precision)\n",
    "        Recall.append(recall)\n",
    "        F1_score.append(f1_score)\n",
    "        Name.append(Lexicon_name)\n",
    "        Treshhold.append(i)\n",
    "        Technique.append(\"Absolute Frequency\")\n",
    "        \n",
    "    return(pd.DataFrame({\"Lexicon\" : Name, \"Technique\": Technique, \"Treshhold\" : Treshhold, \"Accuracy\" : Accuracy, \"Precision\" : Precision, \"Recall\" : Recall, \"F1 Score\" : F1_score}))\n",
    "    \n",
    "\n",
    "def get_nsmh_crosstab_1(df_text, lexicon, min_treshhold, max_treshhold):\n",
    "    for i in range(min_treshhold, max_treshhold + 1):\n",
    "        df = lexicon_climate_classifier_1(df_text, lexicon, i)\n",
    "        cross_table = pd.crosstab(df['Final_Climate_Change_Level_Label'], df['Target Lexicon'], margins=True)\n",
    "        print(cross_table)\n",
    "        print(\"\\n\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c69c28",
   "metadata": {},
   "source": [
    "### Relative Count with Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "9c3ca9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function that take the dataframe, lexicon and n-gram value (how many n-grams should be considered) and determine the \n",
    "#count of words in dataframe text that match the lexicon\n",
    "def count_lexicon_words_2(text_df, lexicon):\n",
    "    lexicon = lexicon[\"Lexicon\"]\n",
    "    count = []\n",
    "    \n",
    "    for text in text_df[\"Text\"]:\n",
    "        lexicon_counts = 0\n",
    "\n",
    "        for word in lexicon:\n",
    "            lexicon_counts += text.lower().count(word.lower())\n",
    "        \n",
    "        word_list = text.split() \n",
    "        word_count = len(word_list)\n",
    "        count.append((lexicon_counts/word_count)*100)\n",
    "\n",
    "    text_df[\"Lexicon Count\"] = count\n",
    "    \n",
    "    return(text_df)\n",
    "\n",
    "#create a function that used the lexicon approach to determine with the target is yes or no\n",
    "def lexicon_target_classifier_2(df, treshold):\n",
    "    target = []\n",
    "    \n",
    "    count = df[\"Lexicon Count\"]\n",
    "    \n",
    "    for c in count:\n",
    "        if c < treshold:\n",
    "            target.append(\"No\")\n",
    "        else:\n",
    "            target.append(\"Yes\")\n",
    "            \n",
    "    df[\"Target Lexicon\"] = target\n",
    "    return(df)\n",
    "\n",
    "#Combine both functions to classify articles based on the lexicon\n",
    "def lexicon_climate_classifier_2(text_df, lexicon, treshold):\n",
    "    df = count_lexicon_words_2(text_df, lexicon)\n",
    "    \n",
    "    return(lexicon_target_classifier_2(df, treshold))\n",
    "\n",
    "def threshold_metrics_2(df_text, lexicon, min_treshhold, max_treshhold, jump):\n",
    "    \n",
    "    if(jump == 0):\n",
    "        df = lexicon_climate_classifier_2(df_text, lexicon, min_treshhold)\n",
    "        cross_table = pd.crosstab(df['Target'], df['Target Lexicon'], margins=True)\n",
    "\n",
    "        # calculate classification metrics using scikit-learn\n",
    "        accuracy = (cross_table.iloc[0, 0] + cross_table.iloc[1, 1]) / cross_table.loc['All', 'All'] if cross_table.shape == (3,3) else cross_table.iloc[1,0] / (cross_table.iloc[1, 0] + cross_table.iloc[0,0]) \n",
    "        precision = cross_table.iloc[1,1] / (cross_table.iloc[0,1] + cross_table.iloc[1,1]) if cross_table.shape == (3,3) else 0\n",
    "        recall = cross_table.iloc[1,1] / (cross_table.iloc[1,0] + cross_table.iloc[1,1]) if cross_table.shape == (3,3) != 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "        # print the metrics\n",
    "        print(\"Threshhold:\", min_treshhold)\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall:\", recall)\n",
    "        print(\"F1 score:\", f1_score)\n",
    "        print(cross_table)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    else:   \n",
    "        for num in range(int((max_treshhold - min_treshhold) / jump) + 1):\n",
    "            i = min_treshhold + num * jump\n",
    "            df = lexicon_climate_classifier_2(df_text, lexicon, i)\n",
    "            cross_table = pd.crosstab(df['Target'], df['Target Lexicon'], margins=True)\n",
    "\n",
    "            # calculate classification metrics using scikit-learn\n",
    "            accuracy = (cross_table.iloc[0, 0] + cross_table.iloc[1, 1]) / cross_table.loc['All', 'All'] if cross_table.shape == (3,3) else cross_table.iloc[1,0] / (cross_table.iloc[1, 0] + cross_table.iloc[0,0]) \n",
    "            precision = cross_table.iloc[1,1] / (cross_table.iloc[0,1] + cross_table.iloc[1,1]) if cross_table.shape == (3,3) else 0\n",
    "            recall = cross_table.iloc[1,1] / (cross_table.iloc[1,0] + cross_table.iloc[1,1]) if cross_table.shape == (3,3) != 0 else 0\n",
    "            f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "            # print the metrics\n",
    "            print(\"Threshhold:\", i)\n",
    "            print(\"Accuracy:\", accuracy)\n",
    "            print(\"Precision:\", precision)\n",
    "            print(\"Recall:\", recall)\n",
    "            print(\"F1 score:\", f1_score)\n",
    "            print(cross_table)\n",
    "            print(\"\\n\")\n",
    "\n",
    "def get_metrics_df_2(df_text, lexicon, min_treshhold, max_treshhold, jump, Lexicon_name):    \n",
    "    Accuracy = []\n",
    "    Precision = []\n",
    "    Recall = []\n",
    "    F1_score = []\n",
    "    Name = []\n",
    "    Treshhold = []\n",
    "    Technique = []\n",
    "    \n",
    "    for num in range(int((max_treshhold - min_treshhold) / jump) + 1):\n",
    "        i = min_treshhold + num * jump\n",
    "        df = lexicon_climate_classifier_2(df_text, lexicon, i)\n",
    "        cross_table = pd.crosstab(df['Target'], df['Target Lexicon'], margins=True)\n",
    "\n",
    "        # calculate classification metrics using scikit-learn\n",
    "        accuracy = (cross_table.iloc[0, 0] + cross_table.iloc[1, 1]) / cross_table.loc['All', 'All'] if cross_table.shape == (3,3) else cross_table.iloc[1,0] / (cross_table.iloc[1, 0] + cross_table.iloc[0,0]) \n",
    "        precision = cross_table.iloc[1,1] / (cross_table.iloc[0,1] + cross_table.iloc[1,1]) if cross_table.shape == (3,3) else 0\n",
    "        recall = cross_table.iloc[1,1] / (cross_table.iloc[1,0] + cross_table.iloc[1,1]) if cross_table.shape == (3,3) != 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "        \n",
    "        Accuracy.append(accuracy)\n",
    "        Precision.append(precision)\n",
    "        Recall.append(recall)\n",
    "        F1_score.append(f1_score)\n",
    "        Name.append(Lexicon_name)\n",
    "        Treshhold.append(i)\n",
    "        Technique.append(\"Relative Frequency\")\n",
    "        \n",
    "    return(pd.DataFrame({\"Lexicon\" : Name, \"Technique\": Technique, \"Treshhold\" : Treshhold, \"Accuracy\" : Accuracy, \"Precision\" : Precision, \"Recall\" : Recall, \"F1 Score\" : F1_score}))\n",
    "\n",
    "def get_nsmh_crosstab_2(df_text, lexicon, min_treshhold, max_treshhold, jump):\n",
    "    if(jump == 0):\n",
    "        df = lexicon_climate_classifier_2(df_text, lexicon, min_treshhold)\n",
    "        cross_table = pd.crosstab(df['Final_Climate_Change_Level_Label'], df['Target Lexicon'], margins=True)\n",
    "        print(cross_table)\n",
    "    else:   \n",
    "        for num in range(int((max_treshhold - min_treshhold) / jump) + 1):\n",
    "            i = min_treshhold + num * jump\n",
    "            df = lexicon_climate_classifier_2(df_text, lexicon, i)\n",
    "            cross_table = pd.crosstab(df['Final_Climate_Change_Level_Label'], df['Target Lexicon'], margins=True)\n",
    "            print(cross_table)\n",
    "            print(\"\\n\")\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f4d81d",
   "metadata": {},
   "source": [
    "### Absolute Term Presences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6226be1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function that take the dataframe, lexicon and n-gram value (how many n-grams should be considered) and determine the \n",
    "#count of words in dataframe text that match the lexicon\n",
    "def count_lexicon_words_3(text_df, lexicon):\n",
    "    lexicon = lexicon[\"Lexicon\"]\n",
    "    count = []\n",
    "\n",
    "    for text in text_df[\"Text\"]:\n",
    "        lexicon_counts = 0\n",
    "\n",
    "        for word in lexicon:\n",
    "            if text.lower().count(word.lower()) > 0:\n",
    "                lexicon_counts += 1\n",
    "        \n",
    "        count.append(lexicon_counts)\n",
    "        \n",
    "    text_df[\"Lexicon Count\"] = count\n",
    "    \n",
    "    return text_df\n",
    "\n",
    "#create a function that used the lexicon approach to determine with the target is yes or no\n",
    "def lexicon_target_classifier_3(df, treshold):\n",
    "    target = []\n",
    "    \n",
    "    count = df[\"Lexicon Count\"]\n",
    "    \n",
    "    for c in count:\n",
    "        if c < treshold:\n",
    "            target.append(\"No\")\n",
    "        else:\n",
    "            target.append(\"Yes\")\n",
    "            \n",
    "    df[\"Target Lexicon\"] = target\n",
    "    return(df)\n",
    "\n",
    "#Combine both functions to classify articles based on the lexicon\n",
    "def lexicon_climate_classifier_3(text_df, lexicon, treshold):\n",
    "    df = count_lexicon_words_3(text_df, lexicon)\n",
    "    \n",
    "    return(lexicon_target_classifier_3(df, treshold))\n",
    "\n",
    "def threshold_metrics_3(df_text, lexicon, min_treshhold, max_treshhold):\n",
    "    for i in range(min_treshhold, max_treshhold + 1):\n",
    "        df = lexicon_climate_classifier_3(df_text, lexicon, i)\n",
    "        cross_table = pd.crosstab(df['Target'], df['Target Lexicon'], margins=True)\n",
    "        \n",
    "        # calculate classification metrics using scikit-learn\n",
    "        accuracy = (cross_table.iloc[0, 0] + cross_table.iloc[1, 1]) / cross_table.loc['All', 'All'] if cross_table.shape == (3,3) else cross_table.iloc[1,0] / (cross_table.iloc[1, 0] + cross_table.iloc[0,0]) \n",
    "        precision = cross_table.iloc[1,1] / (cross_table.iloc[0,1] + cross_table.iloc[1,1]) if cross_table.shape == (3,3) else 0\n",
    "        recall = cross_table.iloc[1,1] / (cross_table.iloc[1,0] + cross_table.iloc[1,1]) if cross_table.shape == (3,3) != 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "        # print the metrics\n",
    "        print(\"Threshhold:\", i)\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall:\", recall)\n",
    "        print(\"F1 score:\", f1_score)\n",
    "        print(cross_table)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "def get_metrics_df_3(df_text, lexicon, min_treshhold, max_treshhold, Lexicon_name):    \n",
    "    Accuracy = []\n",
    "    Precision = []\n",
    "    Recall = []\n",
    "    F1_score = []\n",
    "    Name = []\n",
    "    Treshhold = []\n",
    "    Technique = []\n",
    "    \n",
    "    for i in range(min_treshhold, max_treshhold + 1):\n",
    "        df = lexicon_climate_classifier_3(df_text, lexicon, i)\n",
    "        cross_table = pd.crosstab(df['Target'], df['Target Lexicon'], margins=True)\n",
    "\n",
    "        # calculate classification metrics using scikit-learn\n",
    "        accuracy = (cross_table.iloc[0, 0] + cross_table.iloc[1, 1]) / cross_table.loc['All', 'All'] if cross_table.shape == (3,3) else cross_table.iloc[1,0] / (cross_table.iloc[1, 0] + cross_table.iloc[0,0]) \n",
    "        precision = cross_table.iloc[1,1] / (cross_table.iloc[0,1] + cross_table.iloc[1,1]) if cross_table.shape == (3,3) else 0\n",
    "        recall = cross_table.iloc[1,1] / (cross_table.iloc[1,0] + cross_table.iloc[1,1]) if cross_table.shape == (3,3) != 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "        Accuracy.append(accuracy)\n",
    "        Precision.append(precision)\n",
    "        Recall.append(recall)\n",
    "        F1_score.append(f1_score)\n",
    "        Name.append(Lexicon_name)\n",
    "        Treshhold.append(i)\n",
    "        Technique.append(\"Absolute Presences\")\n",
    "        \n",
    "    return(pd.DataFrame({\"Lexicon\" : Name, \"Technique\": Technique, \"Treshhold\" : Treshhold, \"Accuracy\" : Accuracy, \"Precision\" : Precision, \"Recall\" : Recall, \"F1 Score\" : F1_score}))\n",
    "    \n",
    "def get_nsmh_crosstab_2(df_text, lexicon, min_treshhold, max_treshhold):\n",
    "    for i in range(min_treshhold, max_treshhold + 1):\n",
    "        df = lexicon_climate_classifier_2(df_text, lexicon, i)\n",
    "        cross_table = pd.crosstab(df['Final_Climate_Change_Level_Label'], df['Target Lexicon'], margins=True)\n",
    "        print(cross_table)\n",
    "        print(\"\\n\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dd8d36",
   "metadata": {},
   "source": [
    "### Relative Term Presences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2f82d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function that take the dataframe, lexicon and n-gram value (how many n-grams should be considered) and determine the \n",
    "#count of words in dataframe text that match the lexicon\n",
    "def count_lexicon_words_4(text_df, lexicon):\n",
    "    lexicon = lexicon[\"Lexicon\"]\n",
    "    count = []\n",
    "\n",
    "    for text in text_df[\"Text\"]:\n",
    "        lexicon_counts = 0\n",
    "\n",
    "        for word in lexicon:\n",
    "            if text.lower().count(word.lower()) > 0:\n",
    "                lexicon_counts += 1\n",
    "        \n",
    "        word_list = text.split() \n",
    "        word_count = len(word_list)\n",
    "        count.append((lexicon_counts/word_count)*100)\n",
    "        \n",
    "    text_df[\"Lexicon Count\"] = count\n",
    "    \n",
    "    return text_df\n",
    "\n",
    "#create a function that used the lexicon approach to determine with the target is yes or no\n",
    "def lexicon_target_classifier_4(df, treshold):\n",
    "    target = []\n",
    "    \n",
    "    count = df[\"Lexicon Count\"]\n",
    "    \n",
    "    for c in count:\n",
    "        if c < treshold:\n",
    "            target.append(\"No\")\n",
    "        else:\n",
    "            target.append(\"Yes\")\n",
    "            \n",
    "    df[\"Target Lexicon\"] = target\n",
    "    return(df)\n",
    "\n",
    "#Combine both functions to classify articles based on the lexicon\n",
    "def lexicon_climate_classifier_4(text_df, lexicon, treshold):\n",
    "    df = count_lexicon_words_4(text_df, lexicon)\n",
    "    \n",
    "    return(lexicon_target_classifier_4(df, treshold))\n",
    "\n",
    "def threshold_metrics_4(df_text, lexicon, min_treshhold, max_treshhold, jump):\n",
    "    \n",
    "    if(jump == 0):\n",
    "        df = lexicon_climate_classifier_4(df_text, lexicon, min_treshhold)\n",
    "        cross_table = pd.crosstab(df['Target'], df['Target Lexicon'], margins=True)\n",
    "\n",
    "        # calculate classification metrics using scikit-learn\n",
    "        accuracy = (cross_table.iloc[0, 0] + cross_table.iloc[1, 1]) / cross_table.loc['All', 'All'] if cross_table.shape == (3,3) else cross_table.iloc[1,0] / (cross_table.iloc[1, 0] + cross_table.iloc[0,0]) \n",
    "        precision = cross_table.iloc[1,1] / (cross_table.iloc[0,1] + cross_table.iloc[1,1]) if cross_table.shape == (3,3) else 0\n",
    "        recall = cross_table.iloc[1,1] / (cross_table.iloc[1,0] + cross_table.iloc[1,1]) if cross_table.shape == (3,3) != 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "        # print the metrics\n",
    "        print(\"Threshhold:\", i)\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall:\", recall)\n",
    "        print(\"F1 score:\", f1_score)\n",
    "        print(cross_table)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    else:\n",
    "        for num in range(int((max_treshhold - min_treshhold) / jump) + 1):\n",
    "            i = min_treshhold + num * jump\n",
    "            df = lexicon_climate_classifier_4(df_text, lexicon, i)\n",
    "            cross_table = pd.crosstab(df['Target'], df['Target Lexicon'], margins=True)\n",
    "\n",
    "            # calculate classification metrics using scikit-learn\n",
    "            accuracy = (cross_table.iloc[0, 0] + cross_table.iloc[1, 1]) / cross_table.loc['All', 'All'] if cross_table.shape == (3,3) else cross_table.iloc[1,0] / (cross_table.iloc[1, 0] + cross_table.iloc[0,0]) \n",
    "            precision = cross_table.iloc[1,1] / cross_table.iloc[0,1] if cross_table.iloc[0,1] != 0 else 0\n",
    "            recall = cross_table.iloc[1,1] / cross_table.iloc[1,0] if cross_table.iloc[1,0] != 0 else 0\n",
    "            f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "            # print the metrics\n",
    "            print(\"Threshhold:\", i)\n",
    "            print(\"Accuracy:\", accuracy)\n",
    "            print(\"Precision:\", precision)\n",
    "            print(\"Recall:\", recall)\n",
    "            print(\"F1 score:\", f1_score)\n",
    "            print(cross_table)\n",
    "            print(\"\\n\")\n",
    "\n",
    "def get_metrics_df_4(df_text, lexicon, min_treshhold, max_treshhold, jump, Lexicon_name):    \n",
    "    Accuracy = []\n",
    "    Precision = []\n",
    "    Recall = []\n",
    "    F1_score = []\n",
    "    Name = []\n",
    "    Treshhold = []\n",
    "    Technique = []\n",
    "    \n",
    "    for num in range(int((max_treshhold - min_treshhold) / jump) + 1):\n",
    "        i = min_treshhold + num * jump\n",
    "        df = lexicon_climate_classifier_4(df_text, lexicon, i)\n",
    "        cross_table = pd.crosstab(df['Target'], df['Target Lexicon'], margins=True)\n",
    "\n",
    "        # calculate classification metrics using scikit-learn\n",
    "        accuracy = (cross_table.iloc[0, 0] + cross_table.iloc[1, 1]) / cross_table.loc['All', 'All'] if cross_table.shape == (3,3) else cross_table.iloc[1,0] / (cross_table.iloc[1, 0] + cross_table.iloc[0,0]) \n",
    "        precision = cross_table.iloc[1,1] / (cross_table.iloc[0,1] + cross_table.iloc[1,1]) if cross_table.shape == (3,3) else 0\n",
    "        recall = cross_table.iloc[1,1] / (cross_table.iloc[1,0] + cross_table.iloc[1,1]) if cross_table.shape == (3,3) != 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "        Accuracy.append(accuracy)\n",
    "        Precision.append(precision)\n",
    "        Recall.append(recall)\n",
    "        F1_score.append(f1_score)\n",
    "        Name.append(Lexicon_name)\n",
    "        Treshhold.append(i)\n",
    "        Technique.append(\"Relative Presences\")\n",
    "        \n",
    "    return(pd.DataFrame({\"Lexicon\" : Name, \"Technique\": Technique, \"Treshhold\" : Treshhold, \"Accuracy\" : Accuracy, \"Precision\" : Precision, \"Recall\" : Recall, \"F1 Score\" : F1_score}))\n",
    "\n",
    "def get_nsmh_crosstab_4(df_text, lexicon, min_treshhold, max_treshhold, jump):\n",
    "    if(jump == 0):\n",
    "        df = lexicon_climate_classifier_4(df_text, lexicon, min_treshhold)\n",
    "        cross_table = pd.crosstab(df['Final_Climate_Change_Level_Label'], df['Target Lexicon'], margins=True)\n",
    "        print(cross_table)\n",
    "    else:   \n",
    "        for num in range(int((max_treshhold - min_treshhold) / jump) + 1):\n",
    "            i = min_treshhold + num * jump\n",
    "            df = lexicon_climate_classifier_4(df_text, lexicon, i)\n",
    "            cross_table = pd.crosstab(df['Final_Climate_Change_Level_Label'], df['Target Lexicon'], margins=True)\n",
    "            print(cross_table)\n",
    "            print(\"\\n\")\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98158d0",
   "metadata": {},
   "source": [
    "### Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "3500b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(df_with_text, name, model_name, max_lenght_input=-1):\n",
    "    data_in_list = df_with_text[name].tolist()\n",
    "    tokenizer_sum = AutoTokenizer.from_pretrained(model_name)\n",
    "    model_sum = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    summarizer = pipeline('summarization', model=model_sum, tokenizer = tokenizer_sum) \n",
    "\n",
    "    if max_lenght_input>=0:\n",
    "        df_with_text['summary'] = summarizer(data_in_list, max_length=max_lenght_input)\n",
    "\n",
    "    else:\n",
    "        df_with_text['summary'] = summarizer(data_in_list)\n",
    "\n",
    "def classification(df_with_text, name, model_name, max_lenght_input=-1):\n",
    "    data_in_list = df_with_text[name].tolist()\n",
    "    tokenizer_clas = AutoTokenizer.from_pretrained(model_name)\n",
    "    model_clas = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    classification = pipeline('text-classification', model=model_clas, tokenizer = tokenizer_clas) \n",
    "\n",
    "    if max_lenght_input>=0:\n",
    "        df_with_text['classification'] = classification(data_in_list, max_length=max_lenght_input, truncation=True)\n",
    "\n",
    "    else:\n",
    "        df_with_text['classification'] = classification(data_in_list)\n",
    "        \n",
    "    return(df_with_text)\n",
    "\n",
    "def get_metrics_hugging_face(text_df, text_column, model, tokens):\n",
    "    \n",
    "    df = classification(text_df, text_column, model, tokens)\n",
    "    label_list = list(df[\"classification\"])\n",
    "    labels = [entry['label'] for entry in label_list]\n",
    "    df[\"Label_Hugging\"] = labels\n",
    "    \n",
    "    cross_table = pd.crosstab(df['Target'], df['Label_Hugging'], margins=True)\n",
    "    \n",
    "    # calculate classification metrics using scikit-learn\n",
    "    accuracy = (cross_table.iloc[0, 0] + cross_table.iloc[1, 1]) / cross_table.loc['All', 'All'] if cross_table.shape == (3,3) else cross_table.iloc[1,0] / (cross_table.iloc[1, 0] + cross_table.iloc[0,0]) \n",
    "    precision = cross_table.iloc[1,1] / (cross_table.iloc[0,1] + cross_table.iloc[1,1]) if cross_table.shape == (3,3) else 0\n",
    "    recall = cross_table.iloc[1,1] / (cross_table.iloc[1,0] + cross_table.iloc[1,1]) if cross_table.shape == (3,3) != 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "\n",
    "    # print the metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 score:\", f1_score)\n",
    "    print(cross_table)\n",
    "    print(\"\\n\")\n",
    "    print(pd.crosstab(df['Final_Climate_Change_Level_Label'], df['Label_Hugging'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358383a2",
   "metadata": {},
   "source": [
    "Accuracy: This metric measures the overall performance of a model. It is defined as the number of correct predictions divided by the total number of predictions. Accuracy is a good metric to use when the classes are roughly balanced, meaning there are about the same number of positive and negative examples in the dataset.\n",
    "\n",
    "Precision: This metric measures how many of the positive predictions made by a model are actually correct. It is defined as the number of true positives divided by the total number of positive predictions. Precision is a good metric to use when we care more about avoiding false positives than false negatives.\n",
    "\n",
    "Recall: This metric measures how many of the positive examples in the dataset are correctly predicted by the model. It is defined as the number of true positives divided by the total number of actual positive examples. Recall is a good metric to use when we care more about avoiding false negatives than false positives.\n",
    "\n",
    "F1 score: This metric is a weighted average of precision and recall, where the weight is determined by the beta parameter. The most common value for beta is 1, which gives equal weight to precision and recall. The F1 score is a good metric to use when we want to balance precision and recall, and when the classes are imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc10b67",
   "metadata": {},
   "source": [
    "# 1. Import Label Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6b08d6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Link</th>\n",
       "      <th>Sentiment_Label</th>\n",
       "      <th>Sentiment_Label_R</th>\n",
       "      <th>Level_Climate_Change_Topic</th>\n",
       "      <th>Level_Climate_Change_Topic_R</th>\n",
       "      <th>Final_Climate_Change_Level_Label</th>\n",
       "      <th>Final_Sentiment_Label</th>\n",
       "      <th>was_I_retarded?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>More than a dozen state attorneys general gath...</td>\n",
       "      <td>https://www.washingtonpost.com/news/energy-env...</td>\n",
       "      <td>+1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>-1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sen. Jeff Merkley of Oregon endorsed Bernie S...</td>\n",
       "      <td>http://www.wsj.com/articles/campaign-wire-1460...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Small</td>\n",
       "      <td>Small</td>\n",
       "      <td>Small</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When Carmen Luna moved to a neighborhood on t...</td>\n",
       "      <td>https://www.wsj.com/articles/mexico-city-strug...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>-1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As ocean warming continues to trigger widespre...</td>\n",
       "      <td>https://www.washingtonpost.com/national/health...</td>\n",
       "      <td>+1</td>\n",
       "      <td>-1</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>-1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PG&amp;E Corp. told California regulators that it...</td>\n",
       "      <td>https://www.wsj.com/articles/pg-e-equipment-mi...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>-1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  More than a dozen state attorneys general gath...   \n",
       "1   Sen. Jeff Merkley of Oregon endorsed Bernie S...   \n",
       "2   When Carmen Luna moved to a neighborhood on t...   \n",
       "3  As ocean warming continues to trigger widespre...   \n",
       "4   PG&E Corp. told California regulators that it...   \n",
       "\n",
       "                                                Link Sentiment_Label  \\\n",
       "0  https://www.washingtonpost.com/news/energy-env...              +1   \n",
       "1  http://www.wsj.com/articles/campaign-wire-1460...               0   \n",
       "2  https://www.wsj.com/articles/mexico-city-strug...              -1   \n",
       "3  https://www.washingtonpost.com/national/health...              +1   \n",
       "4  https://www.wsj.com/articles/pg-e-equipment-mi...              -1   \n",
       "\n",
       "  Sentiment_Label_R Level_Climate_Change_Topic Level_Climate_Change_Topic_R  \\\n",
       "0                -1                     Medium                       Medium   \n",
       "1                 0                      Small                        Small   \n",
       "2                -1                     Medium                       Medium   \n",
       "3                -1                       High                         High   \n",
       "4                -1                     Medium                       Medium   \n",
       "\n",
       "  Final_Climate_Change_Level_Label  Final_Sentiment_Label was_I_retarded?  \n",
       "0                           Medium                     -1              No  \n",
       "1                            Small                      0             Yes  \n",
       "2                           Medium                     -1             Yes  \n",
       "3                             High                     -1              No  \n",
       "4                           Medium                     -1             Yes  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_climate_df = pd.read_parquet(\"Climate_Labels_Dataset.parquet\")\n",
    "tag_climate_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "0c9d1d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only keep the required columns\n",
    "tag_climate_df = tag_climate_df[[\"Text\", \"Final_Climate_Change_Level_Label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8f9bdc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Final_Climate_Change_Level_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>More than a dozen state attorneys general gath...</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sen. Jeff Merkley of Oregon endorsed Bernie S...</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When Carmen Luna moved to a neighborhood on t...</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As ocean warming continues to trigger widespre...</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PG&amp;E Corp. told California regulators that it...</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>U.S. government bond prices swung Wednesday, u...</td>\n",
       "      <td>Na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Japan’s corporate governance reforms are start...</td>\n",
       "      <td>Na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>While President Trump is out there wheezing hi...</td>\n",
       "      <td>Na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>The South is home to three schools ranked four...</td>\n",
       "      <td>Na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>One of the last jokes I wrote for President Ob...</td>\n",
       "      <td>Na</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  \\\n",
       "0    More than a dozen state attorneys general gath...   \n",
       "1     Sen. Jeff Merkley of Oregon endorsed Bernie S...   \n",
       "2     When Carmen Luna moved to a neighborhood on t...   \n",
       "3    As ocean warming continues to trigger widespre...   \n",
       "4     PG&E Corp. told California regulators that it...   \n",
       "..                                                 ...   \n",
       "295  U.S. government bond prices swung Wednesday, u...   \n",
       "296  Japan’s corporate governance reforms are start...   \n",
       "297  While President Trump is out there wheezing hi...   \n",
       "298  The South is home to three schools ranked four...   \n",
       "299  One of the last jokes I wrote for President Ob...   \n",
       "\n",
       "    Final_Climate_Change_Level_Label  \n",
       "0                             Medium  \n",
       "1                              Small  \n",
       "2                             Medium  \n",
       "3                               High  \n",
       "4                             Medium  \n",
       "..                               ...  \n",
       "295                               Na  \n",
       "296                               Na  \n",
       "297                               Na  \n",
       "298                               Na  \n",
       "299                               Na  \n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_climate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "d2ee616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the tabel\n",
    "tag_climate_df['Final_Climate_Change_Level_Label'] = tag_climate_df['Final_Climate_Change_Level_Label'].str.strip()\n",
    "tag_climate_df.loc[tag_climate_df[\"Final_Climate_Change_Level_Label\"] == \"NA\", \"Final_Climate_Change_Level_Label\"] = \"Na\"\n",
    "tag_climate_df.loc[tag_climate_df[\"Final_Climate_Change_Level_Label\"] == \"0\", \"Final_Climate_Change_Level_Label\"] = \"Na\"\n",
    "tag_climate_df.loc[tag_climate_df[\"Final_Climate_Change_Level_Label\"] == \"Na\", \"Final_Climate_Change_Level_Label\"] = \"No Climate\"\n",
    "tag_climate_df[\"Target\"] = tag_climate_df[\"Final_Climate_Change_Level_Label\"].apply(lambda x: \"Yes\" if x in [\"High\", \"Medium\"] else \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "add6c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_labels_hms = tag_climate_df.groupby(\"Final_Climate_Change_Level_Label\")[\"Text\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "2c689ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Final_Climate_Change_Level_Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>High</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Medium</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No Climate</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Small</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Final_Climate_Change_Level_Label  Text\n",
       "0                             High    65\n",
       "1                           Medium    35\n",
       "2                       No Climate   109\n",
       "3                            Small    91"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview_labels_hms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "be23a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_labels = tag_climate_df.groupby(\"Target\")[\"Text\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "86308d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Target  Text\n",
       "0     No   200\n",
       "1    Yes   100"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "acf33a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#overview_labels_hms.to_csv(\"C:/Users/Boedt/OneDrive/Bureaublad/R Thesis/overview_tag_labels_hms\", index = False)\n",
    "#overview_labels.to_csv(\"C:/Users/Boedt/OneDrive/Bureaublad/R Thesis/overview_tag_labels\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516660b2",
   "metadata": {},
   "source": [
    "# 2. Taggers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2a7077",
   "metadata": {},
   "source": [
    "## 2.1. Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31249337",
   "metadata": {},
   "source": [
    "### Global Change Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c15452",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54704fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the lexicon\n",
    "Global_Change_Lexicon = pd.read_csv(\"Global_Change_Lexicon\")\n",
    "Global_Change_Lexicon = Global_Change_Lexicon.drop_duplicates().reset_index(drop = True)\n",
    "Global_Change_Lexicon[\"Lexicon\"] = Global_Change_Lexicon[\"Lexicon\"].str.lower()\n",
    "\n",
    "Global_Change_Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d26ff50",
   "metadata": {},
   "source": [
    "### IPCC Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800c5ab8",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41bb7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the lexicon\n",
    "IPCC_Lexicon = pd.read_csv(\"IPCC_Lexicon\")\n",
    "IPCC_Lexicon = IPCC_Lexicon.drop_duplicates().reset_index(drop = True)\n",
    "IPCC_Lexicon[\"Lexicon\"] = IPCC_Lexicon[\"Lexicon\"].str.lower()\n",
    "\n",
    "IPCC_Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb16e34",
   "metadata": {},
   "source": [
    "### Wikipedia Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90610cf6",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335d527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the lexicon\n",
    "Wikipedia_Lexicon = pd.read_csv(\"Wikipedia_Lexicon\")\n",
    "Wikipedia_Lexicon = Wikipedia_Lexicon.drop_duplicates().reset_index(drop = True)\n",
    "Wikipedia_Lexicon[\"Lexicon\"] = Wikipedia_Lexicon[\"Lexicon\"].str.lower()\n",
    "\n",
    "Wikipedia_Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c8a3be",
   "metadata": {},
   "source": [
    "### EPA Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638f81be",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93d019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the lexicon\n",
    "EPA_Lexicon = pd.read_csv(\"EPA_Lexicon\")\n",
    "EPA_Lexicon = EPA_Lexicon.drop_duplicates().reset_index(drop = True)\n",
    "EPA_Lexicon[\"Lexicon\"] = EPA_Lexicon[\"Lexicon\"].str.lower()\n",
    "\n",
    "EPA_Lexicon\n",
    "\n",
    "EPA_Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e47f8",
   "metadata": {},
   "source": [
    "### BBC Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b284bd04",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea125ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the lexicon\n",
    "BBC_Lexicon = pd.read_csv(\"BBC_Lexicon\")\n",
    "BBC_Lexicon = BBC_Lexicon.drop_duplicates().reset_index(drop = True)\n",
    "BBC_Lexicon[\"Lexicon\"] = BBC_Lexicon[\"Lexicon\"].str.lower()\n",
    "\n",
    "BBC_Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aade8b",
   "metadata": {},
   "source": [
    "### UNDP Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bae000f",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66d51e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the lexicon\n",
    "UNDP_Lexicon = pd.read_csv(\"UNDP_Lexicon\")\n",
    "UNDP_Lexicon = UNDP_Lexicon.drop_duplicates().reset_index(drop = True)\n",
    "UNDP_Lexicon[\"Lexicon\"] = UNDP_Lexicon[\"Lexicon\"].str.lower()\n",
    "\n",
    "UNDP_Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de5cce8",
   "metadata": {},
   "source": [
    "### Compare the lexicons to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9894900d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "      <th>Global Change</th>\n",
       "      <th>IPCC</th>\n",
       "      <th>Wikipedia</th>\n",
       "      <th>EPA</th>\n",
       "      <th>BBC</th>\n",
       "      <th>UNDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>105</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IPCC</td>\n",
       "      <td>38</td>\n",
       "      <td>405</td>\n",
       "      <td>28</td>\n",
       "      <td>46</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>164</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EPA</td>\n",
       "      <td>20</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>176</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BBC</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>79</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UNDP</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Lexicon  Global Change  IPCC  Wikipedia  EPA  BBC  UNDP\n",
       "0  Global Change            105    38         12   20   11     7\n",
       "1           IPCC             38   405         28   46   22    19\n",
       "2      Wikipedia             12    28        164   33   15    10\n",
       "3            EPA             20    46         33  176   16    14\n",
       "4            BBC             11    22         15   16   79    11\n",
       "5           UNDP              7    19         10   14   11    47"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create an empty dataframe and write a function to fill with the values\n",
    "\n",
    "common_words_df = pd.DataFrame({\"Lexicon\" : [\"Global Change\", \"IPCC\", \"Wikipedia\", \"EPA\", \"BBC\", \"UNDP\"], \n",
    "                               \"Global Change\": [0, 0, 0, 0, 0, 0], \"IPCC\" : [0, 0, 0, 0, 0, 0], \n",
    "                               \"Wikipedia\" : [0, 0, 0, 0, 0, 0], \"EPA\" : [0, 0, 0, 0, 0, 0], \n",
    "                               \"BBC\" : [0, 0, 0, 0, 0, 0], \"UNDP\" : [0, 0, 0, 0, 0, 0]})\n",
    "\n",
    "dfs = [Global_Change_Lexicon, IPCC_Lexicon, Wikipedia_Lexicon, EPA_Lexicon, BBC_Lexicon, UNDP_Lexicon]\n",
    "\n",
    "for r in range(0, len(dfs)):\n",
    "    for c in range(0, len(dfs)):\n",
    "        # Get the common values between the two columns\n",
    "        common_words = set(dfs[r]['Lexicon']).intersection(set(dfs[c]['Lexicon']))\n",
    "        common_words_df.loc[r, common_words_df.columns[c +1]] = len(common_words)\n",
    "\n",
    "common_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3532d27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "      <th>Non unique words</th>\n",
       "      <th>unique words</th>\n",
       "      <th>total_words</th>\n",
       "      <th>Richness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>45</td>\n",
       "      <td>60</td>\n",
       "      <td>105</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IPCC</td>\n",
       "      <td>88</td>\n",
       "      <td>317</td>\n",
       "      <td>405</td>\n",
       "      <td>0.782716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>47</td>\n",
       "      <td>117</td>\n",
       "      <td>164</td>\n",
       "      <td>0.713415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EPA</td>\n",
       "      <td>66</td>\n",
       "      <td>110</td>\n",
       "      <td>176</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BBC</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>79</td>\n",
       "      <td>0.569620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UNDP</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>47</td>\n",
       "      <td>0.446809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Lexicon  Non unique words  unique words  total_words  Richness\n",
       "0  Global Change                45            60          105  0.571429\n",
       "1           IPCC                88           317          405  0.782716\n",
       "2      Wikipedia                47           117          164  0.713415\n",
       "3            EPA                66           110          176  0.625000\n",
       "4            BBC                34            45           79  0.569620\n",
       "5           UNDP                26            21           47  0.446809"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = [Global_Change_Lexicon, IPCC_Lexicon, Wikipedia_Lexicon, EPA_Lexicon, BBC_Lexicon, UNDP_Lexicon]\n",
    "non_unique_words = []\n",
    "unique_words = []\n",
    "total_words = []\n",
    "for r in range(len(dfs)):\n",
    "    common_words = []\n",
    "    for c in range(len(dfs)):\n",
    "        if c != r:\n",
    "            # Get the common values between the two columns\n",
    "            common_words.extend(list(set(dfs[r]['Lexicon']).intersection(set(dfs[c]['Lexicon']))))\n",
    "    common_words = list(set(common_words))  # Remove duplicates by converting to a set and back to a list\n",
    "    total_words.append(len(dfs[r][\"Lexicon\"]))\n",
    "    unique_words.append(len(dfs[r][\"Lexicon\"]) - len(common_words))\n",
    "    non_unique_words.append(len(common_words))\n",
    "\n",
    "non_unique_words\n",
    "\n",
    "unique_words_df = pd.DataFrame({\"Lexicon\" : [\"Global Change\", \"IPCC\", \"Wikipedia\", \"EPA\", \"BBC\", \"UNDP\"], \n",
    "                                \"Non unique words\" : non_unique_words, \"unique words\" : unique_words, \n",
    "                               \"total_words\" : total_words})\n",
    "\n",
    "unique_words_df[\"Richness\"] = unique_words_df[\"unique words\"] / unique_words_df[\"total_words\"]\n",
    "\n",
    "unique_words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53737e8c",
   "metadata": {},
   "source": [
    "# 3. Testen Taggers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b72304",
   "metadata": {},
   "source": [
    "## 3.1. Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "cca33293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a separate df with the specific cleaning for the lexicons\n",
    "Lexicon_df = tag_climate_df.copy()\n",
    "Lexicon_df[\"Text\"] = Lexicon_df[\"Text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "17e4db12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Treshhold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.649351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.640523</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.774704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.731343</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.837607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.773109</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.840183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.853081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.843137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.834171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.820513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.789189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.752809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.843333</td>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.728324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.843333</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.721893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.690909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.641509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.636943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.803333</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.614379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.803333</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.614379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lexicon           Technique  Treshhold  Accuracy  Precision  Recall  \\\n",
       "0      EPA  Relative Frequency        0.0  0.333333   0.000000    0.00   \n",
       "1      EPA  Relative Frequency        0.1  0.640000   0.480769    1.00   \n",
       "2      EPA  Relative Frequency        0.2  0.733333   0.555556    1.00   \n",
       "3      EPA  Relative Frequency        0.3  0.810000   0.640523    0.98   \n",
       "4      EPA  Relative Frequency        0.4  0.873333   0.731343    0.98   \n",
       "5      EPA  Relative Frequency        0.5  0.883333   0.773109    0.92   \n",
       "6      EPA  Relative Frequency        0.6  0.896667   0.810811    0.90   \n",
       "7      EPA  Relative Frequency        0.7  0.893333   0.826923    0.86   \n",
       "8      EPA  Relative Frequency        0.8  0.890000   0.838384    0.83   \n",
       "9      EPA  Relative Frequency        0.9  0.883333   0.842105    0.80   \n",
       "10     EPA  Relative Frequency        1.0  0.883333   0.865169    0.77   \n",
       "11     EPA  Relative Frequency        1.1  0.870000   0.858824    0.73   \n",
       "12     EPA  Relative Frequency        1.2  0.860000   0.853659    0.70   \n",
       "13     EPA  Relative Frequency        1.3  0.853333   0.858974    0.67   \n",
       "14     EPA  Relative Frequency        1.4  0.843333   0.863014    0.63   \n",
       "15     EPA  Relative Frequency        1.5  0.843333   0.884058    0.61   \n",
       "16     EPA  Relative Frequency        1.6  0.830000   0.876923    0.57   \n",
       "17     EPA  Relative Frequency        1.7  0.810000   0.864407    0.51   \n",
       "18     EPA  Relative Frequency        1.8  0.810000   0.877193    0.50   \n",
       "19     EPA  Relative Frequency        1.9  0.803333   0.886792    0.47   \n",
       "20     EPA  Relative Frequency        2.0  0.803333   0.886792    0.47   \n",
       "\n",
       "    F1 Score  \n",
       "0   0.000000  \n",
       "1   0.649351  \n",
       "2   0.714286  \n",
       "3   0.774704  \n",
       "4   0.837607  \n",
       "5   0.840183  \n",
       "6   0.853081  \n",
       "7   0.843137  \n",
       "8   0.834171  \n",
       "9   0.820513  \n",
       "10  0.814815  \n",
       "11  0.789189  \n",
       "12  0.769231  \n",
       "13  0.752809  \n",
       "14  0.728324  \n",
       "15  0.721893  \n",
       "16  0.690909  \n",
       "17  0.641509  \n",
       "18  0.636943  \n",
       "19  0.614379  \n",
       "20  0.614379  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics_df_2(Lexicon_df, EPA_Lexicon, 0, 2, 0.1, \"EPA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bc8d45",
   "metadata": {},
   "source": [
    "### 3.1.1. One Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "61e0d1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Change Lexicon\n",
    "Global_Change_df_1 = get_metrics_df_1(Lexicon_df, Global_Change_Lexicon, 1, 20, \"Global Change\")\n",
    "Global_Change_df_2 = get_metrics_df_2(Lexicon_df, Global_Change_Lexicon, 0.1, 2, 0.1, \"Global Change\")\n",
    "Global_Change_df_3 = get_metrics_df_3(Lexicon_df, Global_Change_Lexicon, 1, 20, \"Global Change\")\n",
    "Global_Change_df_4 = get_metrics_df_4(Lexicon_df, Global_Change_Lexicon, 0.1, 2, 0.1, \"Global Change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ebbd51ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Global_Change_df = pd.concat([Global_Change_df_1, Global_Change_df_2, Global_Change_df_3, Global_Change_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b48f7730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IPCC Lexicon\n",
    "IPCC_df_1 = get_metrics_df_1(Lexicon_df, IPCC_Lexicon, 1, 20, \"IPCC\")\n",
    "IPCC_df_2 = get_metrics_df_2(Lexicon_df, IPCC_Lexicon, 0.1, 2, 0.1, \"IPCC\")\n",
    "IPCC_df_3 = get_metrics_df_3(Lexicon_df, IPCC_Lexicon, 1, 20, \"IPCC\")\n",
    "IPCC_df_4 = get_metrics_df_4(Lexicon_df, IPCC_Lexicon, 0.1, 2, 0.1, \"IPCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "83e242f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPCC_df = pd.concat([IPCC_df_1, IPCC_df_2, IPCC_df_3, IPCC_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e5c72d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wikipedia Lexicon\n",
    "Wikipedia_df_1 = get_metrics_df_1(Lexicon_df, Wikipedia_Lexicon, 1, 20, \"Wikipedia\")\n",
    "Wikipedia_df_2 = get_metrics_df_2(Lexicon_df, Wikipedia_Lexicon, 0.1, 2, 0.1, \"Wikipedia\")\n",
    "Wikipedia_df_3 = get_metrics_df_3(Lexicon_df, Wikipedia_Lexicon, 1, 20, \"Wikipedia\")\n",
    "Wikipedia_df_4 = get_metrics_df_4(Lexicon_df, Wikipedia_Lexicon, 0.1, 2, 0.1, \"Wikipedia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b9e1474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wikipedia_df = pd.concat([Wikipedia_df_1, Wikipedia_df_2, Wikipedia_df_3, Wikipedia_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9caa4baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPA Lexicon\n",
    "EPA_df_1 = get_metrics_df_1(Lexicon_df, EPA_Lexicon, 1, 20, \"EPA\")\n",
    "EPA_df_2 = get_metrics_df_2(Lexicon_df, EPA_Lexicon, 0.1, 2, 0.1, \"EPA\")\n",
    "EPA_df_3 = get_metrics_df_3(Lexicon_df, EPA_Lexicon, 1, 20, \"EPA\")\n",
    "EPA_df_4 = get_metrics_df_4(Lexicon_df, EPA_Lexicon, 0.1, 2, 0.1, \"EPA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "920067f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPA_df = pd.concat([EPA_df_1, EPA_df_2, EPA_df_3, EPA_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "9a445db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BBC Lexicon\n",
    "BBC_df_1 = get_metrics_df_1(Lexicon_df, BBC_Lexicon, 1, 20, \"BBC\")\n",
    "BBC_df_2 = get_metrics_df_2(Lexicon_df, BBC_Lexicon, 0.1, 2, 0.1, \"BBC\")\n",
    "BBC_df_3 = get_metrics_df_3(Lexicon_df, BBC_Lexicon, 1, 20, \"BBC\")\n",
    "BBC_df_4 = get_metrics_df_4(Lexicon_df, BBC_Lexicon, 0.1, 2, 0.1, \"BBC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "2ec49a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "BBC_df = pd.concat([BBC_df_1, BBC_df_2, BBC_df_3, BBC_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "0c8f351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNDP Lexicon\n",
    "UNDP_df_1 = get_metrics_df_1(Lexicon_df, UNDP_Lexicon, 1, 20, \"UNDP\")\n",
    "UNDP_df_2 = get_metrics_df_2(Lexicon_df, UNDP_Lexicon, 0.1, 2, 0.1, \"UNDP\")\n",
    "UNDP_df_3 = get_metrics_df_3(Lexicon_df, UNDP_Lexicon, 1, 20, \"UNDP\")\n",
    "UNDP_df_4 = get_metrics_df_4(Lexicon_df, UNDP_Lexicon, 0.1, 2, 0.1, \"UNDP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "da66cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNDP_df = pd.concat([UNDP_df_1, UNDP_df_2, UNDP_df_3, UNDP_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "917f4664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all lexicons together\n",
    "Lexicon_df_1 = pd.concat([Global_Change_df, IPCC_df, Wikipedia_df, EPA_df, BBC_df, UNDP_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "aea244ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Treshhold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.853081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.843137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BBC</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.786325</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.847926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.834171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNDP</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.828283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.820513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.773109</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.840183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.773109</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.840183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.832536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UNDP</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.816327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>UNDP</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>UNDP</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>0.778761</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.826291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.795580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>UNDP</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.802139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.806283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>0.824742</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.812183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.731343</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.837607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Lexicon           Technique  Treshhold  Accuracy  Precision  Recall  \\\n",
       "0         EPA  Relative Frequency        0.6  0.896667   0.810811    0.90   \n",
       "1         EPA  Relative Frequency        0.7  0.893333   0.826923    0.86   \n",
       "2         BBC  Relative Frequency        0.2  0.890000   0.786325    0.92   \n",
       "3         EPA  Relative Frequency        0.8  0.890000   0.838384    0.83   \n",
       "4        UNDP  Absolute Frequency        4.0  0.886667   0.836735    0.82   \n",
       "5         EPA  Relative Frequency        0.9  0.883333   0.842105    0.80   \n",
       "6         EPA  Relative Frequency        0.5  0.883333   0.773109    0.92   \n",
       "7   Wikipedia  Relative Frequency        0.4  0.883333   0.773109    0.92   \n",
       "8   Wikipedia  Relative Frequency        0.5  0.883333   0.798165    0.87   \n",
       "9         EPA  Relative Frequency        1.0  0.883333   0.865169    0.77   \n",
       "10       UNDP  Relative Frequency        0.6  0.880000   0.847826    0.78   \n",
       "11  Wikipedia  Absolute Frequency        4.0  0.880000   0.807692    0.84   \n",
       "12  Wikipedia  Relative Frequency        0.6  0.880000   0.833333    0.80   \n",
       "13       UNDP  Relative Frequency        0.5  0.880000   0.807692    0.84   \n",
       "14       UNDP  Relative Frequency        0.4  0.876667   0.778761    0.88   \n",
       "15  Wikipedia  Absolute Frequency        5.0  0.876667   0.888889    0.72   \n",
       "16       UNDP  Relative Frequency        0.7  0.876667   0.862069    0.75   \n",
       "17  Wikipedia  Relative Frequency        0.7  0.876667   0.846154    0.77   \n",
       "18        EPA  Absolute Frequency        5.0  0.876667   0.824742    0.80   \n",
       "19        EPA  Relative Frequency        0.4  0.873333   0.731343    0.98   \n",
       "\n",
       "    F1 Score  \n",
       "0   0.853081  \n",
       "1   0.843137  \n",
       "2   0.847926  \n",
       "3   0.834171  \n",
       "4   0.828283  \n",
       "5   0.820513  \n",
       "6   0.840183  \n",
       "7   0.840183  \n",
       "8   0.832536  \n",
       "9   0.814815  \n",
       "10  0.812500  \n",
       "11  0.823529  \n",
       "12  0.816327  \n",
       "13  0.823529  \n",
       "14  0.826291  \n",
       "15  0.795580  \n",
       "16  0.802139  \n",
       "17  0.806283  \n",
       "18  0.812183  \n",
       "19  0.837607  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lexicon_df_1.sort_values(\"Accuracy\", ascending = False).reset_index(drop = True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a074a4f",
   "metadata": {},
   "source": [
    "### 3.1.2. Two Lexicons Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "94ae84f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNDP and EPA\n",
    "EPA_UNDP_Lexicon = pd.concat([EPA_Lexicon, UNDP_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "EPA_UNDP_df_1 = get_metrics_df_1(Lexicon_df, EPA_UNDP_Lexicon, 1, 20, \"EPA_UDNP\")\n",
    "EPA_UNDP_df_2 = get_metrics_df_2(Lexicon_df, EPA_UNDP_Lexicon, 0.1, 2, 0.1, \"EPA_UDNP\")\n",
    "EPA_UNDP_df_3 = get_metrics_df_3(Lexicon_df, EPA_UNDP_Lexicon, 1, 20, \"EPA_UDNP\")\n",
    "EPA_UNDP_df_4 = get_metrics_df_4(Lexicon_df, EPA_UNDP_Lexicon, 0.1, 2, 0.1, \"EPA_UDNP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ccf1520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPA_UNDP_df = pd.concat([EPA_UNDP_df_1, EPA_UNDP_df_2, EPA_UNDP_df_3, EPA_UNDP_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "418d74b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNDP and BBC\n",
    "BBC_UNDP_Lexicon = pd.concat([BBC_Lexicon, UNDP_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "BBC_UNDP_df_1 = get_metrics_df_1(Lexicon_df, BBC_UNDP_Lexicon, 1, 20, \"BBC_UNDP\")\n",
    "BBC_UNDP_df_2 = get_metrics_df_2(Lexicon_df, BBC_UNDP_Lexicon, 0.1, 2, 0.1, \"BBC_UNDP\")\n",
    "BBC_UNDP_df_3 = get_metrics_df_3(Lexicon_df, BBC_UNDP_Lexicon, 1, 20, \"BBC_UNDP\")\n",
    "BBC_UNDP_df_4 = get_metrics_df_4(Lexicon_df, BBC_UNDP_Lexicon, 0.1, 2, 0.1, \"BBC_UNDP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "56595876",
   "metadata": {},
   "outputs": [],
   "source": [
    "BBC_UNDP_df = pd.concat([BBC_UNDP_df_1, BBC_UNDP_df_2, BBC_UNDP_df_3, BBC_UNDP_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "a6dc494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNDP and Global Change \n",
    "UNDP_Global_Change_Lexicon = pd.concat([Global_Change_Lexicon, UNDP_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "UNDP_Global_Change_df_1 = get_metrics_df_1(Lexicon_df, UNDP_Global_Change_Lexicon, 1, 20, \"UNDP_Global_Change\")\n",
    "UNDP_Global_Change_df_2 = get_metrics_df_2(Lexicon_df, UNDP_Global_Change_Lexicon, 0.1, 2, 0.1, \"UNDP_Global_Change\")\n",
    "UNDP_Global_Change_df_3 = get_metrics_df_3(Lexicon_df, UNDP_Global_Change_Lexicon, 1, 20, \"UNDP_Global_Change\")\n",
    "UNDP_Global_Change_df_4 = get_metrics_df_4(Lexicon_df, UNDP_Global_Change_Lexicon, 0.1, 2, 0.1, \"UNDP_Global_Change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "f0cbdbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "Global_Change_UNDP_df = pd.concat([UNDP_Global_Change_df_1, UNDP_Global_Change_df_2, UNDP_Global_Change_df_3, UNDP_Global_Change_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "7def3b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNDP and IPCC\n",
    "UNDP_IPCC_Lexicon = pd.concat([IPCC_Lexicon, UNDP_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "UNDP_IPCC_df_1 = get_metrics_df_1(Lexicon_df, UNDP_IPCC_Lexicon, 1, 20, \"UNDP_IPCC\")\n",
    "UNDP_IPCC_df_2 = get_metrics_df_2(Lexicon_df, UNDP_IPCC_Lexicon, 0.1, 2, 0.1, \"UNDP_IPCC\")\n",
    "UNDP_IPCC_df_3 = get_metrics_df_3(Lexicon_df, UNDP_IPCC_Lexicon, 1, 20, \"UNDP_IPCC\")\n",
    "UNDP_IPCC_df_4 = get_metrics_df_4(Lexicon_df, UNDP_IPCC_Lexicon, 0.1, 2, 0.1, \"UNDP_IPCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "76c4f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPCC_UNDP_df = pd.concat([UNDP_IPCC_df_1, UNDP_IPCC_df_2, UNDP_IPCC_df_3, UNDP_IPCC_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "881f064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNDP and Wikipedia\n",
    "UNDP_Wikipedia_Lexicon = pd.concat([Wikipedia_Lexicon, UNDP_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "UNDP_Wikipedia_df_1 = get_metrics_df_1(Lexicon_df, UNDP_Wikipedia_Lexicon, 1, 20, \"UNDP_Wikipedia\")\n",
    "UNDP_Wikipedia_df_2 = get_metrics_df_2(Lexicon_df, UNDP_Wikipedia_Lexicon, 0.1, 2, 0.1, \"UNDP_Wikipedia\")\n",
    "UNDP_Wikipedia_df_3 = get_metrics_df_3(Lexicon_df, UNDP_Wikipedia_Lexicon, 1, 20, \"UNDP_Wikipedia\")\n",
    "UNDP_Wikipedia_df_4 = get_metrics_df_4(Lexicon_df, UNDP_Wikipedia_Lexicon, 0.1, 2, 0.1, \"UNDP_Wikipedia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "d486bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wikipedia_UNDP_df = pd.concat([UNDP_Wikipedia_df_1, UNDP_Wikipedia_df_2, UNDP_Wikipedia_df_3, UNDP_Wikipedia_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "f29be6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lexicon_df_2 = pd.concat([EPA_UNDP_df, BBC_UNDP_df, Global_Change_UNDP_df, IPCC_UNDP_df, Wikipedia_UNDP_df]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "637fa27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPA and BBC\n",
    "EPA_BBC_Lexicon = pd.concat([EPA_Lexicon, BBC_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "EPA_BBC_df_1 = get_metrics_df_1(Lexicon_df, EPA_BBC_Lexicon, 1, 20, \"BBC_EPA\")\n",
    "EPA_BBC_df_2 = get_metrics_df_2(Lexicon_df, EPA_BBC_Lexicon, 0.1, 2, 0.1, \"BBC_EPA\")\n",
    "EPA_BBC_df_3 = get_metrics_df_3(Lexicon_df, EPA_BBC_Lexicon, 1, 20, \"BBC_EPA\")\n",
    "EPA_BBC_df_4 = get_metrics_df_4(Lexicon_df, EPA_BBC_Lexicon, 0.1, 2, 0.1, \"BBC_EPA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "5766b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPA_BBC_df = pd.concat([EPA_BBC_df_1, EPA_BBC_df_2, EPA_BBC_df_3, EPA_BBC_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "101535ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPA and Global Change\n",
    "EPA_Global_Change_Lexicon = pd.concat([EPA_Lexicon, Global_Change_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "EPA_Global_Change_df_1 = get_metrics_df_1(Lexicon_df, EPA_Global_Change_Lexicon, 1, 20, \"EPA_GLobal_Change\")\n",
    "EPA_Global_Change_df_2 = get_metrics_df_2(Lexicon_df, EPA_Global_Change_Lexicon, 0.1, 2, 0.1, \"BBC_Global_Change\")\n",
    "EPA_Global_Change_df_3 = get_metrics_df_3(Lexicon_df, EPA_Global_Change_Lexicon, 1, 20, \"BBC_Global_Change\")\n",
    "EPA_Global_Change_df_4 = get_metrics_df_4(Lexicon_df, EPA_Global_Change_Lexicon, 0.1, 2, 0.1, \"BBC_Global_Change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "0d585045",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPA_Global_Change_df = pd.concat([EPA_Global_Change_df_1, EPA_Global_Change_df_2, EPA_Global_Change_df_3, EPA_Global_Change_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "4717a31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Treshhold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BBC_Global_Change</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.794643</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.839623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BBC_Global_Change</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.817308</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BBC_Global_Change</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BBC_Global_Change</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.826531</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BBC_Global_Change</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.831050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EPA_GLobal_Change</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.556667</td>\n",
       "      <td>0.429185</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.600601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBC_Global_Change</td>\n",
       "      <td>Relative Presences</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBC_Global_Change</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPA_GLobal_Change</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.396825</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.568182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBC_Global_Change</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.396825</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.568182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Lexicon           Technique  Treshhold  Accuracy  Precision  \\\n",
       "9   BBC_Global_Change  Relative Frequency        1.0  0.886667   0.794643   \n",
       "10  BBC_Global_Change  Relative Frequency        1.1  0.886667   0.817308   \n",
       "11  BBC_Global_Change  Relative Frequency        1.2  0.880000   0.820000   \n",
       "12  BBC_Global_Change  Relative Frequency        1.3  0.880000   0.826531   \n",
       "8   BBC_Global_Change  Relative Frequency        0.9  0.876667   0.764706   \n",
       "..                ...                 ...        ...       ...        ...   \n",
       "1   EPA_GLobal_Change  Absolute Frequency        2.0  0.556667   0.429185   \n",
       "0   BBC_Global_Change  Relative Presences        0.1  0.500000   0.400000   \n",
       "0   BBC_Global_Change  Relative Frequency        0.1  0.500000   0.400000   \n",
       "0   EPA_GLobal_Change  Absolute Frequency        1.0  0.493333   0.396825   \n",
       "0   BBC_Global_Change  Absolute Presences        1.0  0.493333   0.396825   \n",
       "\n",
       "    Recall  F1 Score  \n",
       "9     0.89  0.839623  \n",
       "10    0.85  0.833333  \n",
       "11    0.82  0.820000  \n",
       "12    0.81  0.818182  \n",
       "8     0.91  0.831050  \n",
       "..     ...       ...  \n",
       "1     1.00  0.600601  \n",
       "0     1.00  0.571429  \n",
       "0     1.00  0.571429  \n",
       "0     1.00  0.568182  \n",
       "0     1.00  0.568182  \n",
       "\n",
       "[78 rows x 7 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPA_Global_Change_df.sort_values(\"Accuracy\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "ab41474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPA and IPCC\n",
    "EPA_IPCC_Lexicon = pd.concat([EPA_Lexicon, IPCC_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "EPA_IPCC_df_1 = get_metrics_df_1(Lexicon_df, EPA_IPCC_Lexicon, 1, 20, \"EPA_IPCC\")\n",
    "EPA_IPCC_df_2 = get_metrics_df_2(Lexicon_df, EPA_IPCC_Lexicon, 0.1, 2, 0.1, \"EPA_IPCC\")\n",
    "EPA_IPCC_df_3 = get_metrics_df_3(Lexicon_df, EPA_IPCC_Lexicon, 1, 20, \"EPA_IPCC\")\n",
    "EPA_IPCC_df_4 = get_metrics_df_4(Lexicon_df, EPA_IPCC_Lexicon, 0.1, 2, 0.1, \"EPA_IPCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "81e6d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPA_IPCC_df = pd.concat([EPA_IPCC_df_1, EPA_IPCC_df_2, EPA_IPCC_df_3, EPA_IPCC_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "f2431357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Treshhold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EPA_IPCC</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>0.805825</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.817734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EPA_IPCC</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.822967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EPA_IPCC</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.765217</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.818605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EPA_IPCC</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.863333</td>\n",
       "      <td>0.743802</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.814480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>EPA_IPCC</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.863333</td>\n",
       "      <td>0.810526</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.789744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EPA_IPCC</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.463333</td>\n",
       "      <td>0.383142</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.554017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPA_IPCC</td>\n",
       "      <td>Relative Presences</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPA_IPCC</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPA_IPCC</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.403333</td>\n",
       "      <td>0.358423</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.527704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPA_IPCC</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.403333</td>\n",
       "      <td>0.358423</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.527704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Lexicon           Technique  Treshhold  Accuracy  Precision  Recall  \\\n",
       "15  EPA_IPCC  Relative Frequency        1.6  0.876667   0.805825    0.83   \n",
       "14  EPA_IPCC  Relative Frequency        1.5  0.876667   0.788991    0.86   \n",
       "13  EPA_IPCC  Relative Frequency        1.4  0.870000   0.765217    0.88   \n",
       "12  EPA_IPCC  Relative Frequency        1.3  0.863333   0.743802    0.90   \n",
       "17  EPA_IPCC  Relative Frequency        1.8  0.863333   0.810526    0.77   \n",
       "..       ...                 ...        ...       ...        ...     ...   \n",
       "1   EPA_IPCC  Relative Frequency        0.2  0.463333   0.383142    1.00   \n",
       "0   EPA_IPCC  Relative Presences        0.1  0.416667   0.363636    1.00   \n",
       "0   EPA_IPCC  Relative Frequency        0.1  0.416667   0.363636    1.00   \n",
       "0   EPA_IPCC  Absolute Frequency        1.0  0.403333   0.358423    1.00   \n",
       "0   EPA_IPCC  Absolute Presences        1.0  0.403333   0.358423    1.00   \n",
       "\n",
       "    F1 Score  \n",
       "15  0.817734  \n",
       "14  0.822967  \n",
       "13  0.818605  \n",
       "12  0.814480  \n",
       "17  0.789744  \n",
       "..       ...  \n",
       "1   0.554017  \n",
       "0   0.533333  \n",
       "0   0.533333  \n",
       "0   0.527704  \n",
       "0   0.527704  \n",
       "\n",
       "[78 rows x 7 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPA_IPCC_df.sort_values(\"Accuracy\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "129ced17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPA and Wikipedia\n",
    "EPA_Wikipedia_Lexicon = pd.concat([EPA_Lexicon, Wikipedia_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "EPA_Wikipedia_df_1 = get_metrics_df_1(Lexicon_df, EPA_Wikipedia_Lexicon, 1, 20, \"EPA_Wikipedia\")\n",
    "EPA_Wikipedia_df_2 = get_metrics_df_2(Lexicon_df, EPA_Wikipedia_Lexicon, 0.1, 2, 0.1, \"EPA_Wikipedia\")\n",
    "EPA_Wikipedia_df_3 = get_metrics_df_3(Lexicon_df, EPA_Wikipedia_Lexicon, 1, 20, \"EPA_Wikipedia\")\n",
    "EPA_Wikipedia_df_4 = get_metrics_df_4(Lexicon_df, EPA_Wikipedia_Lexicon, 0.1, 2, 0.1, \"EPA_Wikipedia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "61c1e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPA_Wikipedia_df = pd.concat([EPA_Wikipedia_df_1, EPA_Wikipedia_df_2, EPA_Wikipedia_df_3, EPA_Wikipedia_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "dc9e53d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Treshhold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.844221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.855814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.809091</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.847619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.836735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.843137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Relative Presences</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.641026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.623333</td>\n",
       "      <td>0.469484</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.638978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.467290</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.636943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.603333</td>\n",
       "      <td>0.456621</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.626959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.603333</td>\n",
       "      <td>0.456621</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.626959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Lexicon           Technique  Treshhold  Accuracy  Precision  Recall  \\\n",
       "13  EPA_Wikipedia  Relative Frequency        1.4  0.896667   0.848485    0.84   \n",
       "9   EPA_Wikipedia  Relative Frequency        1.0  0.896667   0.800000    0.92   \n",
       "10  EPA_Wikipedia  Relative Frequency        1.1  0.893333   0.809091    0.89   \n",
       "14  EPA_Wikipedia  Relative Frequency        1.5  0.893333   0.854167    0.82   \n",
       "11  EPA_Wikipedia  Relative Frequency        1.2  0.893333   0.826923    0.86   \n",
       "..            ...                 ...        ...       ...        ...     ...   \n",
       "0   EPA_Wikipedia  Relative Presences        0.1  0.626667   0.471698    1.00   \n",
       "1   EPA_Wikipedia  Absolute Frequency        2.0  0.623333   0.469484    1.00   \n",
       "0   EPA_Wikipedia  Relative Frequency        0.1  0.620000   0.467290    1.00   \n",
       "0   EPA_Wikipedia  Absolute Frequency        1.0  0.603333   0.456621    1.00   \n",
       "0   EPA_Wikipedia  Absolute Presences        1.0  0.603333   0.456621    1.00   \n",
       "\n",
       "    F1 Score  \n",
       "13  0.844221  \n",
       "9   0.855814  \n",
       "10  0.847619  \n",
       "14  0.836735  \n",
       "11  0.843137  \n",
       "..       ...  \n",
       "0   0.641026  \n",
       "1   0.638978  \n",
       "0   0.636943  \n",
       "0   0.626959  \n",
       "0   0.626959  \n",
       "\n",
       "[78 rows x 7 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPA_Wikipedia_df.sort_values(\"Accuracy\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "1fd66768",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lexicon_df_2 = pd.concat([Lexicon_df_2, EPA_BBC_df, EPA_Global_Change_df, EPA_IPCC_df, EPA_Wikipedia_df]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "1260c559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BBC and Global Change\n",
    "BBC_Global_Change_Lexicon = pd.concat([BBC_Lexicon, Global_Change_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "BBC_Global_Change_df_1 = get_metrics_df_1(Lexicon_df, BBC_Global_Change_Lexicon, 1, 20, \"BBC_Global_Change\")\n",
    "BBC_Global_Change_df_2 = get_metrics_df_2(Lexicon_df, BBC_Global_Change_Lexicon, 0.1, 2, 0.1, \"BBC_Global_Change\")\n",
    "BBC_Global_Change_df_3 = get_metrics_df_3(Lexicon_df, BBC_Global_Change_Lexicon, 1, 20, \"BBC_Global_Change\")\n",
    "BBC_Global_Change_df_4 = get_metrics_df_4(Lexicon_df, BBC_Global_Change_Lexicon, 0.1, 2, 0.1, \"BBC_Global_Change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "4c2024e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BBC_Global_Change_df = pd.concat([BBC_Global_Change_df_1, BBC_Global_Change_df_2, BBC_Global_Change_df_3, BBC_Global_Change_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "a152cd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BBC and IPCC\n",
    "BBC_IPCC_Lexicon = pd.concat([BBC_Lexicon, IPCC_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "BBC_IPCC_df_1 = get_metrics_df_1(Lexicon_df, BBC_IPCC_Lexicon, 1, 20, \"BBC_IPCC\")\n",
    "BBC_IPCC_df_2 = get_metrics_df_2(Lexicon_df, BBC_IPCC_Lexicon, 0.1, 2, 0.1, \"BBC_IPCC\")\n",
    "BBC_IPCC_df_3 = get_metrics_df_3(Lexicon_df, BBC_IPCC_Lexicon, 1, 20, \"BBC_IPCC\")\n",
    "BBC_IPCC_df_4 = get_metrics_df_4(Lexicon_df, BBC_IPCC_Lexicon, 0.1, 2, 0.1, \"BBC_IPCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "64f41eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BBC_IPCC_df = pd.concat([BBC_IPCC_df_1, BBC_IPCC_df_2, BBC_IPCC_df_3, BBC_IPCC_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "7b9bd7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BBC and Wikipedia\n",
    "BBC_Wikipedia_Lexicon = pd.concat([BBC_Lexicon, Wikipedia_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "BBC_Wikipedia_df_1 = get_metrics_df_1(Lexicon_df, BBC_Wikipedia_Lexicon, 1, 20, \"BBC_Wikipedia\")\n",
    "BBC_Wikipedia_df_2 = get_metrics_df_2(Lexicon_df, BBC_Wikipedia_Lexicon, 0.1, 2, 0.1, \"BBC_Wikipedia\")\n",
    "BBC_Wikipedia_df_3 = get_metrics_df_3(Lexicon_df, BBC_Wikipedia_Lexicon, 1, 20, \"BBC_Wikipedia\")\n",
    "BBC_Wikipedia_df_4 = get_metrics_df_4(Lexicon_df, BBC_Wikipedia_Lexicon, 0.1, 2, 0.1, \"BBC_Wikipedia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "9bf1b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "BBC_Wikpedia_df = pd.concat([BBC_Wikipedia_df_1, BBC_Wikipedia_df_2, BBC_Wikipedia_df_3, BBC_Wikipedia_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "08f6aa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lexicon_df_2 = pd.concat([Lexicon_df_2, BBC_Global_Change_df, BBC_IPCC_df, BBC_Wikpedia_df]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "477a603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wikipedia and Global Change\n",
    "Wikipedia_Global_Change_Lexicon = pd.concat([Global_Change_Lexicon, Wikipedia_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "Wikipedia_Global_Change_df_1 = get_metrics_df_1(Lexicon_df, Wikipedia_Global_Change_Lexicon, 1, 20, \"Wikipedia_Global_Change\")\n",
    "Wikipedia_Global_Change_df_2 = get_metrics_df_2(Lexicon_df, Wikipedia_Global_Change_Lexicon, 0.1, 2, 0.1, \"Wikipedia_Global_Change\")\n",
    "Wikipedia_Global_Change_df_3 = get_metrics_df_3(Lexicon_df, Wikipedia_Global_Change_Lexicon, 1, 20, \"Wikipedia_Global_Change\")\n",
    "Wikipedia_Global_Change_df_4 = get_metrics_df_4(Lexicon_df, Wikipedia_Global_Change_Lexicon, 0.1, 2, 0.1, \"Wikipedia_Global_Change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "ae5ea019",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wikpedia_Global_Change_df = pd.concat([Wikipedia_Global_Change_df_1, Wikipedia_Global_Change_df_2, Wikipedia_Global_Change_df_3, Wikipedia_Global_Change_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "8f2287a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wikipedia and IPCC\n",
    "Wikipedia_IPCC_Lexicon = pd.concat([IPCC_Lexicon, Wikipedia_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "Wikipedia_IPCC_df_1 = get_metrics_df_1(Lexicon_df, Wikipedia_IPCC_Lexicon, 1, 20, \"Wikipedia_IPCC\")\n",
    "Wikipedia_IPCC_df_2 = get_metrics_df_2(Lexicon_df, Wikipedia_IPCC_Lexicon, 0.1, 2, 0.1, \"Wikipedia_IPCC\")\n",
    "Wikipedia_IPCC_df_3 = get_metrics_df_3(Lexicon_df, Wikipedia_IPCC_Lexicon, 1, 20, \"Wikipedia_IPCC\")\n",
    "Wikipedia_IPCC_df_4 = get_metrics_df_4(Lexicon_df, Wikipedia_IPCC_Lexicon, 0.1, 2, 0.1, \"Wikipedia_IPCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "f5e11a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wikpedia_IPCC_df = pd.concat([Wikipedia_IPCC_df_1, Wikipedia_IPCC_df_2, Wikipedia_IPCC_df_3, Wikipedia_IPCC_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "0198c9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IPCC and Global Change\n",
    "Global_Change_IPCC_Lexicon = pd.concat([IPCC_Lexicon, Global_Change_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "Global_Change_IPCC_df_1 = get_metrics_df_1(Lexicon_df, Global_Change_IPCC_Lexicon, 1, 20, \"Global_Change_IPCC\")\n",
    "Global_Change_IPCC_df_2 = get_metrics_df_2(Lexicon_df, Global_Change_IPCC_Lexicon, 0.1, 2, 0.1, \"Global_Change_IPCC\")\n",
    "Global_Change_IPCC_df_3 = get_metrics_df_3(Lexicon_df, Global_Change_IPCC_Lexicon, 1, 20, \"Global_Change_IPCC\")\n",
    "Global_Change_IPCC_df_4 = get_metrics_df_4(Lexicon_df, Global_Change_IPCC_Lexicon, 0.1, 2, 0.1, \"Global_Change_IPCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "a0a0fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "Global_Change_IPCC_df = pd.concat([Global_Change_IPCC_df_1, Global_Change_IPCC_df_2, Global_Change_IPCC_df_3, Global_Change_IPCC_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "157d3ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lexicon_df_2 = pd.concat([Lexicon_df_2, Wikpedia_Global_Change_df, Wikpedia_IPCC_df, Global_Change_IPCC_df]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "28d5c0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Treshhold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>EPA_UDNP</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.858491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.855814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>BBC_EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.805310</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.854460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>BBC_UNDP</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.851485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.776860</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.850679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>EPA_UDNP</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>EPA_UDNP</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>EPA_UDNP</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>BBC_Global_Change</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>BBC_Global_Change</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1170 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Lexicon           Technique  Treshhold  Accuracy  Precision  \\\n",
       "25            EPA_UDNP  Relative Frequency        0.6  0.900000   0.812500   \n",
       "653      EPA_Wikipedia  Relative Frequency        1.0  0.896667   0.800000   \n",
       "415            BBC_EPA  Relative Frequency        0.6  0.896667   0.805310   \n",
       "81            BBC_UNDP  Absolute Frequency        4.0  0.900000   0.843137   \n",
       "652      EPA_Wikipedia  Relative Frequency        0.9  0.890000   0.776860   \n",
       "..                 ...                 ...        ...       ...        ...   \n",
       "58            EPA_UDNP  Absolute Presences       20.0  0.333333   0.000000   \n",
       "57            EPA_UDNP  Absolute Presences       19.0  0.333333   0.000000   \n",
       "56            EPA_UDNP  Absolute Presences       18.0  0.333333   0.000000   \n",
       "760  BBC_Global_Change  Absolute Presences       20.0  0.333333   0.000000   \n",
       "759  BBC_Global_Change  Absolute Presences       19.0  0.333333   0.000000   \n",
       "\n",
       "     Recall  F1 Score  \n",
       "25     0.91  0.858491  \n",
       "653    0.92  0.855814  \n",
       "415    0.91  0.854460  \n",
       "81     0.86  0.851485  \n",
       "652    0.94  0.850679  \n",
       "..      ...       ...  \n",
       "58     0.00  0.000000  \n",
       "57     0.00  0.000000  \n",
       "56     0.00  0.000000  \n",
       "760    0.00  0.000000  \n",
       "759    0.00  0.000000  \n",
       "\n",
       "[1170 rows x 7 columns]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lexicon_df_2.sort_values(\"F1 Score\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "00b24048",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lexicon_Metrics = pd.concat([Lexicon_df_1, Lexicon_df_2]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "38fe9429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Treshhold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>EPA_UDNP</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.858491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>BBC_UNDP</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.851485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.853081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>BBC_EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.805310</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.854460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.855814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>BBC</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>BBC</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>EPA_UDNP</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>BBC</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>BBC</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1638 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Lexicon           Technique  Treshhold  Accuracy  Precision  \\\n",
       "493        EPA_UDNP  Relative Frequency        0.6  0.900000   0.812500   \n",
       "549        BBC_UNDP  Absolute Frequency        4.0  0.900000   0.843137   \n",
       "259             EPA  Relative Frequency        0.6  0.896667   0.810811   \n",
       "883         BBC_EPA  Relative Frequency        0.6  0.896667   0.805310   \n",
       "1121  EPA_Wikipedia  Relative Frequency        1.0  0.896667   0.800000   \n",
       "...             ...                 ...        ...       ...        ...   \n",
       "360             BBC  Absolute Presences       10.0  0.333333   0.000000   \n",
       "361             BBC  Absolute Presences       11.0  0.333333   0.000000   \n",
       "526        EPA_UDNP  Absolute Presences       20.0  0.333333   0.000000   \n",
       "363             BBC  Absolute Presences       13.0  0.333333   0.000000   \n",
       "362             BBC  Absolute Presences       12.0  0.333333   0.000000   \n",
       "\n",
       "      Recall  F1 Score  \n",
       "493     0.91  0.858491  \n",
       "549     0.86  0.851485  \n",
       "259     0.90  0.853081  \n",
       "883     0.91  0.854460  \n",
       "1121    0.92  0.855814  \n",
       "...      ...       ...  \n",
       "360     0.00  0.000000  \n",
       "361     0.00  0.000000  \n",
       "526     0.00  0.000000  \n",
       "363     0.00  0.000000  \n",
       "362     0.00  0.000000  \n",
       "\n",
       "[1638 rows x 7 columns]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lexicon_Metrics.sort_values(by=\"Accuracy\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "df31fe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lexicon_Metrics.to_parquet(\"Lexicon_Tagging_Metrics.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c5e22e",
   "metadata": {},
   "source": [
    "### Three Lexicon Combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828a117f",
   "metadata": {},
   "source": [
    "First, we will only look at the ones that showed great performance in the previous steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f4af9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPA, UNDP and BBC\n",
    "EPA_UNDP_BBC_Lexicon = pd.concat([EPA_Lexicon, UNDP_Lexicon, BBC_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "EPA_UNDP_BBC_df_1 = get_metrics_df_1(Lexicon_df, EPA_UNDP_BBC_Lexicon, 0, 20, \"EPA_UNDP_BBC\")\n",
    "EPA_UNDP_BBC_df_2 = get_metrics_df_2(Lexicon_df, EPA_UNDP_BBC_Lexicon, 0, 2, 0.1, \"EPA_UNDP_BBC\")\n",
    "EPA_UNDP_BBC_df_3 = get_metrics_df_3(Lexicon_df, EPA_UNDP_BBC_Lexicon, 0, 20, \"EPA_UNDP_BBC\")\n",
    "EPA_UNDP_BBC_df_4 = get_metrics_df_4(Lexicon_df, EPA_UNDP_BBC_Lexicon, 0, 2, 0.1, \"EPA_UNDP_BBC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692dd974",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPA_UNDP_BBC_df = pd.concat([EPA_UNDP_BBC_df_1, EPA_UNDP_BBC_df_2, EPA_UNDP_BBC_df_3, EPA_UNDP_BBC_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053e667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPA_UNDP_BBC_df.sort_values(by=\"Accuracy\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff96a7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPA, UNDP and Wikipedia\n",
    "EPA_UNDP_Wikipedia_Lexicon = pd.concat([EPA_Lexicon, UNDP_Lexicon, Wikipedia_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "EPA_UNDP_Wikipedia_df_1 = get_metrics_df_1(Lexicon_df, EPA_UNDP_Wikipedia_Lexicon, 0, 20, \"EPA_UNDP_Wikipedia\")\n",
    "EPA_UNDP_Wikipedia_df_2 = get_metrics_df_2(Lexicon_df, EPA_UNDP_Wikipedia_Lexicon, 0, 2, 0.1, \"EPA_UNDP_Wikipedia\")\n",
    "EPA_UNDP_Wikipedia_df_3 = get_metrics_df_3(Lexicon_df, EPA_UNDP_Wikipedia_Lexicon, 0, 20, \"EPA_UNDP_Wikipedia\")\n",
    "EPA_UNDP_Wikipedia_df_4 = get_metrics_df_4(Lexicon_df, EPA_UNDP_Wikipedia_Lexicon, 0, 2, 0.1, \"EPA_UNDP_Wikipedia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1577b8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPA_UNDP_Wikipedia_df = pd.concat([EPA_UNDP_Wikipedia_df_1, EPA_UNDP_Wikipedia_df_2, EPA_UNDP_Wikipedia_df_3, EPA_UNDP_Wikipedia_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d55c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPA_UNDP_Wikipedia_df.sort_values(by=\"F1 Score\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d743e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_nsmh_crosstab_2(Lexicon_df, EPA_UNDP_Wikipedia_Lexicon, 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bc8a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPA, UNDP, BBC and Wikipedia\n",
    "EPA_UNDP_BBC_Wikipedia_Lexicon = pd.concat([EPA_Lexicon, UNDP_Lexicon, Wikipedia_Lexicon, BBC_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "EPA_UNDP_BBC_Wikipedia_df_1 = get_metrics_df_1(Lexicon_df, EPA_UNDP_BBC_Wikipedia_Lexicon, 0, 20, \"EPA_UNDP_Wikipedia_BBC\")\n",
    "EPA_UNDP_BBC_Wikipedia_df_2 = get_metrics_df_2(Lexicon_df, EPA_UNDP_BBC_Wikipedia_Lexicon, 0, 2, 0.1, \"EPA_UNDP_Wikipedia_BBC\")\n",
    "EPA_UNDP_BBC_Wikipedia_df_3 = get_metrics_df_3(Lexicon_df, EPA_UNDP_BBC_Wikipedia_Lexicon, 0, 20, \"EPA_UNDP_Wikipedia_BBC\")\n",
    "EPA_UNDP_BBC_Wikipedia_df_4 = get_metrics_df_4(Lexicon_df, EPA_UNDP_BBC_Wikipedia_Lexicon, 0, 2, 0.1, \"EPA_UNDP_Wikipedia_BBC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86e2bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPA_UNDP_BBC_Wikipedia_df = pd.concat([EPA_UNDP_BBC_Wikipedia_df_1, EPA_UNDP_BBC_Wikipedia_df_2, EPA_UNDP_BBC_Wikipedia_df_3, EPA_UNDP_BBC_Wikipedia_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee594665",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPA_UNDP_BBC_Wikipedia_df.sort_values(by=\"F1 Score\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56657642",
   "metadata": {},
   "source": [
    "### Combining All Six Lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577cf892",
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_Lexicon = pd.concat([Global_Change_Lexicon, IPCC_Lexicon, EPA_Lexicon, Wikipedia_Lexicon, BBC_Lexicon, UNDP_Lexicon]).drop_duplicates(subset = [\"Lexicon\"])\n",
    "get_metrics_df_2(Lexicon_df, Full_Lexicon, 1, 2, 0.2, \"Full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454b1a6c",
   "metadata": {},
   "source": [
    "## 3.2. Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c1d4f505",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3333333333333333\n",
      "Precision: 0.5\n",
      "Recall: 1.0\n",
      "F1 score: 0.6666666666666666\n",
      "Label_Hugging   no  All\n",
      "Target                 \n",
      "No             200  200\n",
      "Yes            100  100\n",
      "All            300  300\n",
      "\n",
      "\n",
      "Label_Hugging                      no  All\n",
      "Final_Climate_Change_Level_Label          \n",
      "High                               65   65\n",
      "Medium                             35   35\n",
      "No Climate                        109  109\n",
      "Small                              91   91\n",
      "All                               300  300\n"
     ]
    }
   ],
   "source": [
    "get_metrics_hugging_face(Lexicon_df, 'Text',\"climatebert/environmental-claims\",512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "477626e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7666666666666667\n",
      "Precision: 1.4615384615384615\n",
      "Recall: 19.0\n",
      "F1 score: 2.7142857142857144\n",
      "Label_Hugging   no  yes  All\n",
      "Target                      \n",
      "No             135   65  200\n",
      "Yes              5   95  100\n",
      "All            140  160  300\n",
      "\n",
      "\n",
      "Label_Hugging                      no  yes  All\n",
      "Final_Climate_Change_Level_Label               \n",
      "High                                0   65   65\n",
      "Medium                              5   30   35\n",
      "No Climate                         99   10  109\n",
      "Small                              36   55   91\n",
      "All                               140  160  300\n"
     ]
    }
   ],
   "source": [
    "get_metrics_hugging_face(Lexicon_df, \"Text\", \"climatebert/distilroberta-base-climate-detector\", 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53055d4e",
   "metadata": {},
   "source": [
    "# 4 Final Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "e657fc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Treshhold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.574713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.632353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.635514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.776667</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.637838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>Global_Change_IPCC</td>\n",
       "      <td>Relative Presences</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>Global_Change_IPCC</td>\n",
       "      <td>Relative Presences</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>Global_Change_IPCC</td>\n",
       "      <td>Relative Presences</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>Global_Change_IPCC</td>\n",
       "      <td>Relative Presences</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.482759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>Global_Change_IPCC</td>\n",
       "      <td>Relative Presences</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1638 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Lexicon           Technique  Treshhold  Accuracy  Precision  \\\n",
       "0          Global Change  Absolute Frequency        1.0  0.506667   0.403226   \n",
       "1          Global Change  Absolute Frequency        2.0  0.666667   0.500000   \n",
       "2          Global Change  Absolute Frequency        3.0  0.740000   0.596491   \n",
       "3          Global Change  Absolute Frequency        4.0  0.776667   0.694118   \n",
       "4          Global Change  Absolute Frequency        5.0  0.773333   0.766667   \n",
       "...                  ...                 ...        ...       ...        ...   \n",
       "1633  Global_Change_IPCC  Relative Presences        1.5  0.770000   0.754098   \n",
       "1634  Global_Change_IPCC  Relative Presences        1.6  0.760000   0.769231   \n",
       "1635  Global_Change_IPCC  Relative Presences        1.7  0.753333   0.770833   \n",
       "1636  Global_Change_IPCC  Relative Presences        1.8  0.750000   0.777778   \n",
       "1637  Global_Change_IPCC  Relative Presences        1.9  0.733333   0.750000   \n",
       "\n",
       "      Recall  F1 Score  \n",
       "0       1.00  0.574713  \n",
       "1       0.86  0.632353  \n",
       "2       0.68  0.635514  \n",
       "3       0.59  0.637838  \n",
       "4       0.46  0.575000  \n",
       "...      ...       ...  \n",
       "1633    0.46  0.571429  \n",
       "1634    0.40  0.526316  \n",
       "1635    0.37  0.500000  \n",
       "1636    0.35  0.482759  \n",
       "1637    0.30  0.428571  \n",
       "\n",
       "[1638 rows x 7 columns]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(\"Lexicon_Tagging_Metrics.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
