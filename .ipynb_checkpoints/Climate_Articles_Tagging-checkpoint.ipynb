{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "549a3d8c",
   "metadata": {},
   "source": [
    "# 0. Packages and Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7567ca2",
   "metadata": {},
   "source": [
    "## 0.1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57bd2f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, pipeline, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0aaaa2",
   "metadata": {},
   "source": [
    "## 0.2. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ce24a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-process text for lexicon based approaches\n",
    "def preprocess_text(text):\n",
    "    # remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # convert to lower case\n",
    "    text = text.lower()\n",
    "    # remove blank spaces\n",
    "    text = ' '.join(text.split())\n",
    "    # remove newline characters\n",
    "    text = text.replace('\\n', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b22206e",
   "metadata": {},
   "source": [
    "### Absolute Count with Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2495792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function that take the dataframe, lexicon and n-gram value (how many n-grams should be considered) and determine the \n",
    "#count of words in dataframe text that match the lexicon\n",
    "def count_lexicon_words_1(text_df, lexicon):\n",
    "    lexicon = lexicon[\"Lexicon\"]\n",
    "    count = []\n",
    "\n",
    "    for text in text_df[\"Text\"]:\n",
    "        lexicon_counts = 0\n",
    "\n",
    "        for word in lexicon:\n",
    "            lexicon_counts += text.lower().count(word.lower())\n",
    "        \n",
    "        count.append(lexicon_counts)\n",
    "        \n",
    "    text_df[\"Lexicon Count\"] = count\n",
    "    \n",
    "    return(text_df)\n",
    "\n",
    "#create a function that used the lexicon approach to determine with the target is yes or no\n",
    "def lexicon_target_classifier_1(df, treshold):\n",
    "    target = []\n",
    "    \n",
    "    count = df[\"Lexicon Count\"]\n",
    "    \n",
    "    for c in count:\n",
    "        if c < treshold:\n",
    "            target.append(\"No\")\n",
    "        else:\n",
    "            target.append(\"Yes\")\n",
    "            \n",
    "    df[\"Target Lexicon\"] = target\n",
    "    return(df)\n",
    "\n",
    "#Combine both functions to classify articles based on the lexicon\n",
    "def lexicon_climate_classifier_1(text_df, lexicon, treshold):\n",
    "    df = count_lexicon_words_1(text_df, lexicon)\n",
    "    \n",
    "    return(lexicon_target_classifier_1(df, treshold))\n",
    "\n",
    "def threshold_metrics_1(df_text, lexicon, min_treshhold, max_treshhold):\n",
    "    for i in range(min_treshhold, max_treshhold + 1):\n",
    "        df = lexicon_climate_classifier_1(df_text, lexicon, i)\n",
    "        cross_table = pd.crosstab(df['Target'], df['Target Lexicon'], margins=True)\n",
    "        \n",
    "        # calculate classification metrics using scikit-learn\n",
    "        accuracy = (cross_table.iloc[0, 0] + cross_table.iloc[1, 1]) / cross_table.loc['All', 'All'] if cross_table.shape == (3,3) else cross_table.iloc[1,0] / (cross_table.iloc[1, 0] + cross_table.iloc[0,0]) \n",
    "        precision = cross_table.iloc[1,1] / cross_table.iloc[0,1] if cross_table.iloc[0,1] != 0 else 0\n",
    "        recall = cross_table.iloc[1,1] / cross_table.iloc[1,0] if cross_table.iloc[1,0] != 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "        # print the metrics\n",
    "        print(\"Threshhold:\", i)\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall:\", recall)\n",
    "        print(\"F1 score:\", f1_score)\n",
    "        print(cross_table)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "def get_metrics_df_1(df_text, lexicon, min_treshhold, max_treshhold, Lexicon_name):    \n",
    "    Accuracy = []\n",
    "    Precision = []\n",
    "    Recall = []\n",
    "    F1_score = []\n",
    "    Name = []\n",
    "    Treshhold = []\n",
    "    Technique = []\n",
    "    \n",
    "    for i in range(min_treshhold, max_treshhold + 1):\n",
    "        df = lexicon_climate_classifier_1(df_text, lexicon, i)\n",
    "        cross_table = pd.crosstab(df['Target'], df['Target Lexicon'], margins=True)\n",
    "\n",
    "        # calculate classification metrics using scikit-learn\n",
    "        accuracy = (cross_table.iloc[0, 0] + cross_table.iloc[1, 1]) / cross_table.loc['All', 'All'] if cross_table.shape == (3,3) else cross_table.iloc[1,0] / (cross_table.iloc[1, 0] + cross_table.iloc[0,0]) \n",
    "        precision = cross_table.iloc[1,1] / cross_table.iloc[0,1] if cross_table.iloc[0,1] != 0 else 0\n",
    "        recall = cross_table.iloc[1,1] / cross_table.iloc[1,0] if cross_table.iloc[1,0] != 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "        \n",
    "        Accuracy.append(accuracy)\n",
    "        Precision.append(precision)\n",
    "        Recall.append(recall)\n",
    "        F1_score.append(f1_score)\n",
    "        Name.append(Lexicon_name)\n",
    "        Treshhold.append(i)\n",
    "        Technique.append(\"Absolute Frequency\")\n",
    "        \n",
    "    return(pd.DataFrame({\"Lexicon\" : Name, \"Technique\": Technique, \"Treshhold\" : Treshhold, \"Accuracy\" : Accuracy, \"Precision\" : Precision, \"Recall\" : Recall, \"F1 Score\" : F1_score}))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c69c28",
   "metadata": {},
   "source": [
    "### Relative Count with Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c3ca9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function that take the dataframe, lexicon and n-gram value (how many n-grams should be considered) and determine the \n",
    "#count of words in dataframe text that match the lexicon\n",
    "def count_lexicon_words_2(text_df, lexicon):\n",
    "    lexicon = lexicon[\"Lexicon\"]\n",
    "    count = []\n",
    "    \n",
    "    for text in text_df[\"Text\"]:\n",
    "        lexicon_counts = 0\n",
    "\n",
    "        for word in lexicon:\n",
    "            lexicon_counts += text.lower().count(word.lower())\n",
    "        \n",
    "        word_list = text.split() \n",
    "        word_count = len(word_list)\n",
    "        count.append((lexicon_counts/word_count)*100)\n",
    "\n",
    "    text_df[\"Lexicon Count\"] = count\n",
    "    \n",
    "    return(text_df)\n",
    "\n",
    "#create a function that used the lexicon approach to determine with the target is yes or no\n",
    "def lexicon_target_classifier_2(df, treshold):\n",
    "    target = []\n",
    "    \n",
    "    count = df[\"Lexicon Count\"]\n",
    "    \n",
    "    for c in count:\n",
    "        if c < treshold:\n",
    "            target.append(\"No\")\n",
    "        else:\n",
    "            target.append(\"Yes\")\n",
    "            \n",
    "    df[\"Target Lexicon\"] = target\n",
    "    return(df)\n",
    "\n",
    "#Combine both functions to classify articles based on the lexicon\n",
    "def lexicon_climate_classifier_2(text_df, lexicon, treshold):\n",
    "    df = count_lexicon_words_2(text_df, lexicon)\n",
    "    \n",
    "    return(lexicon_target_classifier_2(df, treshold))\n",
    "\n",
    "def threshold_metrics_2(df_text, lexicon, min_treshhold, max_treshhold, jump):\n",
    "    for num in range(int((max_treshhold - min_treshhold) / jump) + 1):\n",
    "        i = min_treshhold + num * jump\n",
    "        df = lexicon_climate_classifier_2(df_text, lexicon, i)\n",
    "        cross_table = pd.crosstab(df['Target'], df['Target Lexicon'], margins=True)\n",
    "\n",
    "        # calculate classification metrics using scikit-learn\n",
    "        accuracy = (cross_table.iloc[0, 0] + cross_table.iloc[1, 1]) / cross_table.loc['All', 'All'] if cross_table.shape == (3,3) else cross_table.iloc[1,0] / (cross_table.iloc[1, 0] + cross_table.iloc[0,0]) \n",
    "        precision = cross_table.iloc[1,1] / cross_table.iloc[0,1] if cross_table.iloc[0,1] != 0 else 0\n",
    "        recall = cross_table.iloc[1,1] / cross_table.iloc[1,0] if cross_table.iloc[1,0] != 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "        # print the metrics\n",
    "        print(\"Threshhold:\", i)\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall:\", recall)\n",
    "        print(\"F1 score:\", f1_score)\n",
    "        print(cross_table)\n",
    "        print(\"\\n\")\n",
    "\n",
    "def get_metrics_df_2(df_text, lexicon, min_treshhold, max_treshhold, jump, Lexicon_name):    \n",
    "    Accuracy = []\n",
    "    Precision = []\n",
    "    Recall = []\n",
    "    F1_score = []\n",
    "    Name = []\n",
    "    Treshhold = []\n",
    "    Technique = []\n",
    "    \n",
    "    for num in range(int((max_treshhold - min_treshhold) / jump) + 1):\n",
    "        i = min_treshhold + num * jump\n",
    "        df = lexicon_climate_classifier_2(df_text, lexicon, i)\n",
    "        cross_table = pd.crosstab(df['Target'], df['Target Lexicon'], margins=True)\n",
    "\n",
    "        # calculate classification metrics using scikit-learn\n",
    "        accuracy = (cross_table.iloc[0, 0] + cross_table.iloc[1, 1]) / cross_table.loc['All', 'All'] if cross_table.shape == (3,3) else cross_table.iloc[1,0] / (cross_table.iloc[1, 0] + cross_table.iloc[0,0]) \n",
    "        precision = cross_table.iloc[1,1] / cross_table.iloc[0,1] if cross_table.iloc[0,1] != 0 else 0\n",
    "        recall = cross_table.iloc[1,1] / cross_table.iloc[1,0] if cross_table.iloc[1,0] != 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "        \n",
    "        Accuracy.append(accuracy)\n",
    "        Precision.append(precision)\n",
    "        Recall.append(recall)\n",
    "        F1_score.append(f1_score)\n",
    "        Name.append(Lexicon_name)\n",
    "        Treshhold.append(i)\n",
    "        Technique.append(\"Relative Frequency\")\n",
    "        \n",
    "    return(pd.DataFrame({\"Lexicon\" : Name, \"Technique\": Technique, \"Treshhold\" : Treshhold, \"Accuracy\" : Accuracy, \"Precision\" : Precision, \"Recall\" : Recall, \"F1 Score\" : F1_score}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f4d81d",
   "metadata": {},
   "source": [
    "### Absolute Term Presences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6226be1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function that take the dataframe, lexicon and n-gram value (how many n-grams should be considered) and determine the \n",
    "#count of words in dataframe text that match the lexicon\n",
    "def count_lexicon_words_3(text_df, lexicon):\n",
    "    lexicon = lexicon[\"Lexicon\"]\n",
    "    count = []\n",
    "\n",
    "    for text in text_df[\"Text\"]:\n",
    "        lexicon_counts = 0\n",
    "\n",
    "        for word in lexicon:\n",
    "            if text.lower().count(word.lower()) > 0:\n",
    "                lexicon_counts += 1\n",
    "        \n",
    "        count.append(lexicon_counts)\n",
    "        \n",
    "    text_df[\"Lexicon Count\"] = count\n",
    "    \n",
    "    return text_df\n",
    "\n",
    "#create a function that used the lexicon approach to determine with the target is yes or no\n",
    "def lexicon_target_classifier_3(df, treshold):\n",
    "    target = []\n",
    "    \n",
    "    count = df[\"Lexicon Count\"]\n",
    "    \n",
    "    for c in count:\n",
    "        if c < treshold:\n",
    "            target.append(\"No\")\n",
    "        else:\n",
    "            target.append(\"Yes\")\n",
    "            \n",
    "    df[\"Target Lexicon\"] = target\n",
    "    return(df)\n",
    "\n",
    "#Combine both functions to classify articles based on the lexicon\n",
    "def lexicon_climate_classifier_3(text_df, lexicon, treshold):\n",
    "    df = count_lexicon_words_3(text_df, lexicon)\n",
    "    \n",
    "    return(lexicon_target_classifier_3(df, treshold))\n",
    "\n",
    "def threshold_metrics_3(df_text, lexicon, min_treshhold, max_treshhold):\n",
    "    for i in range(min_treshhold, max_treshhold + 1):\n",
    "        df = lexicon_climate_classifier_3(df_text, lexicon, i)\n",
    "        cross_table = pd.crosstab(df['Target'], df['Target Lexicon'], margins=True)\n",
    "        \n",
    "        # calculate classification metrics using scikit-learn\n",
    "        accuracy = (cross_table.iloc[0, 0] + cross_table.iloc[1, 1]) / cross_table.loc['All', 'All'] if cross_table.shape == (3,3) else cross_table.iloc[1,0] / (cross_table.iloc[1, 0] + cross_table.iloc[0,0]) \n",
    "        precision = cross_table.iloc[1,1] / cross_table.iloc[0,1] if cross_table.iloc[0,1] != 0 else 0\n",
    "        recall = cross_table.iloc[1,1] / cross_table.iloc[1,0] if cross_table.iloc[1,0] != 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "        # print the metrics\n",
    "        print(\"Threshhold:\", i)\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall:\", recall)\n",
    "        print(\"F1 score:\", f1_score)\n",
    "        print(cross_table)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "def get_metrics_df_3(df_text, lexicon, min_treshhold, max_treshhold, Lexicon_name):    \n",
    "    Accuracy = []\n",
    "    Precision = []\n",
    "    Recall = []\n",
    "    F1_score = []\n",
    "    Name = []\n",
    "    Treshhold = []\n",
    "    Technique = []\n",
    "    \n",
    "    for i in range(min_treshhold, max_treshhold + 1):\n",
    "        df = lexicon_climate_classifier_3(df_text, lexicon, i)\n",
    "        cross_table = pd.crosstab(df['Target'], df['Target Lexicon'], margins=True)\n",
    "\n",
    "        # calculate classification metrics using scikit-learn\n",
    "        accuracy = (cross_table.iloc[0, 0] + cross_table.iloc[1, 1]) / cross_table.loc['All', 'All'] if cross_table.shape == (3,3) else cross_table.iloc[1,0] / (cross_table.iloc[1, 0] + cross_table.iloc[0,0]) \n",
    "        precision = cross_table.iloc[1,1] / cross_table.iloc[0,1] if cross_table.iloc[0,1] != 0 else 0\n",
    "        recall = cross_table.iloc[1,1] / cross_table.iloc[1,0] if cross_table.iloc[1,0] != 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "        \n",
    "        Accuracy.append(accuracy)\n",
    "        Precision.append(precision)\n",
    "        Recall.append(recall)\n",
    "        F1_score.append(f1_score)\n",
    "        Name.append(Lexicon_name)\n",
    "        Treshhold.append(i)\n",
    "        Technique.append(\"Absolute Presences\")\n",
    "        \n",
    "    return(pd.DataFrame({\"Lexicon\" : Name, \"Technique\": Technique, \"Treshhold\" : Treshhold, \"Accuracy\" : Accuracy, \"Precision\" : Precision, \"Recall\" : Recall, \"F1 Score\" : F1_score}))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dd8d36",
   "metadata": {},
   "source": [
    "### Relative Term Presences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f82d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function that take the dataframe, lexicon and n-gram value (how many n-grams should be considered) and determine the \n",
    "#count of words in dataframe text that match the lexicon\n",
    "def count_lexicon_words_4(text_df, lexicon):\n",
    "    lexicon = lexicon[\"Lexicon\"]\n",
    "    count = []\n",
    "\n",
    "    for text in text_df[\"Text\"]:\n",
    "        lexicon_counts = 0\n",
    "\n",
    "        for word in lexicon:\n",
    "            if text.lower().count(word.lower()) > 0:\n",
    "                lexicon_counts += 1\n",
    "        \n",
    "        count.append(lexicon_counts)\n",
    "        \n",
    "    text_df[\"Lexicon Count\"] = count\n",
    "    \n",
    "    return text_df\n",
    "\n",
    "#create a function that used the lexicon approach to determine with the target is yes or no\n",
    "def lexicon_target_classifier_4(df, treshold):\n",
    "    target = []\n",
    "    \n",
    "    count = df[\"Lexicon Count\"]\n",
    "    \n",
    "    for c in count:\n",
    "        if c < treshold:\n",
    "            target.append(\"No\")\n",
    "        else:\n",
    "            target.append(\"Yes\")\n",
    "            \n",
    "    df[\"Target Lexicon\"] = target\n",
    "    return(df)\n",
    "\n",
    "#Combine both functions to classify articles based on the lexicon\n",
    "def lexicon_climate_classifier_4(text_df, lexicon, treshold):\n",
    "    df = count_lexicon_words_4(text_df, lexicon)\n",
    "    \n",
    "    return(lexicon_target_classifier_4(df, treshold))\n",
    "\n",
    "def threshold_metrics_4(df_text, lexicon, min_treshhold, max_treshhold, jump):\n",
    "    for num in range(int((max_treshhold - min_treshhold) / jump) + 1):\n",
    "        i = min_treshhold + num * jump\n",
    "        df = lexicon_climate_classifier_4(df_text, lexicon, i)\n",
    "        cross_table = pd.crosstab(df['Target'], df['Target Lexicon'], margins=True)\n",
    "\n",
    "        # calculate classification metrics using scikit-learn\n",
    "        accuracy = (cross_table.iloc[0, 0] + cross_table.iloc[1, 1]) / cross_table.loc['All', 'All'] if cross_table.shape == (3,3) else cross_table.iloc[1,0] / (cross_table.iloc[1, 0] + cross_table.iloc[0,0]) \n",
    "        precision = cross_table.iloc[1,1] / cross_table.iloc[0,1] if cross_table.iloc[0,1] != 0 else 0\n",
    "        recall = cross_table.iloc[1,1] / cross_table.iloc[1,0] if cross_table.iloc[1,0] != 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "        # print the metrics\n",
    "        print(\"Threshhold:\", i)\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall:\", recall)\n",
    "        print(\"F1 score:\", f1_score)\n",
    "        print(cross_table)\n",
    "        print(\"\\n\")\n",
    "\n",
    "def get_metrics_df_4(df_text, lexicon, min_treshhold, max_treshhold, jump, Lexicon_name):    \n",
    "    Accuracy = []\n",
    "    Precision = []\n",
    "    Recall = []\n",
    "    F1_score = []\n",
    "    Name = []\n",
    "    Treshhold = []\n",
    "    Technique = []\n",
    "    \n",
    "    for num in range(int((max_treshhold - min_treshhold) / jump) + 1):\n",
    "        i = min_treshhold + num * jump\n",
    "        df = lexicon_climate_classifier_4(df_text, lexicon, i)\n",
    "        cross_table = pd.crosstab(df['Target'], df['Target Lexicon'], margins=True)\n",
    "\n",
    "        # calculate classification metrics using scikit-learn\n",
    "        accuracy = (cross_table.iloc[0, 0] + cross_table.iloc[1, 1]) / cross_table.loc['All', 'All'] if cross_table.shape == (3,3) else cross_table.iloc[1,0] / (cross_table.iloc[1, 0] + cross_table.iloc[0,0]) \n",
    "        precision = cross_table.iloc[1,1] / cross_table.iloc[0,1] if cross_table.iloc[0,1] != 0 else 0\n",
    "        recall = cross_table.iloc[1,1] / cross_table.iloc[1,0] if cross_table.iloc[1,0] != 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "        \n",
    "        Accuracy.append(accuracy)\n",
    "        Precision.append(precision)\n",
    "        Recall.append(recall)\n",
    "        F1_score.append(f1_score)\n",
    "        Name.append(Lexicon_name)\n",
    "        Treshhold.append(i)\n",
    "        Technique.append(\"Relative Presences\")\n",
    "        \n",
    "    return(pd.DataFrame({\"Lexicon\" : Name, \"Technique\": Technique, \"Treshhold\" : Treshhold, \"Accuracy\" : Accuracy, \"Precision\" : Precision, \"Recall\" : Recall, \"F1 Score\" : F1_score}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358383a2",
   "metadata": {},
   "source": [
    "Accuracy: This metric measures the overall performance of a model. It is defined as the number of correct predictions divided by the total number of predictions. Accuracy is a good metric to use when the classes are roughly balanced, meaning there are about the same number of positive and negative examples in the dataset.\n",
    "\n",
    "Precision: This metric measures how many of the positive predictions made by a model are actually correct. It is defined as the number of true positives divided by the total number of positive predictions. Precision is a good metric to use when we care more about avoiding false positives than false negatives.\n",
    "\n",
    "Recall: This metric measures how many of the positive examples in the dataset are correctly predicted by the model. It is defined as the number of true positives divided by the total number of actual positive examples. Recall is a good metric to use when we care more about avoiding false negatives than false positives.\n",
    "\n",
    "F1 score: This metric is a weighted average of precision and recall, where the weight is determined by the beta parameter. The most common value for beta is 1, which gives equal weight to precision and recall. The F1 score is a good metric to use when we want to balance precision and recall, and when the classes are imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc10b67",
   "metadata": {},
   "source": [
    "# 1. Import Label Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b08d6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Link</th>\n",
       "      <th>Sentiment_Label</th>\n",
       "      <th>Sentiment_Label_R</th>\n",
       "      <th>Level_Climate_Change_Topic</th>\n",
       "      <th>Level_Climate_Change_Topic_R</th>\n",
       "      <th>Final_Climate_Change_Level_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>More than a dozen state attorneys general gath...</td>\n",
       "      <td>https://www.washingtonpost.com/news/energy-env...</td>\n",
       "      <td>+1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sen. Jeff Merkley of Oregon endorsed Bernie S...</td>\n",
       "      <td>http://www.wsj.com/articles/campaign-wire-1460...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Small</td>\n",
       "      <td>Small</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When Carmen Luna moved to a neighborhood on t...</td>\n",
       "      <td>https://www.wsj.com/articles/mexico-city-strug...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As ocean warming continues to trigger widespre...</td>\n",
       "      <td>https://www.washingtonpost.com/national/health...</td>\n",
       "      <td>+1</td>\n",
       "      <td>-1</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PG&amp;E Corp. told California regulators that it...</td>\n",
       "      <td>https://www.wsj.com/articles/pg-e-equipment-mi...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  More than a dozen state attorneys general gath...   \n",
       "1   Sen. Jeff Merkley of Oregon endorsed Bernie S...   \n",
       "2   When Carmen Luna moved to a neighborhood on t...   \n",
       "3  As ocean warming continues to trigger widespre...   \n",
       "4   PG&E Corp. told California regulators that it...   \n",
       "\n",
       "                                                Link Sentiment_Label  \\\n",
       "0  https://www.washingtonpost.com/news/energy-env...              +1   \n",
       "1  http://www.wsj.com/articles/campaign-wire-1460...               0   \n",
       "2  https://www.wsj.com/articles/mexico-city-strug...              -1   \n",
       "3  https://www.washingtonpost.com/national/health...              +1   \n",
       "4  https://www.wsj.com/articles/pg-e-equipment-mi...              -1   \n",
       "\n",
       "  Sentiment_Label_R Level_Climate_Change_Topic Level_Climate_Change_Topic_R  \\\n",
       "0                -1                     Medium                       Medium   \n",
       "1                 0                      Small                        Small   \n",
       "2                -1                     Medium                       Medium   \n",
       "3                -1                       High                         High   \n",
       "4                -1                     Medium                       Medium   \n",
       "\n",
       "  Final_Climate_Change_Level_Label  \n",
       "0                           Medium  \n",
       "1                            Small  \n",
       "2                           Medium  \n",
       "3                             High  \n",
       "4                           Medium  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_climate_df = pd.read_parquet(\"Climate_Labels_Dataset.parquet\")\n",
    "tag_climate_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c9d1d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only keep the required columns\n",
    "tag_climate_df = tag_climate_df[[\"Text\", \"Final_Climate_Change_Level_Label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2ee616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the tabel\n",
    "tag_climate_df['Final_Climate_Change_Level_Label'] = tag_climate_df['Final_Climate_Change_Level_Label'].str.strip()\n",
    "tag_climate_df[tag_climate_df[\"Final_Climate_Change_Level_Label\"] == \"NA\"] = \"Na\"\n",
    "tag_climate_df[tag_climate_df[\"Final_Climate_Change_Level_Label\"] == \"0\"] = \"Na\"\n",
    "tag_climate_df[\"Target\"] = tag_climate_df[\"Final_Climate_Change_Level_Label\"].apply(lambda x: \"Yes\" if x in [\"High\", \"Medium\"] else \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "add6c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_labels_hms = tag_climate_df.groupby(\"Final_Climate_Change_Level_Label\")[\"Text\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c689ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Final_Climate_Change_Level_Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>High</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Medium</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Na</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Small</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Final_Climate_Change_Level_Label  Text\n",
       "0                             High    65\n",
       "1                           Medium    35\n",
       "2                               Na   109\n",
       "3                            Small    91"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview_labels_hms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be23a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_labels = tag_climate_df.groupby(\"Target\")[\"Text\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86308d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Target  Text\n",
       "0     No   200\n",
       "1    Yes   100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acf33a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#overview_labels_hms.to_csv(\"C:/Users/Boedt/OneDrive/Bureaublad/R Thesis/overview_tag_labels_hms\", index = False)\n",
    "#overview_labels.to_csv(\"C:/Users/Boedt/OneDrive/Bureaublad/R Thesis/overview_tag_labels\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516660b2",
   "metadata": {},
   "source": [
    "# 2. Taggers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2a7077",
   "metadata": {},
   "source": [
    "## 2.1. Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31249337",
   "metadata": {},
   "source": [
    "### Global Change Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c15452",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54704fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100-year flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>emissions scenario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adaptation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adaptation science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive capacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>vector</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>vulnerability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>vulnerability assessment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>water security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>water stress</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Lexicon\n",
       "0              100-year flood\n",
       "1          emissions scenario\n",
       "2                  adaptation\n",
       "3          adaptation science\n",
       "4           adaptive capacity\n",
       "..                        ...\n",
       "101                   vector \n",
       "102             vulnerability\n",
       "103  vulnerability assessment\n",
       "104            water security\n",
       "105              water stress\n",
       "\n",
       "[106 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the lexicon\n",
    "Global_Change_Lexicon = pd.read_excel('lexicons-used.xlsx', sheet_name = \"Global Change\", header = None)\n",
    "Global_Change_Lexicon.columns = [\"Lexicon\"]\n",
    "Global_Change_Lexicon = Global_Change_Lexicon.drop_duplicates().reset_index(drop = True)\n",
    "Global_Change_Lexicon[\"Lexicon\"] = Global_Change_Lexicon[\"Lexicon\"].str.lower()\n",
    "\n",
    "Global_Change_Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d26ff50",
   "metadata": {},
   "source": [
    "### IPCC Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800c5ab8",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c41bb7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acceptability of policy or system change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adaptability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adaptation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adaptation behaviour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptation limits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>sd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>sdgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>tcre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>tod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>unfccc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Lexicon\n",
       "0    acceptability of policy or system change\n",
       "1                                adaptability\n",
       "2                                  adaptation\n",
       "3                        adaptation behaviour\n",
       "4                           adaptation limits\n",
       "..                                        ...\n",
       "402                                        sd\n",
       "403                                      sdgs\n",
       "404                                      tcre\n",
       "405                                       tod\n",
       "406                                    unfccc\n",
       "\n",
       "[407 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the lexicon\n",
    "IPCC_Lexicon = pd.read_excel('lexicons-used.xlsx', sheet_name = \"IPCC\", header = None)\n",
    "IPCC_Lexicon.columns = [\"Lexicon\"]\n",
    "IPCC_Lexicon = IPCC_Lexicon.drop_duplicates().reset_index(drop = True)\n",
    "IPCC_Lexicon[\"Lexicon\"] = IPCC_Lexicon[\"Lexicon\"].str.lower()\n",
    "\n",
    "IPCC_Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb16e34",
   "metadata": {},
   "source": [
    "### Wikipedia Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90610cf6",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "335d527b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100,000-year problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adaptation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>additionality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>albedo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anoxic event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>volcanism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>water vapor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>world climate report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>younger dryas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Lexicon\n",
       "0    100,000-year problem\n",
       "1              adaptation\n",
       "2           additionality\n",
       "3                  albedo\n",
       "4            anoxic event\n",
       "..                    ...\n",
       "159             volcanism\n",
       "160           water vapor\n",
       "161               weather\n",
       "162  world climate report\n",
       "163         younger dryas\n",
       "\n",
       "[164 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the lexicon\n",
    "Wikipedia_Lexicon = pd.read_excel('lexicons-used.xlsx', sheet_name = \"Wikipedia\", header = None)\n",
    "Wikipedia_Lexicon = pd.DataFrame(Wikipedia_Lexicon[0])\n",
    "Wikipedia_Lexicon.columns = [\"Lexicon\"]\n",
    "Wikipedia_Lexicon = Wikipedia_Lexicon.drop_duplicates().reset_index(drop = True)\n",
    "Wikipedia_Lexicon[\"Lexicon\"] = Wikipedia_Lexicon[\"Lexicon\"].str.lower()\n",
    "\n",
    "Wikipedia_Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c8a3be",
   "metadata": {},
   "source": [
    "### EPA Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638f81be",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e93d019b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abrupt climate change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adaptation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adaptive capacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aerosols</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afforestation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>pfcs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>sf6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>o3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>uv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>unfccc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Lexicon\n",
       "0    abrupt climate change\n",
       "1               adaptation\n",
       "2        adaptive capacity\n",
       "3                 aerosols\n",
       "4            afforestation\n",
       "..                     ...\n",
       "171                   pfcs\n",
       "172                    sf6\n",
       "173                     o3\n",
       "174                     uv\n",
       "175                 unfccc\n",
       "\n",
       "[176 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the lexicon\n",
    "EPA_Lexicon = pd.read_excel('lexicons-used.xlsx', sheet_name = \"EPA\", header = None)\n",
    "EPA_Lexicon = pd.DataFrame(EPA_Lexicon[0])\n",
    "EPA_Lexicon.columns = [\"Lexicon\"]\n",
    "EPA_Lexicon = EPA_Lexicon.drop_duplicates().reset_index(drop = True)\n",
    "EPA_Lexicon[\"Lexicon\"] = EPA_Lexicon[\"Lexicon\"].str.lower()\n",
    "\n",
    "EPA_Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e47f8",
   "metadata": {},
   "source": [
    "### BBC Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b284bd04",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ea125ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abrupt climate change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adaptation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adaptive capacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aerosols</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afforestation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>pfcs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>sf6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>o3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>uv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>unfccc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Lexicon\n",
       "0    abrupt climate change\n",
       "1               adaptation\n",
       "2        adaptive capacity\n",
       "3                 aerosols\n",
       "4            afforestation\n",
       "..                     ...\n",
       "171                   pfcs\n",
       "172                    sf6\n",
       "173                     o3\n",
       "174                     uv\n",
       "175                 unfccc\n",
       "\n",
       "[176 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the lexicon\n",
    "BBC_Lexicon = pd.read_excel('lexicons-used.xlsx', sheet_name = \"EPA\", header = None)\n",
    "BBC_Lexicon = pd.DataFrame(BBC_Lexicon[0])\n",
    "BBC_Lexicon.columns = [\"Lexicon\"]\n",
    "BBC_Lexicon = BBC_Lexicon.drop_duplicates().reset_index(drop = True)\n",
    "BBC_Lexicon[\"Lexicon\"] = BBC_Lexicon[\"Lexicon\"].str.lower()\n",
    "\n",
    "BBC_Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aade8b",
   "metadata": {},
   "source": [
    "### UNDP Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bae000f",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f66d51e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>climate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>greenhouse gases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>greenhouse gas emmisions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>global warming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>climate change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>climate crisis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>feedback loop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tipping point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>climate overshoot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mitigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>adaptation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>resilience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>carbon footprint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>climate justice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>nature-based solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>indigenous knowledge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>loss and damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>climate security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>climate finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>net zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>decarbonization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>renewable energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>carbon sink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>carbon removal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>carbon capture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>carbon markets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>regenerative agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>reforestation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>afforestation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>rewilding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>circular economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>blue economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>green jobs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>greenwashing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>just transition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>unfccc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>conference of the parties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>cop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>paris agreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>nationally determined contributions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>transparent reporting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>transparency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>national adaptation plans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>long-term strategies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>redd+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>intergovernmental panel on climate change</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Lexicon\n",
       "0                                     weather\n",
       "1                                     climate\n",
       "2                            greenhouse gases\n",
       "3                    greenhouse gas emmisions\n",
       "4                              global warming\n",
       "5                              climate change\n",
       "6                              climate crisis\n",
       "7                               feedback loop\n",
       "8                               tipping point\n",
       "9                           climate overshoot\n",
       "10                                 mitigation\n",
       "11                                 adaptation\n",
       "12                                 resilience\n",
       "13                           carbon footprint\n",
       "14                            climate justice\n",
       "15                     nature-based solutions\n",
       "16                       indigenous knowledge\n",
       "17                            loss and damage\n",
       "18                           climate security\n",
       "19                            climate finance\n",
       "20                                   net zero\n",
       "21                            decarbonization\n",
       "22                           renewable energy\n",
       "23                                carbon sink\n",
       "24                             carbon removal\n",
       "25                             carbon capture\n",
       "26                             carbon markets\n",
       "27                   regenerative agriculture\n",
       "28                              reforestation\n",
       "29                              afforestation\n",
       "30                                  rewilding\n",
       "31                           circular economy\n",
       "32                               blue economy\n",
       "33                                 green jobs\n",
       "34                               greenwashing\n",
       "35                            just transition\n",
       "36                                     unfccc\n",
       "37                  conference of the parties\n",
       "38                                        cop\n",
       "39                            paris agreement\n",
       "40        nationally determined contributions\n",
       "41                      transparent reporting\n",
       "42                               transparency\n",
       "43                  national adaptation plans\n",
       "44                       long-term strategies\n",
       "45                                      redd+\n",
       "46  intergovernmental panel on climate change"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the lexicon\n",
    "UNDP_Lexicon = pd.read_excel('lexicons-used.xlsx', sheet_name = \"UNDP\", header = None)\n",
    "UNDP_Lexicon = pd.DataFrame(UNDP_Lexicon[0])\n",
    "UNDP_Lexicon.columns = [\"Lexicon\"]\n",
    "UNDP_Lexicon = UNDP_Lexicon.drop_duplicates().reset_index(drop = True)\n",
    "UNDP_Lexicon[\"Lexicon\"] = UNDP_Lexicon[\"Lexicon\"].str.lower()\n",
    "\n",
    "UNDP_Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f304b018",
   "metadata": {},
   "source": [
    "## 2.2. Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "158a8097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(df_with_text, name, model_name, max_lenght_input=-1):\n",
    "    data_in_list = df_with_text[name].tolist()\n",
    "    tokenizer_sum = AutoTokenizer.from_pretrained(model_name)\n",
    "    model_sum = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    summarizer = pipeline('summarization', model=model_sum, tokenizer = tokenizer_sum) \n",
    "\n",
    "    if max_lenght_input>=0:\n",
    "        df_with_text['summary'] = summarizer(data_in_list, max_length=max_lenght_input)\n",
    "\n",
    "    else:\n",
    "        df_with_text['summary'] = summarizer(data_in_list)\n",
    "\n",
    "def classification(df_with_text, name, model_name, max_lenght_input=-1):\n",
    "    data_in_list = df_with_text[name].tolist()\n",
    "    tokenizer_clas = AutoTokenizer.from_pretrained(model_name)\n",
    "    model_clas = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    classification = pipeline('text-classification', model=model_clas, tokenizer = tokenizer_clas) \n",
    "\n",
    "    if max_lenght_input>=0:\n",
    "        df_with_text['classification'] = classification(data_in_list, max_length=max_lenght_input, truncation=True)\n",
    "\n",
    "    else:\n",
    "        df_with_text['classification'] = classification(data_in_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9aa8d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification(Lexicon_df, 'Text',\"climatebert/environmental-claims\",512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53737e8c",
   "metadata": {},
   "source": [
    "# 3. Testen Taggers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b72304",
   "metadata": {},
   "source": [
    "## 3.1. Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cca33293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a separate df with the specific cleaning for the lexicons\n",
    "Lexicon_df = tag_climate_df.copy()\n",
    "Lexicon_df[\"Text\"] = Lexicon_df[\"Text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bc8d45",
   "metadata": {},
   "source": [
    "### 3.1.1. One Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61e0d1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Change Lexicon\n",
    "Global_Change_df_1 = get_metrics_df_1(Lexicon_df, Global_Change_Lexicon, 0, 20, \"Global Change\")\n",
    "Global_Change_df_2 = get_metrics_df_2(Lexicon_df, Global_Change_Lexicon, 0, 2, 0.1, \"Global Change\")\n",
    "Global_Change_df_3 = get_metrics_df_3(Lexicon_df, Global_Change_Lexicon, 0, 20, \"Global Change\")\n",
    "Global_Change_df_4 = get_metrics_df_4(Lexicon_df, Global_Change_Lexicon, 0, 2, 0.1, \"Global Change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebbd51ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Global_Change_df = pd.concat([Global_Change_df_1, Global_Change_df_2, Global_Change_df_3, Global_Change_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b48f7730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IPCC Lexicon\n",
    "IPCC_df_1 = get_metrics_df_1(Lexicon_df, IPCC_Lexicon, 0, 20, \"IPCC\")\n",
    "IPCC_df_2 = get_metrics_df_2(Lexicon_df, IPCC_Lexicon, 0, 2, 0.1, \"IPCC\")\n",
    "IPCC_df_3 = get_metrics_df_3(Lexicon_df, IPCC_Lexicon, 0, 20, \"IPCC\")\n",
    "IPCC_df_4 = get_metrics_df_4(Lexicon_df, IPCC_Lexicon, 0, 2, 0.1, \"IPCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83e242f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPCC_df = pd.concat([IPCC_df_1, IPCC_df_2, IPCC_df_3, IPCC_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5c72d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wikipedia Lexicon\n",
    "Wikipedia_df_1 = get_metrics_df_1(Lexicon_df, Wikipedia_Lexicon, 0, 20, \"Wikipedia\")\n",
    "Wikipedia_df_2 = get_metrics_df_2(Lexicon_df, Wikipedia_Lexicon, 0, 2, 0.1, \"Wikipedia\")\n",
    "Wikipedia_df_3 = get_metrics_df_3(Lexicon_df, Wikipedia_Lexicon, 0, 20, \"Wikipedia\")\n",
    "Wikipedia_df_4 = get_metrics_df_4(Lexicon_df, Wikipedia_Lexicon, 0, 2, 0.1, \"Wikipedia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9e1474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wikipedia_df = pd.concat([Wikipedia_df_1, Wikipedia_df_2, Wikipedia_df_3, Wikipedia_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9caa4baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPA Lexicon\n",
    "EPA_df_1 = get_metrics_df_1(Lexicon_df, EPA_Lexicon, 0, 20, \"EPA\")\n",
    "EPA_df_2 = get_metrics_df_2(Lexicon_df, EPA_Lexicon, 0, 2, 0.1, \"EPA\")\n",
    "EPA_df_3 = get_metrics_df_3(Lexicon_df, EPA_Lexicon, 0, 20, \"EPA\")\n",
    "EPA_df_4 = get_metrics_df_4(Lexicon_df, EPA_Lexicon, 0, 2, 0.1, \"EPA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "920067f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPA_df = pd.concat([EPA_df_1, EPA_df_2, EPA_df_3, EPA_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a445db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BBC Lexicon\n",
    "BBC_df_1 = get_metrics_df_1(Lexicon_df, BBC_Lexicon, 0, 20, \"BBC\")\n",
    "BBC_df_2 = get_metrics_df_2(Lexicon_df, BBC_Lexicon, 0, 2, 0.1, \"BBC\")\n",
    "BBC_df_3 = get_metrics_df_3(Lexicon_df, BBC_Lexicon, 0, 20, \"BBC\")\n",
    "BBC_df_4 = get_metrics_df_4(Lexicon_df, BBC_Lexicon, 0, 2, 0.1, \"BBC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec49a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "BBC_df = pd.concat([BBC_df_1, BBC_df_2, BBC_df_3, BBC_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8f351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNDP Lexicon\n",
    "UNDP_df_1 = get_metrics_df_1(Lexicon_df, UNDP_Lexicon, 0, 20, \"UNDP\")\n",
    "UNDP_df_2 = get_metrics_df_2(Lexicon_df, UNDP_Lexicon, 0, 2, 0.1, \"UNDP\")\n",
    "UNDP_df_3 = get_metrics_df_3(Lexicon_df, UNDP_Lexicon, 0, 20, \"UNDP\")\n",
    "UNDP_df_4 = get_metrics_df_4(Lexicon_df, UNDP_Lexicon, 0, 2, 0.1, \"UNDP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da66cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNDP_df = pd.concat([UNDP_df_1, UNDP_df_2, UNDP_df_3, UNDP_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917f4664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all lexicons together\n",
    "Lexicon_df_1 = pd.concat([Global_Change_df, IPCC_df, Wikipedia_df, EPA_df, BBC_df, UNDP_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea244ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lexicon_df_1.sort_values(\"Accuracy\", ascending = False).reset_index(drop = True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a074a4f",
   "metadata": {},
   "source": [
    "### 3.1.2. Two Lexicons Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "94ae84f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNDP and EPA\n",
    "EPA_UNDP_Lexicon = pd.concat([EPA_Lexicon, UNDP_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "EPA_UNDP_df_1 = get_metrics_df_1(Lexicon_df, EPA_UNDP_Lexicon, 0, 20, \"UNDP_EPA\")\n",
    "EPA_UNDP_df_2 = get_metrics_df_2(Lexicon_df, EPA_UNDP_Lexicon, 0, 2, 0.1, \"UNDP_EPA\")\n",
    "EPA_UNDP_df_3 = get_metrics_df_3(Lexicon_df, EPA_UNDP_Lexicon, 0, 20, \"UNDP_EPA\")\n",
    "EPA_UNDP_df_4 = get_metrics_df_4(Lexicon_df, EPA_UNDP_Lexicon, 0, 2, 0.1, \"UNDP_EPA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ccf1520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPA_UNDP_df = pd.concat([EPA_UNDP_df_1, EPA_UNDP_df_2, EPA_UNDP_df_3, EPA_UNDP_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "418d74b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNDP and BBC\n",
    "BBC_UNDP_Lexicon = pd.concat([BBC_Lexicon, UNDP_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "BBC_UNDP_df_1 = get_metrics_df_1(Lexicon_df, BBC_UNDP_Lexicon, 0, 20, \"BBC_UNDP\")\n",
    "BBC_UNDP_df_2 = get_metrics_df_2(Lexicon_df, BBC_UNDP_Lexicon, 0, 2, 0.1, \"BBC_UNDP\")\n",
    "BBC_UNDP_df_3 = get_metrics_df_3(Lexicon_df, BBC_UNDP_Lexicon, 0, 20, \"BBC_UNDP\")\n",
    "BBC_UNDP_df_4 = get_metrics_df_4(Lexicon_df, BBC_UNDP_Lexicon, 0, 2, 0.1, \"BBC_UNDP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "56595876",
   "metadata": {},
   "outputs": [],
   "source": [
    "BBC_UNDP_df = pd.concat([BBC_UNDP_df_1, BBC_UNDP_df_2, BBC_UNDP_df_3, BBC_UNDP_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a6dc494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNDP and Global Change \n",
    "UNDP_Global_Change_Lexicon = pd.concat([Global_Change_Lexicon, UNDP_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "UNDP_Global_Change_df_1 = get_metrics_df_1(Lexicon_df, UNDP_Global_Change_Lexicon, 0, 20, \"UNDP_Global_Change\")\n",
    "UNDP_Global_Change_df_2 = get_metrics_df_2(Lexicon_df, UNDP_Global_Change_Lexicon, 0, 2, 0.1, \"UNDP_Global_Change\")\n",
    "UNDP_Global_Change_df_3 = get_metrics_df_3(Lexicon_df, UNDP_Global_Change_Lexicon, 0, 20, \"UNDP_Global_Change\")\n",
    "UNDP_Global_Change_df_4 = get_metrics_df_4(Lexicon_df, UNDP_Global_Change_Lexicon, 0, 2, 0.1, \"UNDP_Global_Change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f0cbdbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "Global_Change_UNDP_df = pd.concat([UNDP_Global_Change_df_1, UNDP_Global_Change_df_2, UNDP_Global_Change_df_3, UNDP_Global_Change_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "984b718c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Treshhold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UNDP_Global_Change</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>4.052632</td>\n",
       "      <td>3.347826</td>\n",
       "      <td>3.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UNDP_Global_Change</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>3.478261</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.720930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UNDP_Global_Change</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>3.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UNDP_Global_Change</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>5.153846</td>\n",
       "      <td>2.030303</td>\n",
       "      <td>2.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UNDP_Global_Change</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>2.225806</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>UNDP_Global_Change</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>UNDP_Global_Change</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>UNDP_Global_Change</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNDP_Global_Change</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNDP_Global_Change</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Lexicon           Technique  Treshhold  Accuracy  Precision  \\\n",
       "9   UNDP_Global_Change  Relative Frequency        0.9  0.860000   4.052632   \n",
       "8   UNDP_Global_Change  Relative Frequency        0.8  0.856667   3.478261   \n",
       "10  UNDP_Global_Change  Relative Frequency        1.0  0.853333   4.500000   \n",
       "12  UNDP_Global_Change  Relative Frequency        1.2  0.846667   5.153846   \n",
       "11  UNDP_Global_Change  Relative Frequency        1.1  0.846667   4.600000   \n",
       "..                 ...                 ...        ...       ...        ...   \n",
       "17  UNDP_Global_Change  Absolute Presences       17.0  0.333333   0.500000   \n",
       "16  UNDP_Global_Change  Absolute Presences       16.0  0.333333   0.500000   \n",
       "15  UNDP_Global_Change  Absolute Presences       15.0  0.333333   0.500000   \n",
       "0   UNDP_Global_Change  Relative Frequency        0.0  0.333333   0.500000   \n",
       "0   UNDP_Global_Change  Absolute Presences        0.0  0.333333   0.500000   \n",
       "\n",
       "      Recall  F1 Score  \n",
       "9   3.347826  3.666667  \n",
       "8   4.000000  3.720930  \n",
       "10  2.571429  3.272727  \n",
       "12  2.030303  2.913043  \n",
       "11  2.225806  3.000000  \n",
       "..       ...       ...  \n",
       "17  1.000000  0.666667  \n",
       "16  1.000000  0.666667  \n",
       "15  1.000000  0.666667  \n",
       "0   1.000000  0.666667  \n",
       "0   1.000000  0.666667  \n",
       "\n",
       "[84 rows x 7 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Global_Change_UNDP_df.sort_values(\"Accuracy\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7def3b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNDP and IPCC\n",
    "UNDP_IPCC_Lexicon = pd.concat([IPCC_Lexicon, UNDP_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "UNDP_IPCC_df_1 = get_metrics_df_1(Lexicon_df, UNDP_IPCC_Lexicon, 0, 20, \"UNDP_IPCC\")\n",
    "UNDP_IPCC_df_2 = get_metrics_df_2(Lexicon_df, UNDP_IPCC_Lexicon, 0, 2, 0.1, \"UNDP_IPCC\")\n",
    "UNDP_IPCC_df_3 = get_metrics_df_3(Lexicon_df, UNDP_IPCC_Lexicon, 0, 20, \"UNDP_IPCC\")\n",
    "UNDP_IPCC_df_4 = get_metrics_df_4(Lexicon_df, UNDP_IPCC_Lexicon, 0, 2, 0.1, \"UNDP_IPCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "76c4f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPCC_UNDP_df = pd.concat([UNDP_IPCC_df_1, UNDP_IPCC_df_2, UNDP_IPCC_df_3, UNDP_IPCC_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "881f064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNDP and Wikipedia\n",
    "UNDP_Wikipedia_Lexicon = pd.concat([Wikipedia_Lexicon, UNDP_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "UNDP_Wikipedia_df_1 = get_metrics_df_1(Lexicon_df, UNDP_Wikipedia_Lexicon, 0, 20, \"UNDP_Wikipedia\")\n",
    "UNDP_Wikipedia_df_2 = get_metrics_df_2(Lexicon_df, UNDP_Wikipedia_Lexicon, 0, 2, 0.1, \"UNDP_Wikipedia\")\n",
    "UNDP_Wikipedia_df_3 = get_metrics_df_3(Lexicon_df, UNDP_Wikipedia_Lexicon, 0, 20, \"UNDP_Wikipedia\")\n",
    "UNDP_Wikipedia_df_4 = get_metrics_df_4(Lexicon_df, UNDP_Wikipedia_Lexicon, 0, 2, 0.1, \"UNDP_Wikipedia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d486bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wikipedia_UNDP_df = pd.concat([UNDP_Wikipedia_df_1, UNDP_Wikipedia_df_2, UNDP_Wikipedia_df_3, UNDP_Wikipedia_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9373038f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Treshhold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UNDP_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>5.125000</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>4.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UNDP_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>UNDP_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>5.571429</td>\n",
       "      <td>3.545455</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UNDP_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>3.909091</td>\n",
       "      <td>6.142857</td>\n",
       "      <td>4.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>UNDP_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.054054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>UNDP_Wikipedia</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>UNDP_Wikipedia</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>UNDP_Wikipedia</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNDP_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNDP_Wikipedia</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Lexicon           Technique  Treshhold  Accuracy  Precision  \\\n",
       "11  UNDP_Wikipedia  Relative Frequency        1.1  0.886667   5.125000   \n",
       "12  UNDP_Wikipedia  Relative Frequency        1.2  0.886667   5.714286   \n",
       "13  UNDP_Wikipedia  Relative Frequency        1.3  0.880000   5.571429   \n",
       "10  UNDP_Wikipedia  Relative Frequency        1.0  0.880000   3.909091   \n",
       "15  UNDP_Wikipedia  Relative Frequency        1.5  0.876667   6.250000   \n",
       "..             ...                 ...        ...       ...        ...   \n",
       "19  UNDP_Wikipedia  Absolute Presences       19.0  0.333333   0.500000   \n",
       "18  UNDP_Wikipedia  Absolute Presences       18.0  0.333333   0.500000   \n",
       "17  UNDP_Wikipedia  Absolute Presences       17.0  0.333333   0.500000   \n",
       "0   UNDP_Wikipedia  Relative Frequency        0.0  0.333333   0.500000   \n",
       "0   UNDP_Wikipedia  Absolute Presences        0.0  0.333333   0.500000   \n",
       "\n",
       "      Recall  F1 Score  \n",
       "11  4.555556  4.823529  \n",
       "12  4.000000  4.705882  \n",
       "13  3.545455  4.333333  \n",
       "10  6.142857  4.777778  \n",
       "15  3.000000  4.054054  \n",
       "..       ...       ...  \n",
       "19  1.000000  0.666667  \n",
       "18  1.000000  0.666667  \n",
       "17  1.000000  0.666667  \n",
       "0   1.000000  0.666667  \n",
       "0   1.000000  0.666667  \n",
       "\n",
       "[84 rows x 7 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wikipedia_UNDP_df.sort_values(\"Accuracy\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f29be6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lexicon_df_2 = pd.concat([EPA_UNDP_df, BBC_UNDP_df, Global_Change_UNDP_df, IPCC_UNDP_df, Wikipedia_UNDP_df]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3df23872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Treshhold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>UNDP_EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>3.869565</td>\n",
       "      <td>8.090909</td>\n",
       "      <td>5.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>BBC_UNDP</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>3.869565</td>\n",
       "      <td>8.090909</td>\n",
       "      <td>5.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>UNDP_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>5.125000</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>4.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>UNDP_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>UNDP_EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>3.407407</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>5.257143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>UNDP_IPCC</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>0.471503</td>\n",
       "      <td>10.111111</td>\n",
       "      <td>0.900990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>UNDP_IPCC</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>0.910891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>UNDP_IPCC</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.950495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>UNDP_IPCC</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>0.471503</td>\n",
       "      <td>10.111111</td>\n",
       "      <td>0.900990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>UNDP_IPCC</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.323333</td>\n",
       "      <td>0.460733</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.866995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Lexicon           Technique  Treshhold  Accuracy  Precision  \\\n",
       "30         UNDP_EPA  Relative Frequency        0.9  0.886667   3.869565   \n",
       "114        BBC_UNDP  Relative Frequency        0.9  0.886667   3.869565   \n",
       "368  UNDP_Wikipedia  Relative Frequency        1.1  0.886667   5.125000   \n",
       "369  UNDP_Wikipedia  Relative Frequency        1.2  0.886667   5.714286   \n",
       "29         UNDP_EPA  Relative Frequency        0.8  0.883333   3.407407   \n",
       "..              ...                 ...        ...       ...        ...   \n",
       "262       UNDP_IPCC  Absolute Frequency       10.0  0.326667   0.471503   \n",
       "260       UNDP_IPCC  Absolute Frequency        8.0  0.326667   0.474227   \n",
       "258       UNDP_IPCC  Absolute Frequency        6.0  0.326667   0.484848   \n",
       "263       UNDP_IPCC  Absolute Frequency       11.0  0.326667   0.471503   \n",
       "264       UNDP_IPCC  Absolute Frequency       12.0  0.323333   0.460733   \n",
       "\n",
       "        Recall  F1 Score  \n",
       "30    8.090909  5.235294  \n",
       "114   8.090909  5.235294  \n",
       "368   4.555556  4.823529  \n",
       "369   4.000000  4.705882  \n",
       "29   11.500000  5.257143  \n",
       "..         ...       ...  \n",
       "262  10.111111  0.900990  \n",
       "260  11.500000  0.910891  \n",
       "258  24.000000  0.950495  \n",
       "263  10.111111  0.900990  \n",
       "264   7.333333  0.866995  \n",
       "\n",
       "[420 rows x 7 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lexicon_df_2.sort_values(\"Accuracy\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "637fa27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPA and BBC\n",
    "EPA_BBC_Lexicon = pd.concat([EPA_Lexicon, BBC_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "EPA_BBC_df_1 = get_metrics_df_1(Lexicon_df, EPA_BBC_Lexicon, 0, 20, \"BBC_EPA\")\n",
    "EPA_BBC_df_2 = get_metrics_df_2(Lexicon_df, EPA_BBC_Lexicon, 0, 2, 0.1, \"BBC_EPA\")\n",
    "EPA_BBC_df_3 = get_metrics_df_3(Lexicon_df, EPA_BBC_Lexicon, 0, 20, \"BBC_EPA\")\n",
    "EPA_BBC_df_4 = get_metrics_df_4(Lexicon_df, EPA_BBC_Lexicon, 0, 2, 0.1, \"BBC_EPA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5766b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPA_BBC_df = pd.concat([EPA_BBC_df_1, EPA_BBC_df_2, EPA_BBC_df_3, EPA_BBC_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6ba89991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Treshhold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BBC_EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>3.538462</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>5.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BBC_EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>5.062500</td>\n",
       "      <td>4.263158</td>\n",
       "      <td>4.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BBC_EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>4.611111</td>\n",
       "      <td>4.882353</td>\n",
       "      <td>4.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BBC_EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>4.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BBC_EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>3.782609</td>\n",
       "      <td>6.692308</td>\n",
       "      <td>4.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BBC_EPA</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BBC_EPA</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BBC_EPA</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBC_EPA</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBC_EPA</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Lexicon           Technique  Treshhold  Accuracy  Precision     Recall  \\\n",
       "6   BBC_EPA  Relative Frequency        0.6  0.886667   3.538462  11.500000   \n",
       "10  BBC_EPA  Relative Frequency        1.0  0.883333   5.062500   4.263158   \n",
       "9   BBC_EPA  Relative Frequency        0.9  0.883333   4.611111   4.882353   \n",
       "8   BBC_EPA  Relative Frequency        0.8  0.883333   4.250000   5.666667   \n",
       "7   BBC_EPA  Relative Frequency        0.7  0.880000   3.782609   6.692308   \n",
       "..      ...                 ...        ...       ...        ...        ...   \n",
       "19  BBC_EPA  Absolute Presences       19.0  0.333333   0.500000   1.000000   \n",
       "18  BBC_EPA  Absolute Presences       18.0  0.333333   0.500000   1.000000   \n",
       "17  BBC_EPA  Absolute Presences       17.0  0.333333   0.500000   1.000000   \n",
       "0   BBC_EPA  Relative Frequency        0.0  0.333333   0.500000   1.000000   \n",
       "0   BBC_EPA  Absolute Presences        0.0  0.333333   0.500000   1.000000   \n",
       "\n",
       "    F1 Score  \n",
       "6   5.411765  \n",
       "10  4.628571  \n",
       "9   4.742857  \n",
       "8   4.857143  \n",
       "7   4.833333  \n",
       "..       ...  \n",
       "19  0.666667  \n",
       "18  0.666667  \n",
       "17  0.666667  \n",
       "0   0.666667  \n",
       "0   0.666667  \n",
       "\n",
       "[84 rows x 7 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPA_BBC_df.sort_values(\"Accuracy\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "101535ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPA and Global Change\n",
    "EPA_Global_Change_Lexicon = pd.concat([EPA_Lexicon, Global_Change_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "EPA_Global_Change_df_1 = get_metrics_df_1(Lexicon_df, EPA_Global_Change_Lexicon, 0, 20, \"EPA_GLobal_Change\")\n",
    "EPA_Global_Change_df_2 = get_metrics_df_2(Lexicon_df, EPA_Global_Change_Lexicon, 0, 2, 0.1, \"BBC_Global_Change\")\n",
    "EPA_Global_Change_df_3 = get_metrics_df_3(Lexicon_df, EPA_Global_Change_Lexicon, 0, 20, \"BBC_Global_Change\")\n",
    "EPA_Global_Change_df_4 = get_metrics_df_4(Lexicon_df, EPA_Global_Change_Lexicon, 0, 2, 0.1, \"BBC_Global_Change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0d585045",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPA_Global_Change_df = pd.concat([EPA_Global_Change_df_1, EPA_Global_Change_df_2, EPA_Global_Change_df_3, EPA_Global_Change_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4717a31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Treshhold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BBC_Global_Change</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>4.540541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BBC_Global_Change</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>3.214286</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BBC_Global_Change</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>3.480000</td>\n",
       "      <td>6.692308</td>\n",
       "      <td>4.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BBC_Global_Change</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>3.904762</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>4.205128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BBC_Global_Change</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>5.615385</td>\n",
       "      <td>2.703704</td>\n",
       "      <td>3.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BBC_Global_Change</td>\n",
       "      <td>Relative Presences</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPA_GLobal_Change</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBC_Global_Change</td>\n",
       "      <td>Relative Presences</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBC_Global_Change</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBC_Global_Change</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Lexicon           Technique  Treshhold  Accuracy  Precision  \\\n",
       "12  BBC_Global_Change  Relative Frequency        1.2  0.876667   4.000000   \n",
       "10  BBC_Global_Change  Relative Frequency        1.0  0.873333   3.214286   \n",
       "11  BBC_Global_Change  Relative Frequency        1.1  0.873333   3.480000   \n",
       "13  BBC_Global_Change  Relative Frequency        1.3  0.870000   3.904762   \n",
       "18  BBC_Global_Change  Relative Frequency        1.8  0.866667   5.615385   \n",
       "..                ...                 ...        ...       ...        ...   \n",
       "7   BBC_Global_Change  Relative Presences        0.7  0.453333   0.609756   \n",
       "0   EPA_GLobal_Change  Absolute Frequency        0.0  0.333333   0.500000   \n",
       "0   BBC_Global_Change  Relative Presences        0.0  0.333333   0.500000   \n",
       "0   BBC_Global_Change  Relative Frequency        0.0  0.333333   0.500000   \n",
       "0   BBC_Global_Change  Absolute Presences        0.0  0.333333   0.500000   \n",
       "\n",
       "      Recall  F1 Score  \n",
       "12  5.250000  4.540541  \n",
       "10  9.000000  4.736842  \n",
       "11  6.692308  4.578947  \n",
       "13  4.555556  4.205128  \n",
       "18  2.703704  3.650000  \n",
       "..       ...       ...  \n",
       "7   0.000000  0.000000  \n",
       "0   1.000000  0.666667  \n",
       "0   1.000000  0.666667  \n",
       "0   1.000000  0.666667  \n",
       "0   1.000000  0.666667  \n",
       "\n",
       "[84 rows x 7 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPA_Global_Change_df.sort_values(\"Accuracy\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ab41474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPA and IPCC\n",
    "EPA_IPCC_Lexicon = pd.concat([EPA_Lexicon, IPCC_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "EPA_IPCC_df_1 = get_metrics_df_1(Lexicon_df, EPA_IPCC_Lexicon, 0, 20, \"EPA_IPCC\")\n",
    "EPA_IPCC_df_2 = get_metrics_df_2(Lexicon_df, EPA_IPCC_Lexicon, 0, 2, 0.1, \"EPA_IPCC\")\n",
    "EPA_IPCC_df_3 = get_metrics_df_3(Lexicon_df, EPA_IPCC_Lexicon, 0, 20, \"EPA_IPCC\")\n",
    "EPA_IPCC_df_4 = get_metrics_df_4(Lexicon_df, EPA_IPCC_Lexicon, 0, 2, 0.1, \"EPA_IPCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "81e6d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPA_IPCC_df = pd.concat([EPA_IPCC_df_1, EPA_IPCC_df_2, EPA_IPCC_df_3, EPA_IPCC_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f2431357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Treshhold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>EPA_IPCC</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>1.863636</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>1.012346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EPA_IPCC</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>1.730769</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>1.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EPA_IPCC</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.723333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.040816</td>\n",
       "      <td>1.228916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>EPA_IPCC</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>1.384615</td>\n",
       "      <td>1.173913</td>\n",
       "      <td>1.270588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>EPA_IPCC</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.713333</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>1.702703</td>\n",
       "      <td>1.465116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EPA_IPCC</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>EPA_IPCC</td>\n",
       "      <td>Relative Presences</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EPA_IPCC</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.476684</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>0.915423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EPA_IPCC</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>0.471503</td>\n",
       "      <td>10.111111</td>\n",
       "      <td>0.900990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EPA_IPCC</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.950495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Lexicon           Technique  Treshhold  Accuracy  Precision     Recall  \\\n",
       "20  EPA_IPCC  Absolute Presences       20.0  0.730000   1.863636   0.694915   \n",
       "19  EPA_IPCC  Absolute Presences       19.0  0.730000   1.730769   0.818182   \n",
       "18  EPA_IPCC  Absolute Presences       18.0  0.723333   1.500000   1.040816   \n",
       "17  EPA_IPCC  Absolute Presences       17.0  0.716667   1.384615   1.173913   \n",
       "16  EPA_IPCC  Absolute Presences       16.0  0.713333   1.285714   1.702703   \n",
       "..       ...                 ...        ...       ...        ...        ...   \n",
       "2   EPA_IPCC  Absolute Presences        2.0  0.333333   0.500000   1.000000   \n",
       "20  EPA_IPCC  Relative Presences        2.0  0.333333   0.500000   1.000000   \n",
       "10  EPA_IPCC  Absolute Frequency       10.0  0.330000   0.476684  11.500000   \n",
       "11  EPA_IPCC  Absolute Frequency       11.0  0.326667   0.471503  10.111111   \n",
       "7   EPA_IPCC  Absolute Frequency        7.0  0.326667   0.484848  24.000000   \n",
       "\n",
       "    F1 Score  \n",
       "20  1.012346  \n",
       "19  1.111111  \n",
       "18  1.228916  \n",
       "17  1.270588  \n",
       "16  1.465116  \n",
       "..       ...  \n",
       "2   0.666667  \n",
       "20  0.666667  \n",
       "10  0.915423  \n",
       "11  0.900990  \n",
       "7   0.950495  \n",
       "\n",
       "[84 rows x 7 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPA_IPCC_df.sort_values(\"Accuracy\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "129ced17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPA and Wikipedia\n",
    "EPA_Wikipedia_Lexicon = pd.concat([EPA_Lexicon, Wikipedia_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "EPA_Wikipedia_df_1 = get_metrics_df_1(Lexicon_df, EPA_Wikipedia_Lexicon, 0, 20, \"EPA_Wikipedia\")\n",
    "EPA_Wikipedia_df_2 = get_metrics_df_2(Lexicon_df, EPA_Wikipedia_Lexicon, 0, 2, 0.1, \"EPA_Wikipedia\")\n",
    "EPA_Wikipedia_df_3 = get_metrics_df_3(Lexicon_df, EPA_Wikipedia_Lexicon, 0, 20, \"EPA_Wikipedia\")\n",
    "EPA_Wikipedia_df_4 = get_metrics_df_4(Lexicon_df, EPA_Wikipedia_Lexicon, 0, 2, 0.1, \"EPA_Wikipedia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "61c1e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPA_Wikipedia_df = pd.concat([EPA_Wikipedia_df_1, EPA_Wikipedia_df_2, EPA_Wikipedia_df_3, EPA_Wikipedia_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dc9e53d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Treshhold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>3.760000</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>6.064516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>5.533333</td>\n",
       "      <td>4.882353</td>\n",
       "      <td>5.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>3.956522</td>\n",
       "      <td>10.111111</td>\n",
       "      <td>5.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>6.153846</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.848485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>5.466667</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>4.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Relative Presences</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.526667</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Relative Presences</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Absolute Presences</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Lexicon           Technique  Treshhold  Accuracy  Precision  \\\n",
       "10  EPA_Wikipedia  Relative Frequency        1.0  0.896667   3.760000   \n",
       "15  EPA_Wikipedia  Relative Frequency        1.5  0.893333   5.533333   \n",
       "11  EPA_Wikipedia  Relative Frequency        1.1  0.893333   3.956522   \n",
       "17  EPA_Wikipedia  Relative Frequency        1.7  0.890000   6.153846   \n",
       "16  EPA_Wikipedia  Relative Frequency        1.6  0.890000   5.466667   \n",
       "..            ...                 ...        ...       ...        ...   \n",
       "7   EPA_Wikipedia  Relative Presences        0.7  0.526667   0.704225   \n",
       "0   EPA_Wikipedia  Absolute Frequency        0.0  0.333333   0.500000   \n",
       "0   EPA_Wikipedia  Relative Presences        0.0  0.333333   0.500000   \n",
       "0   EPA_Wikipedia  Relative Frequency        0.0  0.333333   0.500000   \n",
       "0   EPA_Wikipedia  Absolute Presences        0.0  0.333333   0.500000   \n",
       "\n",
       "       Recall  F1 Score  \n",
       "10  15.666667  6.064516  \n",
       "15   4.882353  5.187500  \n",
       "11  10.111111  5.687500  \n",
       "17   4.000000  4.848485  \n",
       "16   4.555556  4.969697  \n",
       "..        ...       ...  \n",
       "7    0.000000  0.000000  \n",
       "0    1.000000  0.666667  \n",
       "0    1.000000  0.666667  \n",
       "0    1.000000  0.666667  \n",
       "0    1.000000  0.666667  \n",
       "\n",
       "[84 rows x 7 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPA_Wikipedia_df.sort_values(\"Accuracy\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1fd66768",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lexicon_df_2 = pd.concat([Lexicon_df_2, EPA_BBC_df, EPA_Global_Change_df, EPA_IPCC_df, EPA_Wikipedia_df]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3af7a07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Treshhold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>3.760000</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>6.064516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>3.956522</td>\n",
       "      <td>10.111111</td>\n",
       "      <td>5.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>5.533333</td>\n",
       "      <td>4.882353</td>\n",
       "      <td>5.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>6.153846</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.848485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>EPA_Wikipedia</td>\n",
       "      <td>Relative Frequency</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>5.466667</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>4.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>EPA_IPCC</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>0.471503</td>\n",
       "      <td>10.111111</td>\n",
       "      <td>0.900990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>UNDP_IPCC</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>0.910891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>UNDP_IPCC</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>0.471503</td>\n",
       "      <td>10.111111</td>\n",
       "      <td>0.900990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>UNDP_IPCC</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.326667</td>\n",
       "      <td>0.471503</td>\n",
       "      <td>10.111111</td>\n",
       "      <td>0.900990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>UNDP_IPCC</td>\n",
       "      <td>Absolute Frequency</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.323333</td>\n",
       "      <td>0.460733</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.866995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>756 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Lexicon           Technique  Treshhold  Accuracy  Precision  \\\n",
       "703  EPA_Wikipedia  Relative Frequency        1.0  0.896667   3.760000   \n",
       "704  EPA_Wikipedia  Relative Frequency        1.1  0.893333   3.956522   \n",
       "708  EPA_Wikipedia  Relative Frequency        1.5  0.893333   5.533333   \n",
       "710  EPA_Wikipedia  Relative Frequency        1.7  0.890000   6.153846   \n",
       "709  EPA_Wikipedia  Relative Frequency        1.6  0.890000   5.466667   \n",
       "..             ...                 ...        ...       ...        ...   \n",
       "599       EPA_IPCC  Absolute Frequency       11.0  0.326667   0.471503   \n",
       "260      UNDP_IPCC  Absolute Frequency        8.0  0.326667   0.474227   \n",
       "262      UNDP_IPCC  Absolute Frequency       10.0  0.326667   0.471503   \n",
       "263      UNDP_IPCC  Absolute Frequency       11.0  0.326667   0.471503   \n",
       "264      UNDP_IPCC  Absolute Frequency       12.0  0.323333   0.460733   \n",
       "\n",
       "        Recall  F1 Score  \n",
       "703  15.666667  6.064516  \n",
       "704  10.111111  5.687500  \n",
       "708   4.882353  5.187500  \n",
       "710   4.000000  4.848485  \n",
       "709   4.555556  4.969697  \n",
       "..         ...       ...  \n",
       "599  10.111111  0.900990  \n",
       "260  11.500000  0.910891  \n",
       "262  10.111111  0.900990  \n",
       "263  10.111111  0.900990  \n",
       "264   7.333333  0.866995  \n",
       "\n",
       "[756 rows x 7 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lexicon_df_2.sort_values(\"Accuracy\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1260c559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BBC and Global Change\n",
    "#EPA and Wikipedia\n",
    "BBC_Global_Change_Lexicon = pd.concat([BBC_Lexicon, Global_Change_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "BBC_Global_Change_df_1 = get_metrics_df_1(Lexicon_df, BBC_Global_Change_Lexicon, 0, 20, \"BBC_Global_Change\")\n",
    "BBC_Global_Change_df_2 = get_metrics_df_2(Lexicon_df, BBC_Global_Change_Lexicon, 0, 2, 0.1, \"BBC_Global_Change\")\n",
    "BBC_Global_Change_df_3 = get_metrics_df_3(Lexicon_df, BBC_Global_Change_Lexicon, 0, 20, \"BBC_Global_Change\")\n",
    "BBC_Global_Change_df_4 = get_metrics_df_4(Lexicon_df, BBC_Global_Change_Lexicon, 0, 2, 0.1, \"BBC_Global_Change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4c2024e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BBC_Global_Change_df = pd.concat([BBC_Global_Change_df_1, BBC_Global_Change_df_2, BBC_Global_Change_df_3, BBC_Global_Change_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a152cd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BBC and IPCC\n",
    "BBC_IPCC_Lexicon = pd.concat([BBC_Lexicon, IPCC_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "BBC_IPCC_df_1 = get_metrics_df_1(Lexicon_df, BBC_IPCC_Lexicon, 0, 20, \"BBC_IPCC\")\n",
    "BBC_IPCC_df_2 = get_metrics_df_2(Lexicon_df, BBC_IPCC_Lexicon, 0, 2, 0.1, \"BBC_IPCC\")\n",
    "BBC_IPCC_df_3 = get_metrics_df_3(Lexicon_df, BBC_IPCC_Lexicon, 0, 20, \"BBC_IPCC\")\n",
    "BBC_IPCC_df_4 = get_metrics_df_4(Lexicon_df, BBC_IPCC_Lexicon, 0, 2, 0.1, \"BBC_IPCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "64f41eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BBC_IPCC_df = pd.concat([BBC_IPCC_df_1, BBC_IPCC_df_2, BBC_IPCC_df_3, BBC_IPCC_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7b9bd7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BBC and Wikipedia\n",
    "BBC_Wikipedia_Lexicon = pd.concat([BBC_Lexicon, Wikipedia_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "BBC_Wikipedia_df_1 = get_metrics_df_1(Lexicon_df, BBC_Wikipedia_Lexicon, 0, 20, \"BBC_Wikipedia\")\n",
    "BBC_Wikipedia_df_2 = get_metrics_df_2(Lexicon_df, BBC_Wikipedia_Lexicon, 0, 2, 0.1, \"BBC_Wikipedia\")\n",
    "BBC_Wikipedia_df_3 = get_metrics_df_3(Lexicon_df, BBC_Wikipedia_Lexicon, 0, 20, \"BBC_Wikipedia\")\n",
    "BBC_Wikipedia_df_4 = get_metrics_df_4(Lexicon_df, BBC_Wikipedia_Lexicon, 0, 2, 0.1, \"BBC_Wikipedia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9bf1b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "BBC_Wikpedia_df = pd.concat([BBC_Wikipedia_df_1, BBC_Wikipedia_df_2, BBC_Wikipedia_df_3, BBC_Wikipedia_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "08f6aa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lexicon_df_2 = pd.concat([Lexicon_df_2, BBC_Global_Change_df, BBC_IPCC_df, BBC_Wikpedia_df]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477a603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wikipedia and Global Change\n",
    "Wikipedia_Global_Change_Lexicon = pd.concat([Global_Change_Lexicon, Wikipedia_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "Wikipedia_Global_Change_df_1 = get_metrics_df_1(Lexicon_df, Wikipedia_Global_Change_Lexicon, 0, 20, \"Wikipedia_Global_Change\")\n",
    "Wikipedia_Global_Change_df_2 = get_metrics_df_2(Lexicon_df, Wikipedia_Global_Change_Lexicon, 0, 2, 0.1, \"Wikipedia_Global_Change\")\n",
    "Wikipedia_Global_Change_df_3 = get_metrics_df_3(Lexicon_df, Wikipedia_Global_Change_Lexicon, 0, 20, \"Wikipedia_Global_Change\")\n",
    "Wikipedia_Global_Change_df_4 = get_metrics_df_4(Lexicon_df, Wikipedia_Global_Change_Lexicon, 0, 2, 0.1, \"Wikipedia_Global_Change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5ea019",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wikpedia_Global_Change_df = pd.concat([Wikipedia_Global_Change_df_1, Wikipedia_Global_Change_df_2, Wikipedia_Global_Change_df_3, Wikipedia_Global_Change_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2287a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wikipedia and IPCC\n",
    "Wikipedia_IPCC_Lexicon = pd.concat([IPCC_Lexicon, Wikipedia_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "Wikipedia_IPCC_df_1 = get_metrics_df_1(Lexicon_df, Wikipedia_IPCC_Lexicon, 0, 20, \"Wikipedia_IPCC\")\n",
    "Wikipedia_IPCC_df_2 = get_metrics_df_2(Lexicon_df, Wikipedia_IPCC_Lexicon, 0, 2, 0.1, \"Wikipedia_IPCC\")\n",
    "Wikipedia_IPCC_df_3 = get_metrics_df_3(Lexicon_df, Wikipedia_IPCC_Lexicon, 0, 20, \"Wikipedia_IPCC\")\n",
    "Wikipedia_IPCC_df_4 = get_metrics_df_4(Lexicon_df, Wikipedia_IPCC_Lexicon, 0, 2, 0.1, \"Wikipedia_IPCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e11a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wikpedia_IPCC_df = pd.concat([Wikipedia_IPCC_df_1, Wikipedia_IPCC_df_2, Wikipedia_IPCC_df_3, Wikipedia_IPCC_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0198c9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IPCC and Global Change\n",
    "Global_Change_IPCC_Lexicon = pd.concat([IPCC_Lexicon, Global_Change_Lexicon]).drop_duplicates().reset_index(drop = True)\n",
    "Global_Change_IPCC_df_1 = get_metrics_df_1(Lexicon_df, Global_Change_IPCC_Lexicon, 0, 20, \"Global_Change_IPCC\")\n",
    "Global_Change_IPCC_df_2 = get_metrics_df_2(Lexicon_df, Global_Change_IPCC_Lexicon, 0, 2, 0.1, \"Global_Change_IPCC\")\n",
    "Global_Change_IPCC_df_3 = get_metrics_df_3(Lexicon_df, Global_Change_IPCC_Lexicon, 0, 20, \"Global_Change_IPCC\")\n",
    "Global_Change_IPCC_df_4 = get_metrics_df_4(Lexicon_df, Global_Change_IPCC_Lexicon, 0, 2, 0.1, \"Global_Change_IPCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a0fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "Global_Change_IPCC_df = pd.concat([Global_Change_IPCC_df_1, Global_Change_IPCC_df_2, Global_Change_IPCC_df_3, Global_Change_IPCC_df_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d3ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lexicon_df_2 = pd.concat([Lexicon_df_2, Wikpedia_Global_Change_df, Wikpedia_IPCC_df, Global_Change_IPCC_df]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d5c0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lexicon_df_2.sort_values(\"Accuracy\", ascending = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
