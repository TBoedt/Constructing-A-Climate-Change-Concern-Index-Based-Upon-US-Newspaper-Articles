{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "285c4d9c",
   "metadata": {},
   "source": [
    "# 0. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d39ea7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from datetime import date, timedelta\n",
    "import random\n",
    "import threading\n",
    "import multiprocessing as np\n",
    "from multiprocessing import Pool\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91c53ad",
   "metadata": {},
   "source": [
    "# 1. Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e0c218",
   "metadata": {},
   "source": [
    "## 1.1. Loop Through Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1770ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daterange(start_date, end_date):\n",
    "    for n in range(int((end_date - start_date).days) + 1):\n",
    "        yield start_date + timedelta(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcdb837a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next page Â»\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.politico.com/search/20?adv=true&start=02/01/2016&end=02/01/2016\")\n",
    "#print(driver.find_element(By.CSS_SELECTOR, \"a.button\").text)\n",
    "print(driver.find_element(By.CSS_SELECTOR, \"a.button:nth-child(2)\").text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cd9278",
   "metadata": {},
   "source": [
    "# 2. Scraping News Media"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb1b56a",
   "metadata": {},
   "source": [
    "## 2.1. Wall Street Journal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746f9a4c",
   "metadata": {},
   "source": [
    "### 2.1.1. Function - Get URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b27213ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWallStreetJournalURLS(start_date, end_date, username, password):\n",
    "    #put dates in date format\n",
    "    start_date = datetime.strptime(start_date, \"%d/%m/%Y\")\n",
    "    end_date = datetime.strptime(end_date, \"%d/%m/%Y\")\n",
    "\n",
    "    #Define list of variables to store \n",
    "    WSJ_date = []\n",
    "    WSJ_link = []\n",
    "\n",
    "    #Go to the website\n",
    "    fireFoxOptions = webdriver.FirefoxOptions()\n",
    "    fireFoxOptions.add_argument('--ignore-certificate-errors')\n",
    "    fireFoxOptions.add_argument('--allow-running-insecure-content')\n",
    "    fireFoxOptions.add_argument(\"--headless\")\n",
    "    fireFoxOptions.add_argument(\"--disable-gpu\")\n",
    "    fireFoxOptions.add_argument(\"--no-sandbox\")\n",
    "    user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.50 Safari/537.36'\n",
    "    fireFoxOptions.add_argument(f'user-agent={user_agent}')\n",
    "    driver_WSJ = webdriver.Firefox(options=fireFoxOptions)\n",
    "    #driver_WSJ = webdriver.Firefox()\n",
    "    driver_WSJ.get(\"https://sso.accounts.dowjones.com/login-page?op=localop&scope=openid%20idp_id%20roles%20email%20given_name%20family_name%20djid%20djUsername%20djStatus%20trackid%20tags%20prts%20suuid%20createTimestamp&client_id=5hssEAdMy0mJTICnJNvC9TXEw3Va7jfO&response_type=code&redirect_uri=https%3A%2F%2Faccounts.wsj.com%2Fauth%2Fsso%2Flogin&nonce=ab6a473a-cfa6-4714-8fad-b6dff98f5f18&ui_locales=en-us-x-wsj-223-2&mars=-1&ns=prod%2Faccounts-wsj&state=8rChOTDzC_Y_AK-i.TJAixN_XjsWxwUEEPoHg2OPCaX6qRBu4nGSk5fqLliY4H0B5F7gj_57-XH-YBWGS&protocol=oauth2&client=5hssEAdMy0mJTICnJNvC9TXEw3Va7jfO#!/signin\")\n",
    "\n",
    "    #put in user_name:\n",
    "    time.sleep(3) #makes sure field is fully loaded\n",
    "    username_field = driver_WSJ.find_element(By.XPATH, \"/html/body/div[1]/div[2]/div/div/div/div[1]/div[1]/form/div[2]/div[1]/div[2]/input\")\n",
    "    username_field.send_keys(username)\n",
    "\n",
    "    #continue to password:\n",
    "    driver_WSJ.find_element(By.XPATH, \"/html/body/div[1]/div[2]/div/div/div/div[1]/div[1]/form/div[2]/div[6]/div[1]/button[2]\").click()\n",
    "\n",
    "    #input password:\n",
    "    time.sleep(3) #makes sure field is fully loaded\n",
    "    password_field = driver_WSJ.find_element(By.XPATH, \"//*[@id='password-login-password']\")\n",
    "    password_field.send_keys(password)\n",
    "\n",
    "    #click on sign in:\n",
    "    driver_WSJ.find_element(By.XPATH, \"//*[@id='password-login']/div/form/div/div[5]/div[1]/button\").click()\n",
    "\n",
    "    try:\n",
    "        #accept cookies\n",
    "        time.sleep(10)\n",
    "        driver_WSJ.switch_to.frame(WebDriverWait(driver_WSJ,30).until(EC.presence_of_element_located((By.ID, 'sp_message_iframe_718122'))))\n",
    "        driver_WSJ.find_element(By.CSS_SELECTOR, \"button.message-component:nth-child(2)\").click()\n",
    "        driver_WSJ.switch_to.default_content() \n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    scrape_time = time.time() #starting the timing\n",
    "\n",
    "    for single_date in daterange(start_date, end_date):\n",
    "        date = single_date.strftime(\"%d/%m/%Y\")\n",
    "        print(date)\n",
    "        year = \"%02d\" % (int(date.split('/')[2]),)\n",
    "        month = \"%02d\" % (int(date.split('/')[1]),)\n",
    "        day = \"%02d\" % (int(date.split('/')[0]),)\n",
    "        page = \"%02d\" % (1,) #we assume there is always at least one page\n",
    "        url = f\"https://www.wsj.com/news/archive/{year}/{month}/{day}?page={page}\"\n",
    "        test = 0\n",
    "        while(test < 100):\n",
    "            try:\n",
    "                driver_WSJ.get(url) #go to the page in the WSJ archive for the given date\n",
    "                break\n",
    "            except:\n",
    "                test += 1\n",
    "                time.sleep(10)\n",
    "\n",
    "        #check if there are multiple pages and if so, visit these as well\n",
    "        pages_load = 0\n",
    "        while(pages_load < 100):\n",
    "            try:\n",
    "                pages = WebDriverWait(driver_WSJ, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"WSJTheme--pagepicker-total--Kl350I1l \")))\n",
    "                page_total = re.findall(r'\\d+', pages.text)\n",
    "                nr_pages = int(page_total[0])\n",
    "                break\n",
    "            except:\n",
    "                pages_load += 1\n",
    "                driver_WSJ.get(url)\n",
    "\n",
    "        for p in range(1,nr_pages+1):\n",
    "            page = \"%02d\" % (p,)\n",
    "            url = f\"https://www.wsj.com/news/archive/{year}/{month}/{day}?page={page}\"\n",
    "            urls_load = 0\n",
    "            while(urls_load < 100):\n",
    "                try:\n",
    "                    driver_WSJ.get(url) #go to the page in the WSJ archive for the given date\n",
    "                    break\n",
    "                except:\n",
    "                    driver_WSJ.get(url)\n",
    "\n",
    "            #get the article urls for the articles on the other pages, if there are more than 1\n",
    "            articles = WebDriverWait(driver_WSJ,10).until(EC.presence_of_all_elements_located((By.TAG_NAME, \"article\")))\n",
    "            for a in range(0,len(articles)):\n",
    "                WSJ_link.append(articles[a].find_element(By.TAG_NAME, \"a\").get_attribute('href'))\n",
    "                WSJ_date.append(date)\n",
    "    \n",
    "    driver_WSJ.quit()\n",
    "    \n",
    "    WSJ = [\"Wall_Street_Journal\"] * len(WSJ_link)\n",
    "    data = {\"Date\" : WSJ_date, \"News Paper\" : WSJ, \"Link\" : WSJ_link}\n",
    "    Wall_Street_Journal = pd.DataFrame(data)\n",
    "\n",
    "    start_date = start_date.strftime(\"%d%m%Y\")\n",
    "    end_date = end_date.strftime(\"%d%m%Y\")\n",
    "    path = f\"Data/URLS/Wall_Street_Journal_{start_date}_{end_date}_URLS\"\n",
    "    Wall_Street_Journal.to_parquet(path) \n",
    "    \n",
    "    print(\"--- %s seconds ---\" % (time.time() - scrape_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217b3365",
   "metadata": {},
   "source": [
    "### 2.1.2. Function - Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10f6db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWallStreetJournalArticles(username, password, dataframe):\n",
    "    WSJ_article_content = []\n",
    "    WSJ_title = []\n",
    "\n",
    "    #FIREFOX\n",
    "    #Declare the driver and go to website\n",
    "    #fireFoxOptions = webdriver.FirefoxOptions()\n",
    "    #fireFoxOptions.add_argument('--ignore-certificate-errors')\n",
    "    #fireFoxOptions.add_argument('--allow-running-insecure-content')\n",
    "    #fireFoxOptions.add_argument(\"--headless\")\n",
    "    #fireFoxOptions.add_argument(\"--disable-gpu\")\n",
    "    #fireFoxOptions.add_argument(\"--no-sandbox\")\n",
    "    #user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.50 Safari/537.36'\n",
    "    #fireFoxOptions.add_argument(f'user-agent={user_agent}')\n",
    "    #driver_WSJ = webdriver.Firefox(options=fireFoxOptions)\n",
    "    \n",
    "    #CHROME\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--disable-extensions\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\") # linux only\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36\"\n",
    "    chrome_options.add_argument(f'user-agent={user_agent}')\n",
    "    driver_WSJ = webdriver.Chrome(options=chrome_options)\n",
    "   # driver_WSJ = webdriver.Chrome()\n",
    "    driver_WSJ.get(\"https://sso.accounts.dowjones.com/login-page?op=localop&scope=openid%20idp_id%20roles%20email%20given_name%20family_name%20djid%20djUsername%20djStatus%20trackid%20tags%20prts%20suuid%20updated_at&client_id=5hssEAdMy0mJTICnJNvC9TXEw3Va7jfO&response_type=code&redirect_uri=https%3A%2F%2Faccounts.wsj.com%2Fauth%2Fsso%2Flogin&nonce=5e93fe71-314a-44b9-bb2d-4a0e5a3167a4&ui_locales=en-us-x-wsj-223-2&mars=-1&ns=prod%2Faccounts-wsj&state=zJgHWictetlLHLG6.Uob1DvxnFA4kIkiqJAY80zp2N4FxS3WdBvV-VuTFdpM&protocol=oauth2&client=5hssEAdMy0mJTICnJNvC9TXEw3Va7jfO#!/signin\")\n",
    "\n",
    "    #put in user_name:\n",
    "    time.sleep(3) #makes sure field is fully loaded\n",
    "    username_field = driver_WSJ.find_element(By.XPATH, \"/html/body/div[1]/div[2]/div/div/div/div[1]/div[1]/form/div[2]/div[1]/div[2]/input\")\n",
    "    username_field.send_keys(username)\n",
    "\n",
    "    #continue to password:\n",
    "    driver_WSJ.find_element(By.XPATH, \"/html/body/div[1]/div[2]/div/div/div/div[1]/div[1]/form/div[2]/div[6]/div[1]/button[2]\").click()\n",
    "\n",
    "    #input password:\n",
    "    time.sleep(3) #makes sure field is fully loaded\n",
    "    password_field = driver_WSJ.find_element(By.XPATH, \"//*[@id='password-login-password']\")\n",
    "    password_field.send_keys(password)\n",
    "\n",
    "    #click on sign in:\n",
    "    driver_WSJ.find_element(By.XPATH, \"//*[@id='password-login']/div/form/div/div[5]/div[1]/button\").click()\n",
    "\n",
    "    try:\n",
    "        #accept cookies\n",
    "        time.sleep(20)\n",
    "        driver_WSJ.switch_to.default_content()\n",
    "        driver_WSJ.switch_to.frame(WebDriverWait(driver_WSJ,30).until(EC.presence_of_element_located((By.ID, 'sp_message_iframe_718122'))))\n",
    "        driver_WSJ.find_element(By.CSS_SELECTOR, \"button.message-component:nth-child(2)\").click()\n",
    "        print(\"accepted\")\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    scrape_time = time.time()\n",
    "    #go to all the articles and scrape the content\n",
    "    links  = list(dataframe[\"Link\"])\n",
    "    for u in range(0, len(links)):\n",
    "        trys = 0\n",
    "        while(trys < 100):\n",
    "            try:\n",
    "                driver_WSJ.get(links[u])\n",
    "                break\n",
    "            except:\n",
    "                trys += 1\n",
    "                time.sleep(10)\n",
    "\n",
    "        try:\n",
    "            #extract the content and add to a variables\n",
    "            content = WebDriverWait(driver_WSJ, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'article-content  ')))\n",
    "            text = content.find_elements(By.TAG_NAME, 'p')\n",
    "            article_text = \"\"\n",
    "            for t in range(0,len(text)):\n",
    "                article_text += \" \" + text[t].text\n",
    "\n",
    "            WSJ_article_content.append(article_text) #add text to the list\n",
    "            #WSJ_article_content.append(content.text) #add text to the list\n",
    "\n",
    "        except: #we don't have access to the article\n",
    "            WSJ_article_content.append(\"NO ACCESS\")\n",
    "            pass #go back to page with all articles\n",
    "\n",
    "        try:\n",
    "            #collect the title as well\n",
    "            title = WebDriverWait(driver_WSJ,10).until(EC.presence_of_element_located((By.CLASS_NAME, \"wsj-article-headline\"))).text\n",
    "            WSJ_title.append(title)\n",
    "        except:\n",
    "            try:\n",
    "                #there are 2 main formats in which the titles are present in the HTML\n",
    "                title = WebDriverWait(driver_WSJ,10).until(EC.presence_of_element_located((By.CLASS_NAME, \"bigTop__hed\"))).text\n",
    "                WSJ_title.append(title)\n",
    "\n",
    "            except:\n",
    "                #add error if there is some unexpected layout -> this way our arrays will be of the same length and we will be able\n",
    "                #to construct a dataframe in the end\n",
    "                WSJ_title.append(\"ERROR\")\n",
    "                pass\n",
    "\n",
    "    driver_WSJ.quit()\n",
    "\n",
    "    WSJ = [\"Wall_Street_Journal\"] * len(WSJ_article_content)\n",
    "    data = {\"Title\" : WSJ_title, \"Text\" : WSJ_article_content, \"Link\" : dataframe[\"Link\"]}\n",
    "    Wall_Street_Journal = pd.DataFrame(data)\n",
    "    Wall_Street_Journal = pd.merge(Wall_Street_Journal, dataframe, on = \"Link\")\n",
    "    return(Wall_Street_Journal)\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - scrape_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2cf9e1",
   "metadata": {},
   "source": [
    "## 2.2. Washington Post"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a6082c",
   "metadata": {},
   "source": [
    "### 2.2.1. Function - Get URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a32e3729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWashingtonPostURLS(start_date, end_date, username, password):\n",
    "    #put dates in date format\n",
    "    start_date = datetime.strptime(start_date, \"%d/%m/%Y\")   \n",
    "    end_date = datetime.strptime(end_date, \"%d/%m/%Y\")\n",
    "\n",
    "\n",
    "    #put them in correct format\n",
    "\n",
    "\n",
    "    #Declare all list variables for the output\n",
    "    WP_date = []\n",
    "    WP_link = []\n",
    "    \n",
    "    #FIREFOX\n",
    "    #Declare the driver and go to website\n",
    "    #fireFoxOptions = webdriver.FirefoxOptions()\n",
    "    #fireFoxOptions.add_argument('--ignore-certificate-errors')\n",
    "    #fireFoxOptions.add_argument('--allow-running-insecure-content')\n",
    "    #fireFoxOptions.add_argument(\"--headless\")\n",
    "    #fireFoxOptions.add_argument(\"--disable-gpu\")\n",
    "    #fireFoxOptions.add_argument(\"--no-sandbox\")\n",
    "    #user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.50 Safari/537.36'\n",
    "    #fireFoxOptions.add_argument(f'user-agent={user_agent}')\n",
    "    #driver = webdriver.Firefox(options=fireFoxOptions)\n",
    "    \n",
    "    #CHROME\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--disable-extensions\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\") # linux only\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36\"\n",
    "    chrome_options.add_argument(f'user-agent={user_agent}')\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver = webdriver.Chrome()\n",
    "    # Initialize the driver\n",
    "\n",
    "\n",
    "    #Go the the searchpage of the Washington Post\n",
    "    driver.get(\"https://www.washingtonpost.com/search/?query=+&facets=%7B%22time%22%3A%22all%22%2C%22sort%22%3A%22relevancy%22%2C%22section%22%3A%5B%5D%2C%22author%22%3A%5B%5D%7D\")\n",
    "    #Accept Cookies\n",
    "    try:\n",
    "        driver.save_screenshot(\"cookies.png\")\n",
    "        WebDriverWait(driver,20).until(EC.presence_of_element_located((By.ID, \"onetrust-accept-btn-handler\"))).click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #Log-in into Washington Post account\n",
    "    try: #it is possible that account is already logged in! \n",
    "        #Sign in into Washington Post account\n",
    "        #Click on Sign In\n",
    "        #WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='__next']/div[1]/nav/div[4]/div[2]/a/p\"))).click()\n",
    "        driver.get(\"https://www.washingtonpost.com/subscribe/signin/?next_url=https%3A%2F%2Fwww.washingtonpost.com&nid=top_pb_signin&arcId=&itid=nav_sign_in\")\n",
    "        time.sleep(5)\n",
    "        driver.save_screenshot(\"Login.png\")\n",
    "        #located username field\n",
    "        time.sleep(2) #field needs to completely load\n",
    "        username_field = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='username']\")))\n",
    "        username_field.send_keys(username) #send username\n",
    "        username_field.send_keys(Keys.RETURN) #press enter\n",
    "\n",
    "        #Located password field\n",
    "        time.sleep(2) #field needs to completely load\n",
    "        password_field = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='password']\")))\n",
    "        password_field.send_keys(password)\n",
    "        password_field.send_keys(Keys.ENTER)\n",
    "\n",
    "        #Go back to the search page\n",
    "        WebDriverWait(driver,10).until(EC.presence_of_element_located((By.CLASS_NAME, \"wpds-c-jlBemH \"))).click()\n",
    "        go_to_search = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.ID, \"query\")))\n",
    "        go_to_search.send_keys(search_term)\n",
    "        go_to_search.send_keys(Keys.ENTER)\n",
    "\n",
    "    except:\n",
    "        #you already logged-in -> continue \n",
    "        pass\n",
    "    \n",
    "    search_page_load = 0\n",
    "    while(search_page_load < 100):\n",
    "        try:\n",
    "            driver.get(\"https://www.washingtonpost.com/search/?query=+&facets=%7B%22time%22%3A%22all%22%2C%22sort%22%3A%22relevancy%22%2C%22section%22%3A%5B%5D%2C%22author%22%3A%5B%5D%7D\")\n",
    "            break\n",
    "        except:\n",
    "            search_page_load += 1\n",
    "            \n",
    "    scrape_time = time.time()\n",
    "    for single_date in daterange(start_date, end_date):\n",
    "        date = single_date.strftime(\"%m/%d/%y\")\n",
    "\n",
    "        #Locate the searchbar, send searchterm and press enter\n",
    "        \n",
    "        time.sleep(10)\n",
    "        driver.save_screenshot(\"Searchbar.png\")\n",
    "        searchbar = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.CLASS_NAME, \"aa-Input\")))\n",
    "        searchbar.send_keys(\" \")\n",
    "        searchbar.send_keys(Keys.ENTER)\n",
    "\n",
    "        #Select time period\n",
    "        #select periode specification\n",
    "        WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='main-content']/div[1]/section[2]/div[1]/button/div/div[2]/span\"))).click()\n",
    "\n",
    "        #select custom time\n",
    "        WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='main-content']/div[1]/section[2]/div[1]/div/div/div[1]/button/div/div[2]\"))).click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        #Send start date\n",
    "        WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='main-content']/div[1]/section[2]/div[1]/div/div/div[2]/div[1]/div/div/div[1]/input\"))).send_keys(date)\n",
    "\n",
    "        #Empty automatic end date\n",
    "        WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='main-content']/div[1]/section[2]/div[1]/div/div/div[2]/div[2]/div/div/div[1]/input\"))).clear()\n",
    "\n",
    "        #Send end date\n",
    "        WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='main-content']/div[1]/section[2]/div[1]/div/div/div[2]/div[2]/div/div/div[1]/input\"))).send_keys(date)\n",
    "\n",
    "        #Press Apply\n",
    "        WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='main-content']/div[1]/section[2]/div[1]/div/div/div[2]/button[2]\"))).click()\n",
    "        time.sleep(5)\n",
    "        driver.refresh()\n",
    "        #click to load more on the page untill no longer possible\n",
    "        loading = True\n",
    "        while(loading):\n",
    "            try:\n",
    "                driver.save_screenshot(\"loading.png\")\n",
    "                WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='main-content']/div[1]/section[3]/button\"))).click()\n",
    "            except:\n",
    "                loading = False\n",
    "        \n",
    "        driver.save_screenshot(\"articles.png\")\n",
    "        articles = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.TAG_NAME, \"article\")))\n",
    "\n",
    "        for a in range(0,len(articles)):\n",
    "            WP_link.append(articles[a].find_element(By.TAG_NAME, \"a\").get_attribute('href'))\n",
    "            WP_date.append(single_date.strftime(\"%d/%m/%Y\"))\n",
    "    \n",
    "    driver.quit()\n",
    "    \n",
    "    WP = [\"Washington_Post\"] * len(WP_link)\n",
    "    data = {\"Date\" : WP_date, \"News Paper\" : WP, \"Link\" : WP_link}\n",
    "    WashingtonPost = pd.DataFrame(data)\n",
    "\n",
    "    start_date = start_date.strftime(\"%d%m%Y\")\n",
    "    end_date = end_date.strftime(\"%d%m%Y\")\n",
    "    path = f\"Data/URLS/Washington_Post_{start_date}_{end_date}_URLS\"\n",
    "    #WashingtonPost.to_parquet(path) \n",
    "    return(WashingtonPost)\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - scrape_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3055a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "URLS_WP = getWashingtonPostURLS(\"01/01/2016\", \"01/01/2016\", \"tb.boedttibo@gmail.com\", \"ThesisR&T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "16754361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(URLS_WP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c850d03",
   "metadata": {},
   "source": [
    "### 2.2.2. Function - Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8cc19fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWashingtonPostArticles(username, password, dataframe):\n",
    "    WP_article_content = []\n",
    "    WP_title = []\n",
    "\n",
    "    #FIREFOX\n",
    "    #Declare the driver and go to website\n",
    "    #fireFoxOptions = webdriver.FirefoxOptions()\n",
    "    #fireFoxOptions.add_argument('--ignore-certificate-errors')\n",
    "    #fireFoxOptions.add_argument('--allow-running-insecure-content')\n",
    "    #fireFoxOptions.add_argument(\"--headless\")\n",
    "    #fireFoxOptions.add_argument(\"--disable-gpu\")\n",
    "    #fireFoxOptions.add_argument(\"--no-sandbox\")\n",
    "    #user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.50 Safari/537.36'\n",
    "    #fireFoxOptions.add_argument(f'user-agent={user_agent}')\n",
    "    #driver_WSJ = webdriver.Firefox(options=fireFoxOptions)\n",
    "\n",
    "    #CHROME\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--disable-extensions\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\") # linux only\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36\"\n",
    "    chrome_options.add_argument(f'user-agent={user_agent}')\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    #driver = webdriver.Chrome()\n",
    "\n",
    "    #Go the the searchpage of the Washington Post\n",
    "    driver.get(\"https://www.washingtonpost.com/search/?query=+&facets=%7B%22time%22%3A%22all%22%2C%22sort%22%3A%22relevancy%22%2C%22section%22%3A%5B%5D%2C%22author%22%3A%5B%5D%7D\")\n",
    "\n",
    "    try:\n",
    "        #Accept Cookies\n",
    "        WebDriverWait(driver,10).until(EC.presence_of_element_located((By.ID, \"onetrust-accept-btn-handler\"))).click()\n",
    "    except:\n",
    "        print(\"no cookies\")\n",
    "        pass\n",
    "    #Log-in into Washington Post account\n",
    "    try: #it is possible that account is already logged in! \n",
    "\n",
    "        #Sign in into Washington Post account\n",
    "        #Click on Sign In\n",
    "        WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='__next']/div[1]/nav/div[4]/div[2]/a/p\"))).click()\n",
    "\n",
    "        #located username field\n",
    "        time.sleep(2) #field needs to completely load\n",
    "        username_field = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='username']\")))\n",
    "        username_field.send_keys(username) #send username\n",
    "        username_field.send_keys(Keys.RETURN) #press enter\n",
    "\n",
    "        #Located password field\n",
    "        time.sleep(2) #field needs to completely load\n",
    "        password_field = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='password']\")))\n",
    "        password_field.send_keys(password)\n",
    "        password_field.send_keys(Keys.ENTER)\n",
    "\n",
    "        time.sleep(10)\n",
    "\n",
    "    except:\n",
    "        #you already logged-in -> continue \n",
    "        pass\n",
    "\n",
    "    scrape_time = time.time()\n",
    "    links = list(dataframe[\"Link\"])\n",
    "    for u in range(0, len(links)):\n",
    "            trys = 0\n",
    "            while(trys < 100):\n",
    "                try:\n",
    "                    #go to every article\n",
    "                    driver.get(links[u])\n",
    "                    break\n",
    "                except:\n",
    "                    trys += 1\n",
    "\n",
    "            text = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.TAG_NAME, \"article\"))).text\n",
    "            try:\n",
    "                text = text[text.index(\"Share\")+len(\"Share\")+1:text.rindex(\"Gift Article\")]\n",
    "                WP_article_content.append(text)\n",
    "            except:\n",
    "                try:\n",
    "                    text = text[text.index(\"Share\")+len(\"Share\")+1:text.rindex(\"Comments\")]\n",
    "                    WP_article_content.append(text)\n",
    "                except:\n",
    "                    try:\n",
    "                        text = text[text.index(\"tb.boedttibo\")+len(\"tb.boedttibo\")+1:text.rindex(\"Comments\")]\n",
    "                        WP_article_content.append(text)\n",
    "                    except:\n",
    "                        WP_article_content.append(text)\n",
    "                        #WP_article_content.append(\"ERROR\")\n",
    "                        pass\n",
    "            #idea is: We take the full text and before we have the article content the last pice of text is \"share\" and immediatly after the content\n",
    "            #we have \"comments\" this way we are able to only extract the article content\n",
    "            #the reasons for this is that each article has a more or less different html dependent on their \"type\"\n",
    "\n",
    "            #there are different formats of titles, in this order all titles are located\n",
    "            try:\n",
    "                title = driver.find_element(By.CSS_SELECTOR, \"#main-content > span:nth-child(2)\").text\n",
    "                WP_title.append(title)\n",
    "            except:\n",
    "                try:\n",
    "                    title = driver.find_element(By.CSS_SELECTOR, \"#main-content\").text\n",
    "                    WP_title.append(title)\n",
    "                except:\n",
    "                    try:\n",
    "                        title = driver.find_element(By.CSS_SELECTOR, \"#main-content > span\").text\n",
    "                        WP_title.append(title)\n",
    "                    except:\n",
    "                        WP_title.append(\"ERROR\")\n",
    "                        pass\n",
    "\n",
    "    #Close driver\n",
    "    driver.quit()\n",
    "\n",
    "    #How long did the scraping took? \n",
    "    print(\"--- %s seconds ---\" % (time.time() - scrape_time))\n",
    "\n",
    "    #Create output file\n",
    "    #Make the dataframe\n",
    "    WP = [\"Washington Post\"] * len(WP_article_content)\n",
    "    data = {\"Title\" : WP_title, \"Text\" : WP_article_content, \"Date\" : dataframe[\"Date\"], \"News Paper\" : dataframe[\"News Paper\"], \"Link\" : dataframe[\"Link\"]}\n",
    "    WashingtonPost = pd.DataFrame(data)\n",
    "    return(WashingtonPost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7ea379c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 64.20283389091492 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>News Paper</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hereâs another sign the era of mass incarcerat...</td>\n",
       "      <td>Keith Humphreys is a professor of psychiatry a...</td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/wonk/wp/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Record flooding in the U.K. is just the latest...</td>\n",
       "      <td>December witnessed a spate of extreme global w...</td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/energy-env...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Will Compton is rubbing elbows with his heroes...</td>\n",
       "      <td>Will Compton admires DeAngelo Hall. Thanks to ...</td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/football-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Itâs high season for online dating â plot your...</td>\n",
       "      <td>If dating is a game, online dating is a game o...</td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/soloish/wp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Fixâs 2016 predictions!</td>\n",
       "      <td>In these final days of 2015 -- the most unpred...</td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/the-fix/wp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What UFC 195 lacks in personality it could mak...</td>\n",
       "      <td>UFC will kick off a new year of pay-per-views ...</td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/early-lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Want to do something good for your health? Try...</td>\n",
       "      <td>Every day, we are confronted with choices abou...</td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/posteverything/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kanye West calls out Nike, mentions LeBron Jam...</td>\n",
       "      <td>Updated post: Michael Jordanâs son responds to...</td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/early-lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NBA\\n7 p.m. Orlando at Washington Â» CSN, WNEW ...</td>\n",
       "      <td>NBA\\n7 p.m. Orlando at Washington Â» CSN, WNEW ...</td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/sports/tv-and-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Derrick Henry rushes for 75 yards and two touc...</td>\n",
       "      <td>ARLINGTON, Texas â Porous on the first night o...</td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/sports/colleges...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ben Carsonâs top staffers resign in a delayed ...</td>\n",
       "      <td>Three of Ben Carson's high-ranking advisers, i...</td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/post-polit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Draymond Green, Klay Thompson prove Warriors c...</td>\n",
       "      <td>You just knew the hot takes were coming. When ...</td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/early-lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>As 2015 winds down, Bernie Sanders points to c...</td>\n",
       "      <td>DES MOINES, Iowa -- Democratic presidential ho...</td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/post-polit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>By Associated Press\\nDecember 31, 2015\\nLOS AN...</td>\n",
       "      <td>LOS ANGELES â Wayne Rogers, whose Trapper John...</td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/national/2015/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Odell Beckham Jr. vows to âlearnâ from suspens...</td>\n",
       "      <td>Odell Beckham Jr. lost his cool in a big way, ...</td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/early-lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Correction: An earlier version of this story h...</td>\n",
       "      <td>Once again, they marched. Starting at the Chin...</td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/local/dc-marche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nicklas Backstrom returns to the lineup Thursd...</td>\n",
       "      <td>RALEIGH, N.C. â The Washington Capitals knew t...</td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/sports/capitals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cam Newton has chosen a name for his baby boy....</td>\n",
       "      <td>Cam Newton is not given to modesty. After all,...</td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/early-lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FBI Director J. Edgar Hoover, right, with Pres...</td>\n",
       "      <td>Frank Askin is a general counsel emeritus at t...</td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/opinions/happy-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CLEVELAND, OH- DECEMBER 8: Protestors performe...</td>\n",
       "      <td>James Downie is The Postâs digital opinions ed...</td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/opinions/when-a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0   Hereâs another sign the era of mass incarcerat...   \n",
       "1   Record flooding in the U.K. is just the latest...   \n",
       "2   Will Compton is rubbing elbows with his heroes...   \n",
       "3   Itâs high season for online dating â plot your...   \n",
       "4                         The Fixâs 2016 predictions!   \n",
       "5   What UFC 195 lacks in personality it could mak...   \n",
       "6   Want to do something good for your health? Try...   \n",
       "7   Kanye West calls out Nike, mentions LeBron Jam...   \n",
       "8   NBA\\n7 p.m. Orlando at Washington Â» CSN, WNEW ...   \n",
       "9   Derrick Henry rushes for 75 yards and two touc...   \n",
       "10  Ben Carsonâs top staffers resign in a delayed ...   \n",
       "11  Draymond Green, Klay Thompson prove Warriors c...   \n",
       "12  As 2015 winds down, Bernie Sanders points to c...   \n",
       "13  By Associated Press\\nDecember 31, 2015\\nLOS AN...   \n",
       "14  Odell Beckham Jr. vows to âlearnâ from suspens...   \n",
       "15  Correction: An earlier version of this story h...   \n",
       "16  Nicklas Backstrom returns to the lineup Thursd...   \n",
       "17  Cam Newton has chosen a name for his baby boy....   \n",
       "18  FBI Director J. Edgar Hoover, right, with Pres...   \n",
       "19  CLEVELAND, OH- DECEMBER 8: Protestors performe...   \n",
       "\n",
       "                                                 Text        Date  \\\n",
       "0   Keith Humphreys is a professor of psychiatry a...  01/01/2016   \n",
       "1   December witnessed a spate of extreme global w...  01/01/2016   \n",
       "2   Will Compton admires DeAngelo Hall. Thanks to ...  01/01/2016   \n",
       "3   If dating is a game, online dating is a game o...  01/01/2016   \n",
       "4   In these final days of 2015 -- the most unpred...  01/01/2016   \n",
       "5   UFC will kick off a new year of pay-per-views ...  01/01/2016   \n",
       "6   Every day, we are confronted with choices abou...  01/01/2016   \n",
       "7   Updated post: Michael Jordanâs son responds to...  01/01/2016   \n",
       "8   NBA\\n7 p.m. Orlando at Washington Â» CSN, WNEW ...  01/01/2016   \n",
       "9   ARLINGTON, Texas â Porous on the first night o...  01/01/2016   \n",
       "10  Three of Ben Carson's high-ranking advisers, i...  01/01/2016   \n",
       "11  You just knew the hot takes were coming. When ...  01/01/2016   \n",
       "12  DES MOINES, Iowa -- Democratic presidential ho...  01/01/2016   \n",
       "13  LOS ANGELES â Wayne Rogers, whose Trapper John...  01/01/2016   \n",
       "14  Odell Beckham Jr. lost his cool in a big way, ...  01/01/2016   \n",
       "15  Once again, they marched. Starting at the Chin...  01/01/2016   \n",
       "16  RALEIGH, N.C. â The Washington Capitals knew t...  01/01/2016   \n",
       "17  Cam Newton is not given to modesty. After all,...  01/01/2016   \n",
       "18  Frank Askin is a general counsel emeritus at t...  01/01/2016   \n",
       "19  James Downie is The Postâs digital opinions ed...  01/01/2016   \n",
       "\n",
       "         News Paper                                               Link  \n",
       "0   Washington_Post  https://www.washingtonpost.com/news/wonk/wp/20...  \n",
       "1   Washington_Post  https://www.washingtonpost.com/news/energy-env...  \n",
       "2   Washington_Post  https://www.washingtonpost.com/news/football-i...  \n",
       "3   Washington_Post  https://www.washingtonpost.com/news/soloish/wp...  \n",
       "4   Washington_Post  https://www.washingtonpost.com/news/the-fix/wp...  \n",
       "5   Washington_Post  https://www.washingtonpost.com/news/early-lead...  \n",
       "6   Washington_Post  https://www.washingtonpost.com/posteverything/...  \n",
       "7   Washington_Post  https://www.washingtonpost.com/news/early-lead...  \n",
       "8   Washington_Post  https://www.washingtonpost.com/sports/tv-and-r...  \n",
       "9   Washington_Post  https://www.washingtonpost.com/sports/colleges...  \n",
       "10  Washington_Post  https://www.washingtonpost.com/news/post-polit...  \n",
       "11  Washington_Post  https://www.washingtonpost.com/news/early-lead...  \n",
       "12  Washington_Post  https://www.washingtonpost.com/news/post-polit...  \n",
       "13  Washington_Post  https://www.washingtonpost.com/national/2015/1...  \n",
       "14  Washington_Post  https://www.washingtonpost.com/news/early-lead...  \n",
       "15  Washington_Post  https://www.washingtonpost.com/local/dc-marche...  \n",
       "16  Washington_Post  https://www.washingtonpost.com/sports/capitals...  \n",
       "17  Washington_Post  https://www.washingtonpost.com/news/early-lead...  \n",
       "18  Washington_Post  https://www.washingtonpost.com/opinions/happy-...  \n",
       "19  Washington_Post  https://www.washingtonpost.com/opinions/when-a...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getWashingtonPostArticles(\"tb.boedttibo@gmail.com\", \"ThesisR&T\", URLS_WP[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3023eb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no cookies\n",
      "no cookies\n",
      "--- 26.277382135391235 seconds ---\n",
      "--- 35.9525420665741 seconds ---\n",
      "--- 39.549072265625 seconds ---\n",
      "--- 39.95678997039795 seconds ---\n",
      "--------------------------\n",
      "--- 71.04116654396057 seconds ---\n"
     ]
    }
   ],
   "source": [
    "tijd = time.time()\n",
    "\n",
    "import concurrent.futures\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    # Submit the two instances of the scraping function to the executor\n",
    "    future1 = executor.submit(getWashingtonPostArticles, \"tb.boedttibo@gmail.com\", \"ThesisR&T\", URLS_WP[0:5])\n",
    "    future2 = executor.submit(getWashingtonPostArticles, \"tb.boedttibo@gmail.com\", \"ThesisR&T\", URLS_WP[5:10])\n",
    "    future3 = executor.submit(getWashingtonPostArticles, \"tb.boedttibo@gmail.com\", \"ThesisR&T\", URLS_WP[10:15])\n",
    "    future4 = executor.submit(getWashingtonPostArticles, \"tb.boedttibo@gmail.com\", \"ThesisR&T\", URLS_WP[15:20])\n",
    "    \n",
    "    # Wait for the scraping functions to complete\n",
    "    concurrent.futures.wait([future1, future2, future3, future4])\n",
    "    \n",
    "print(\"--------------------------\")   \n",
    "print(\"--- %s seconds ---\" % (time.time() - tijd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d699e9f",
   "metadata": {},
   "source": [
    "## 2.3. New York Times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c29e7e",
   "metadata": {},
   "source": [
    "### 2.3.1. Function - Get URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec8d98ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNewYorkTimesURLS(start_date, end_date, username, password):\n",
    "    #put dates in date format\n",
    "    start_date = datetime.strptime(start_date, \"%d/%m/%Y\") \n",
    "    end_date = datetime.strptime(end_date, \"%d/%m/%Y\")\n",
    "\n",
    "    #Declare all list variables for the output\n",
    "    NYT_date = []\n",
    "    NYT_link = []\n",
    "\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "    chrome_options.add_argument(\"--disable-extensions\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\") # linux only\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36\"\n",
    "    chrome_options.add_argument(f'user-agent={user_agent}')\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(\"https://myaccount.nytimes.com/auth/login?response_type=cookie&client_id=vi&redirect_uri=https%3A%2F%2Fwww.nytimes.com%2Fsubscription%2Fonboarding-offer%3FcampaignId%3D7JFJX%26EXIT_URI%3Dhttps%253A%252F%252Fwww.nytimes.com%252F&asset=masthead\")\n",
    "    time.sleep(5)\n",
    "    driver.save_screenshot(\"test.png\")\n",
    "    #not a robot\n",
    "    input(\"Press Enter to continue...\")\n",
    "\n",
    "    #Select log-in field\n",
    "    login = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.ID, \"email\")))\n",
    "\n",
    "    #Send username\n",
    "    login.send_keys(username)\n",
    "\n",
    "    #Press continue\n",
    "    WebDriverWait(driver,10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#myAccountAuth > div > div > div > form > div > div.css-bho3kg-buttonWrapper-buttonStyles-Button > button\"))).click()\n",
    "\n",
    "    #Select password field\n",
    "    password_field = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.ID, \"password\")))\n",
    "\n",
    "    #send password\n",
    "    password_field.send_keys(password)\n",
    "\n",
    "    #Press continue\n",
    "    WebDriverWait(driver,10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#myAccountAuth > div > div > form > div > div.css-1nkv26b-buttonWrapper-buttonStyles-Button > button\"))).click()\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    #go to search page\n",
    "    search_page_loaded = 0\n",
    "    while(search_page_loaded < 100):\n",
    "        try:\n",
    "            driver.get(\"https://www.nytimes.com/search?dropmab=false&query=&sort=best\")\n",
    "            break\n",
    "        except:\n",
    "            search_page_loaded += 1\n",
    "\n",
    "    #Accept Cookies\n",
    "    try:\n",
    "        WebDriverWait(driver,5).until(EC.presence_of_element_located((By.CLASS_NAME, \"banner__container__cta--accept\"))).click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    scrape_time = time.time()\n",
    "    for single_date in daterange(start_date, end_date):\n",
    "        date = single_date.strftime(\"%Y%m%d\")\n",
    "\n",
    "        url = f\"https://www.nytimes.com/search?dropmab=false&endDate={date}&query=%20&sort=best&startDate={date}\"\n",
    "        url_loaded = 0\n",
    "        while(url_loaded < 100):\n",
    "            try:\n",
    "                driver.get(url)\n",
    "                break\n",
    "            except:\n",
    "                url_loaded += 1\n",
    "\n",
    "        #click to load more on the page untill no longer possible\n",
    "        loading = True\n",
    "        while(loading):\n",
    "            try:\n",
    "                WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='site-content']/div/div[2]/div[2]/div/button\"))).click()\n",
    "            except:\n",
    "                loading = False\n",
    "\n",
    "        articles = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"css-1l4w6pd\")))\n",
    "        dates = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"css-17ubb9w\")))\n",
    "\n",
    "        date_list = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"css-17ubb9w\")))\n",
    "        true_date = date_list[0].text\n",
    "        for a in range(0, len(articles)):\n",
    "            if(true_date == date_list[a].text):\n",
    "                NYT_link.append(articles[a].find_element(By.TAG_NAME, \"a\").get_attribute('href'))\n",
    "                NYT_date.append(single_date.strftime(\"%d/%m/%Y\"))\n",
    "    \n",
    "    driver.quit()\n",
    "    \n",
    "    NYT = [\"New_York_Times\"] * len(NYT_link)\n",
    "    data = {\"Date\" : NYT_date, \"News Paper\" : NYT, \"Link\" : NYT_link}\n",
    "    New_York_Times = pd.DataFrame(data)\n",
    "    \n",
    "    print(\"--- %s seconds ---\" % (time.time() - scrape_time))\n",
    "    \n",
    "    return(New_York_Times)\n",
    "    start_date = start_date.strftime(\"%d%m%Y\")\n",
    "    end_date = end_date.strftime(\"%d%m%Y\")\n",
    "    path = f\"Data/URLS/New_York_Times_{start_date}_{end_date}_URLS\"\n",
    "    New_York_Times.to_parquet(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce3650f",
   "metadata": {},
   "source": [
    "## 2.4. Politico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f600994",
   "metadata": {},
   "source": [
    "### 2.4.1. Function - Get URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050ba84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPolitico(start_date, end_date):\n",
    "    #put dates in date format\n",
    "    end_date = datetime.strptime(end_date, \"%d/%m/%Y\")\n",
    "    start_date = datetime.strptime(start_date, \"%d/%m/%Y\")\n",
    "\n",
    "    #Declare all list variables for the output\n",
    "    P_date = []\n",
    "    P_link = []\n",
    "\n",
    "    fireFoxOptions = webdriver.FirefoxOptions()\n",
    "    fireFoxOptions.add_argument('--ignore-certificate-errors')\n",
    "    fireFoxOptions.add_argument('--allow-running-insecure-content')\n",
    "    fireFoxOptions.add_argument(\"--headless\")\n",
    "    fireFoxOptions.add_argument(\"--disable-gpu\")\n",
    "    fireFoxOptions.add_argument(\"--no-sandbox\")\n",
    "    user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.50 Safari/537.36'\n",
    "    fireFoxOptions.add_argument(f'user-agent={user_agent}')\n",
    "    driver = webdriver.Firefox(options=fireFoxOptions)\n",
    "\n",
    "    #go to the website\n",
    "    driver.get(\"https://www.politico.com/search?adv=true\")\n",
    "\n",
    "    #accept cookies\n",
    "    try:\n",
    "        WebDriverWait(driver,10).until(EC.presence_of_element_located((By.ID, \"onetrust-accept-btn-handler\"))).click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    scrape_time = time.time()\n",
    "    for single_date in daterange(start_date, end_date):\n",
    "        date = single_date.strftime(\"%m/%d/%Y\")\n",
    "        test = 0\n",
    "        while(test < 100):\n",
    "            try:\n",
    "                driver.get(f\"https://www.politico.com/search/1?adv=true&start={date}&end={date}\")\n",
    "                break\n",
    "            except:\n",
    "                test += 1\n",
    "                time.sleep(10)\n",
    "        articles = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.TAG_NAME, \"article\")))\n",
    "        for a in range(0, len(articles)):\n",
    "            P_link.append(articles[a].find_element(By.TAG_NAME, \"a\").get_attribute('href'))\n",
    "            P_date.append(date)\n",
    "\n",
    "        #get the number of pages to know how much you should click .pagination > ol:nth-child(2) > li:nth-child(3) > a:nth-child(1)\n",
    "        try:\n",
    "            nr_pages = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \".pagination > ol:nth-child(2) > li:nth-child(6) > a:nth-child(1)\"))).text\n",
    "        except:\n",
    "            nr_pages = 1\n",
    "            pass\n",
    "\n",
    "        for p in range(1, int(nr_pages)):\n",
    "            url = f\"https://www.politico.com/search/{p+1}?adv=true&start={date}&end={date}\"\n",
    "            driver.get(url)\n",
    "\n",
    "        articles = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.TAG_NAME, \"article\")))\n",
    "        for a in range(0, len(articles)):\n",
    "            P_link.append(articles[a].find_element(By.TAG_NAME, \"a\").get_attribute('href'))\n",
    "            P_date.append(single_date.strftime(\"%d/%m/%Y\"))\n",
    "\n",
    "    driver.quit()\n",
    "    print(\"--- %s seconds ---\" % (time.time() - scrape_time))\n",
    "\n",
    "    P = [\"Politico\"] * len(P_link)\n",
    "    data = {\"Date\" : P_date, \"News Paper\" : P, \"Link\" : P_link}\n",
    "    Politico = pd.DataFrame(data)\n",
    "\n",
    "    start_date = start_date.strftime(\"%d%m%Y\")\n",
    "    end_date = end_date.strftime(\"%d%m%Y\")\n",
    "    path = f\"Data/URLS/Politico_{start_date}_{end_date}_URLS\"\n",
    "    Politico.to_parquet(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0928dfb",
   "metadata": {},
   "source": [
    "# 3. Running Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc7e763",
   "metadata": {},
   "source": [
    "## 3.1. Wall Street Journal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa89ce63",
   "metadata": {},
   "source": [
    "## 3.2. Washington Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83ebf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getWashingtonPostURLS(\"01/01/2016\", \"01/01/2016\", \"tb.boedttibo@gmail.com\", \"ThesisR&T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5515224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "WP_URLS = pd.read_parquet(\"Data/URLS/Wall_Street_Journal_01012016_01012016_URLS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d40067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "WP_URLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb21e2bd",
   "metadata": {},
   "source": [
    "## 3.3. New York Times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc311562",
   "metadata": {},
   "source": [
    "## 3.4. Politico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70da76b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
