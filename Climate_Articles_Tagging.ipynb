{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "549a3d8c",
   "metadata": {},
   "source": [
    "# 0. Packages and Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7567ca2",
   "metadata": {},
   "source": [
    "## 0.1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bd2f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0aaaa2",
   "metadata": {},
   "source": [
    "## 0.2. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce24a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-process text for lexicon based approaches\n",
    "def preprocess_text(text):\n",
    "    # remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # convert to lower case\n",
    "    text = text.lower()\n",
    "    # remove blank spaces\n",
    "    text = ' '.join(text.split())\n",
    "    # remove newline characters\n",
    "    text = text.replace('\\n', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b22206e",
   "metadata": {},
   "source": [
    "### Absolute Count with Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "2495792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function that take the dataframe, lexicon and n-gram value (how many n-grams should be considered) and determine the \n",
    "#count of words in dataframe text that match the lexicon\n",
    "def count_lexicon_words_1(text_df, lexicon):\n",
    "    lexicon = lexicon[\"Lexicon\"]\n",
    "    count = []\n",
    "\n",
    "    for text in text_df[\"Text\"]:\n",
    "        lexicon_counts = 0\n",
    "\n",
    "        for word in lexicon:\n",
    "            lexicon_counts += text.lower().count(word.lower())\n",
    "        \n",
    "        count.append(lexicon_counts)\n",
    "        \n",
    "    text_df[\"Lexicon Count\"] = count\n",
    "    \n",
    "    return(text_df)\n",
    "\n",
    "#create a function that used the lexicon approach to determine with the target is yes or no\n",
    "def lexicon_target_classifier_1(df, treshold):\n",
    "    target = []\n",
    "    \n",
    "    count = df[\"Lexicon Count\"]\n",
    "    \n",
    "    for c in count:\n",
    "        if c < treshold:\n",
    "            target.append(\"No\")\n",
    "        else:\n",
    "            target.append(\"Yes\")\n",
    "            \n",
    "    df[\"Target Lexicon\"] = target\n",
    "    return(df)\n",
    "\n",
    "#Combine both functions to classify articles based on the lexicon\n",
    "def lexicon_climate_classifier_1(text_df, lexicon, treshold):\n",
    "    df = count_lexicon_words_1(text_df, lexicon)\n",
    "    \n",
    "    return(lexicon_target_classifier_1(df, treshold))\n",
    "\n",
    "def threshold_metrics_1(df_text, lexicon, min_treshhold, max_treshhold):\n",
    "    for i in range(min_treshhold, max_treshhold + 1):\n",
    "        df = lexicon_climate_classifier_1(df_text, lexicon, i)\n",
    "        cross_table = pd.crosstab(df['Target'], df['Target Lexicon'], margins=True)\n",
    "        \n",
    "        # calculate classification metrics using scikit-learn\n",
    "        accuracy = (cross_table.iloc[0, 0] + cross_table.iloc[1, 1]) / cross_table.loc['All', 'All'] if cross_table.shape == (3,3) else cross_table.iloc[1,0] / (cross_table.iloc[1, 0] + cross_table.iloc[0,0]) \n",
    "        precision = cross_table.iloc[1,1] / cross_table.iloc[0,1] if cross_table.iloc[0,1] != 0 else 0\n",
    "        recall = cross_table.iloc[1,1] / cross_table.iloc[1,0] if cross_table.iloc[1,0] != 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "        # print the metrics\n",
    "        print(\"Threshhold:\", i)\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall:\", recall)\n",
    "        print(\"F1 score:\", f1_score)\n",
    "        print(cross_table)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "def get_metrics_df_1(df_text, lexicon, min_treshhold, max_treshhold, Lexicon_name):    \n",
    "    Accuracy = []\n",
    "    Precision = []\n",
    "    Recall = []\n",
    "    F1_score = []\n",
    "    Name = []\n",
    "    Treshhold = []\n",
    "    \n",
    "    for i in range(min_treshhold, max_treshhold + 1):\n",
    "        df = lexicon_climate_classifier_1(df_text, lexicon, i)\n",
    "        cross_table = pd.crosstab(df['Target'], df['Target Lexicon'], margins=True)\n",
    "\n",
    "        # calculate classification metrics using scikit-learn\n",
    "        accuracy = (cross_table.iloc[0, 0] + cross_table.iloc[1, 1]) / cross_table.loc['All', 'All'] if cross_table.shape == (3,3) else cross_table.iloc[1,0] / (cross_table.iloc[1, 0] + cross_table.iloc[0,0]) \n",
    "        precision = cross_table.iloc[1,1] / cross_table.iloc[0,1] if cross_table.iloc[0,1] != 0 else 0\n",
    "        recall = cross_table.iloc[1,1] / cross_table.iloc[1,0] if cross_table.iloc[1,0] != 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "        \n",
    "        Accuracy.append(accuracy)\n",
    "        Precision.append(precision)\n",
    "        Recall.append(recall)\n",
    "        F1_score.append(f1_score)\n",
    "        Name.append(Lexicon_name)\n",
    "        Treshhold.append(i)\n",
    "        \n",
    "    return(pd.DataFrame({\"Lexicon\" : Name, \"Treshhold\" : Treshhold, \"Accuracy\" : Accuracy, \"Precision\" : Precision, \"Recall\" : Recall, \"F1 Score\" : F1_score}))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c69c28",
   "metadata": {},
   "source": [
    "### Relative Count with Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3ca9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function that take the dataframe, lexicon and n-gram value (how many n-grams should be considered) and determine the \n",
    "#count of words in dataframe text that match the lexicon\n",
    "def count_lexicon_words_2(text_df, lexicon):\n",
    "    lexicon = lexicon[\"Lexicon\"]\n",
    "    count = []\n",
    "    \n",
    "    for text in text_df[\"Text\"]:\n",
    "        lexicon_counts = 0\n",
    "\n",
    "        for word in lexicon:\n",
    "            lexicon_counts += text.lower().count(word.lower())\n",
    "        \n",
    "        word_list = text.split() \n",
    "        word_count = len(word_list)\n",
    "        count.append((lexicon_counts/word_count)*100)\n",
    "\n",
    "    text_df[\"Lexicon Count\"] = count\n",
    "    \n",
    "    return(text_df)\n",
    "\n",
    "#create a function that used the lexicon approach to determine with the target is yes or no\n",
    "def lexicon_target_classifier_2(df, treshold):\n",
    "    target = []\n",
    "    \n",
    "    count = df[\"Lexicon Count\"]\n",
    "    \n",
    "    for c in count:\n",
    "        if c < treshold:\n",
    "            target.append(\"No\")\n",
    "        else:\n",
    "            target.append(\"Yes\")\n",
    "            \n",
    "    df[\"Target Lexicon\"] = target\n",
    "    return(df)\n",
    "\n",
    "#Combine both functions to classify articles based on the lexicon\n",
    "def lexicon_climate_classifier_2(text_df, lexicon, treshold):\n",
    "    df = count_lexicon_words_2(text_df, lexicon)\n",
    "    \n",
    "    return(lexicon_target_classifier_2(df, treshold))\n",
    "\n",
    "def threshold_metrics_2(df_text, lexicon, min_treshhold, max_treshhold, jump):\n",
    "    for num in range(int((max_treshhold - min_treshhold) / jump) + 1):\n",
    "        i = min_treshhold + num * jump\n",
    "        df = lexicon_climate_classifier_2(df_text, lexicon, i)\n",
    "        cross_table = pd.crosstab(df['Target'], df['Target Lexicon'], margins=True)\n",
    "\n",
    "        # calculate classification metrics using scikit-learn\n",
    "        accuracy = (cross_table.iloc[0, 0] + cross_table.iloc[1, 1]) / cross_table.loc['All', 'All'] if cross_table.shape == (3,3) else cross_table.iloc[1,0] / (cross_table.iloc[1, 0] + cross_table.iloc[0,0]) \n",
    "        precision = cross_table.iloc[1,1] / cross_table.iloc[0,1] if cross_table.iloc[0,1] != 0 else 0\n",
    "        recall = cross_table.iloc[1,1] / cross_table.iloc[1,0] if cross_table.iloc[1,0] != 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "        # print the metrics\n",
    "        print(\"Threshhold:\", i)\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall:\", recall)\n",
    "        print(\"F1 score:\", f1_score)\n",
    "        print(cross_table)\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358383a2",
   "metadata": {},
   "source": [
    "Accuracy: This metric measures the overall performance of a model. It is defined as the number of correct predictions divided by the total number of predictions. Accuracy is a good metric to use when the classes are roughly balanced, meaning there are about the same number of positive and negative examples in the dataset.\n",
    "\n",
    "Precision: This metric measures how many of the positive predictions made by a model are actually correct. It is defined as the number of true positives divided by the total number of positive predictions. Precision is a good metric to use when we care more about avoiding false positives than false negatives.\n",
    "\n",
    "Recall: This metric measures how many of the positive examples in the dataset are correctly predicted by the model. It is defined as the number of true positives divided by the total number of actual positive examples. Recall is a good metric to use when we care more about avoiding false negatives than false positives.\n",
    "\n",
    "F1 score: This metric is a weighted average of precision and recall, where the weight is determined by the beta parameter. The most common value for beta is 1, which gives equal weight to precision and recall. The F1 score is a good metric to use when we want to balance precision and recall, and when the classes are imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc10b67",
   "metadata": {},
   "source": [
    "# 1. Import Label Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b08d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_climate_df = pd.read_parquet(\"Final_Label_Table.parquet\")\n",
    "tag_climate_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9d1d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only keep the required columns\n",
    "tag_climate_df = tag_climate_df[[\"Text\", \"Climate_Change_Topic\", \"Level_Climate_Change_Topic\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ee616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the tabel\n",
    "tag_climate_df['Level_Climate_Change_Topic'] = tag_climate_df['Level_Climate_Change_Topic'].str.strip()\n",
    "tag_climate_df[tag_climate_df[\"Level_Climate_Change_Topic\"] == \"NA\"] = \"Na\"\n",
    "tag_climate_df[tag_climate_df[\"Level_Climate_Change_Topic\"] == \"0\"] = \"Na\"\n",
    "tag_climate_df[\"Target\"] = tag_climate_df[\"Level_Climate_Change_Topic\"].apply(lambda x: \"Yes\" if x in [\"High\", \"Medium\"] else \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add6c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_labels_hms = tag_climate_df.groupby(\"Level_Climate_Change_Topic\")[\"Text\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c689ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_labels_hms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be23a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_labels = tag_climate_df.groupby(\"Target\")[\"Text\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86308d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf33a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#overview_labels_hms.to_csv(\"C:/Users/Boedt/OneDrive/Bureaublad/R Thesis/overview_tag_labels_hms\", index = False)\n",
    "#overview_labels.to_csv(\"C:/Users/Boedt/OneDrive/Bureaublad/R Thesis/overview_tag_labels\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516660b2",
   "metadata": {},
   "source": [
    "# 2. Taggers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31249337",
   "metadata": {},
   "source": [
    "## 2.1. Tagger 1 - Global Change Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c15452",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b853e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the dataframe in a different one, for the purpose of this lexicon. This way there is no confusion.\n",
    "tag1_Global_Change = tag_climate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54704fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the lexicon\n",
    "Global_Change_Lexicon = pd.read_excel('lexicons-used.xlsx', sheet_name = \"Global Change\", header = None)\n",
    "Global_Change_Lexicon.columns = [\"Lexicon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe43ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the text\n",
    "tag1_Global_Change[\"Text\"] = tag1_Global_Change[\"Text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b46de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_metrics_1(tag1_Global_Change, Global_Change_Lexicon, 0, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f08fc574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "      <th>Treshhold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>0</td>\n",
       "      <td>0.512438</td>\n",
       "      <td>1.051020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.024876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>1</td>\n",
       "      <td>0.532338</td>\n",
       "      <td>1.095745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>2</td>\n",
       "      <td>0.636816</td>\n",
       "      <td>1.517241</td>\n",
       "      <td>5.866667</td>\n",
       "      <td>2.410959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>3</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>2.193548</td>\n",
       "      <td>1.942857</td>\n",
       "      <td>2.060606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>4</td>\n",
       "      <td>0.661692</td>\n",
       "      <td>2.458333</td>\n",
       "      <td>1.340909</td>\n",
       "      <td>1.735294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>5</td>\n",
       "      <td>0.641791</td>\n",
       "      <td>3.214286</td>\n",
       "      <td>0.775862</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>6</td>\n",
       "      <td>0.631841</td>\n",
       "      <td>4.222222</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>1.027027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>7</td>\n",
       "      <td>0.641791</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>8</td>\n",
       "      <td>0.621891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>9</td>\n",
       "      <td>0.606965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.303797</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>10</td>\n",
       "      <td>0.592040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256098</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>11</td>\n",
       "      <td>0.562189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170455</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>12</td>\n",
       "      <td>0.557214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157303</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>13</td>\n",
       "      <td>0.547264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131868</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>14</td>\n",
       "      <td>0.532338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095745</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>15</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072917</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>16</td>\n",
       "      <td>0.517413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>17</td>\n",
       "      <td>0.512438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>18</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>19</td>\n",
       "      <td>0.502488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Global Change</td>\n",
       "      <td>20</td>\n",
       "      <td>0.497512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019802</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Lexicon  Treshhold  Accuracy  Precision    Recall  F1 Score\n",
       "0   Global Change          0  0.512438   1.051020  1.000000  1.024876\n",
       "1   Global Change          1  0.532338   1.095745  0.000000  0.000000\n",
       "2   Global Change          2  0.636816   1.517241  5.866667  2.410959\n",
       "3   Global Change          3  0.671642   2.193548  1.942857  2.060606\n",
       "4   Global Change          4  0.661692   2.458333  1.340909  1.735294\n",
       "5   Global Change          5  0.641791   3.214286  0.775862  1.250000\n",
       "6   Global Change          6  0.631841   4.222222  0.584615  1.027027\n",
       "7   Global Change          7  0.641791  16.500000  0.471429  0.916667\n",
       "8   Global Change          8  0.621891   0.000000  0.355263  0.000000\n",
       "9   Global Change          9  0.606965   0.000000  0.303797  0.000000\n",
       "10  Global Change         10  0.592040   0.000000  0.256098  0.000000\n",
       "11  Global Change         11  0.562189   0.000000  0.170455  0.000000\n",
       "12  Global Change         12  0.557214   0.000000  0.157303  0.000000\n",
       "13  Global Change         13  0.547264   0.000000  0.131868  0.000000\n",
       "14  Global Change         14  0.532338   0.000000  0.095745  0.000000\n",
       "15  Global Change         15  0.522388   0.000000  0.072917  0.000000\n",
       "16  Global Change         16  0.517413   0.000000  0.061856  0.000000\n",
       "17  Global Change         17  0.512438   0.000000  0.051020  0.000000\n",
       "18  Global Change         18  0.507463   0.000000  0.040404  0.000000\n",
       "19  Global Change         19  0.502488   0.000000  0.030000  0.000000\n",
       "20  Global Change         20  0.497512   0.000000  0.019802  0.000000"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics_df_1(tag1_Global_Change, Global_Change_Lexicon, 0, 20, \"Global Change\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d26ff50",
   "metadata": {},
   "source": [
    "## 2.2. Tagger 2 - IPCC Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800c5ab8",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1104c38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the dataframe in a different one, for the purpose of this lexicon. This way there is no confusion.\n",
    "tag2_IPCC = tag_climate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41bb7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the lexicon\n",
    "IPCC_Lexicon = pd.read_excel('lexicons-used.xlsx', sheet_name = \"IPCC\", header = None)\n",
    "IPCC_Lexicon.columns = [\"Lexicon\"]\n",
    "\n",
    "IPCC_Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a672099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the text\n",
    "tag2_IPCC[\"Text\"] = tag2_IPCC[\"Text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ff11a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_metrics_1(tag2_IPCC, IPCC_Lexicon, 8, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb16e34",
   "metadata": {},
   "source": [
    "## 2.3. Tagger 3 - Wikipedia Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90610cf6",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950e45ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the dataframe in a different one, for the purpose of this lexicon. This way there is no confusion.\n",
    "tag3_Wikipedia = tag_climate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335d527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the lexicon\n",
    "Wikipedia_Lexicon = pd.read_excel('lexicons-used.xlsx', sheet_name = \"Wikipedia\", header = None)\n",
    "Wikipedia_Lexicon = pd.DataFrame(Wikipedia_Lexicon[0])\n",
    "Wikipedia_Lexicon.columns = [\"Lexicon\"]\n",
    "\n",
    "Wikipedia_Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97d0c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the text\n",
    "tag3_Wikipedia[\"Text\"] = tag3_Wikipedia[\"Text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc1016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_metrics_1(tag3_Wikipedia, Wikipedia_Lexicon, 3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bf038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_metrics_2(tag3_Wikipedia, Wikipedia_Lexicon, 0, 1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "86522550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "      <th>Treshhold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>0</td>\n",
       "      <td>0.512438</td>\n",
       "      <td>1.051020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.024876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.527363</td>\n",
       "      <td>1.084211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>2</td>\n",
       "      <td>0.527363</td>\n",
       "      <td>1.084211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.810945</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>11.875000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>4</td>\n",
       "      <td>0.830846</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>4.421053</td>\n",
       "      <td>4.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>5</td>\n",
       "      <td>0.800995</td>\n",
       "      <td>8.875000</td>\n",
       "      <td>2.218750</td>\n",
       "      <td>3.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>6</td>\n",
       "      <td>0.771144</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>1.512195</td>\n",
       "      <td>2.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>7</td>\n",
       "      <td>0.741294</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>1.145833</td>\n",
       "      <td>2.115385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>8</td>\n",
       "      <td>0.726368</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>1.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>9</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.775862</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>10</td>\n",
       "      <td>0.691542</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>1.387097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>11</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>1.301587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>12</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>13</td>\n",
       "      <td>0.646766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>14</td>\n",
       "      <td>0.636816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>15</td>\n",
       "      <td>0.631841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.391892</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>16</td>\n",
       "      <td>0.616915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337662</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>17</td>\n",
       "      <td>0.592040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256098</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>18</td>\n",
       "      <td>0.587065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240964</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>19</td>\n",
       "      <td>0.572139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197674</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>20</td>\n",
       "      <td>0.572139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197674</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Lexicon  Treshhold  Accuracy  Precision     Recall  F1 Score\n",
       "0   Wikipedia          0  0.512438   1.051020   1.000000  1.024876\n",
       "1   Wikipedia          1  0.527363   1.084211   0.000000  0.000000\n",
       "2   Wikipedia          2  0.527363   1.084211   0.000000  0.000000\n",
       "3   Wikipedia          3  0.810945   3.166667  11.875000  5.000000\n",
       "4   Wikipedia          4  0.830846   5.600000   4.421053  4.941176\n",
       "5   Wikipedia          5  0.800995   8.875000   2.218750  3.550000\n",
       "6   Wikipedia          6  0.771144  12.400000   1.512195  2.695652\n",
       "7   Wikipedia          7  0.741294  13.750000   1.145833  2.115385\n",
       "8   Wikipedia          8  0.726368  25.000000   0.943396  1.818182\n",
       "9   Wikipedia          9  0.701493  22.500000   0.775862  1.500000\n",
       "10  Wikipedia         10  0.691542  21.500000   0.716667  1.387097\n",
       "11  Wikipedia         11  0.686567  41.000000   0.661290  1.301587\n",
       "12  Wikipedia         12  0.671642   0.000000   0.560606  0.000000\n",
       "13  Wikipedia         13  0.646766   0.000000   0.450704  0.000000\n",
       "14  Wikipedia         14  0.636816   0.000000   0.410959  0.000000\n",
       "15  Wikipedia         15  0.631841   0.000000   0.391892  0.000000\n",
       "16  Wikipedia         16  0.616915   0.000000   0.337662  0.000000\n",
       "17  Wikipedia         17  0.592040   0.000000   0.256098  0.000000\n",
       "18  Wikipedia         18  0.587065   0.000000   0.240964  0.000000\n",
       "19  Wikipedia         19  0.572139   0.000000   0.197674  0.000000\n",
       "20  Wikipedia         20  0.572139   0.000000   0.197674  0.000000"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics_df_1(tag3_Wikipedia, Wikipedia_Lexicon, 0, 20, \"Wikipedia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c8a3be",
   "metadata": {},
   "source": [
    "## 2.4. Tagger 4 - EPA Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638f81be",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f541b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag4_EPA = tag_climate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93d019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the lexicon\n",
    "EPA_Lexicon = pd.read_excel('lexicons-used.xlsx', sheet_name = \"EPA\", header = None)\n",
    "EPA_Lexicon = pd.DataFrame(EPA_Lexicon[0])\n",
    "EPA_Lexicon.columns = [\"Lexicon\"]\n",
    "\n",
    "EPA_Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c022ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the text\n",
    "tag4_EPA[\"Text\"] = tag4_EPA[\"Text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de76c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_metrics_1(tag4_EPA, EPA_Lexicon, 3, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e47f8",
   "metadata": {},
   "source": [
    "## 2.5. Tagger 5 - BBC Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b284bd04",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e6e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_BBC = tag_climate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea125ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the lexicon\n",
    "BBC_Lexicon = pd.read_excel('lexicons-used.xlsx', sheet_name = \"EPA\", header = None)\n",
    "BBC_Lexicon = pd.DataFrame(BBC_Lexicon[0])\n",
    "BBC_Lexicon.columns = [\"Lexicon\"]\n",
    "\n",
    "BBC_Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd130ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the text\n",
    "tag_BBC[\"Text\"] = tag_BBC[\"Text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfcfd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_metrics_1(tag_BBC, BBC_Lexicon, 1, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23e9fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_metrics_2(tag_BBC, BBC_Lexicon, 0, 1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aade8b",
   "metadata": {},
   "source": [
    "## 2.6. Tagger 6 - UNDP Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bae000f",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2452ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_UNDP = tag_climate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66d51e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the lexicon\n",
    "UNDP_Lexicon = pd.read_excel('lexicons-used.xlsx', sheet_name = \"UNDP\", header = None)\n",
    "UNDP_Lexicon = pd.DataFrame(UNDP_Lexicon[0])\n",
    "UNDP_Lexicon.columns = [\"Lexicon\"]\n",
    "\n",
    "UNDP_Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab9a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the text\n",
    "tag_UNDP[\"Text\"] = tag_UNDP[\"Text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0404ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_metrics_1(tag_UNDP, UNDP_Lexicon, 1, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f4ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_metrics_2(tag_UNDP, UNDP_Lexicon, 0, 1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f17fb2",
   "metadata": {},
   "source": [
    "## 2.5. Tagger 5 - Global Change Lexicon & IPCC Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda6d4c1",
   "metadata": {},
   "source": [
    "uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9935fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag5_GC_IPCC = tag_climate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d39eee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the lexicon\n",
    "l1 = pd.read_excel('lexicons-used.xlsx', sheet_name = \"Global Change\", header = None)\n",
    "l2 = pd.read_excel('lexicons-used.xlsx', sheet_name = \"IPCC\", header = None)\n",
    "\n",
    "GC_IPCC_Lexicon = pd.concat([l1, l2]).reset_index(drop = True)\n",
    "GC_IPCC_Lexicon = pd.DataFrame(GC_IPCC_Lexicon[0])\n",
    "GC_IPCC_Lexicon.columns = [\"Lexicon\"]\n",
    "\n",
    "GC_IPCC_Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04af049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag5_GC_IPCC[\"Text\"] = tag5_GC_IPCC[\"Text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e742dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_metrics_1(tag5_GC_IPCC, GC_IPCC_Lexicon, 1, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba42a11",
   "metadata": {},
   "source": [
    "## 2.6. Tagger 6 - Global Change Lexicon & Wikipedia Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476b68be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag5_GC_W = tag_climate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab4a3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the lexicon\n",
    "l1 = pd.read_excel('lexicons-used.xlsx', sheet_name = \"Global Change\", header = None)\n",
    "l2 = pd.read_excel('lexicons-used.xlsx', sheet_name = \"Wikipedia\", header = None)\n",
    "\n",
    "GC_W_Lexicon = pd.concat([l1, l2]).reset_index(drop = True)\n",
    "GC_W_Lexicon = pd.DataFrame(GC_W_Lexicon[0])\n",
    "GC_W_Lexicon.columns = [\"Lexicon\"]\n",
    "\n",
    "GC_W_Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80d960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag5_GC_W[\"Text\"] = tag5_GC_W[\"Text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fa3cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_metrics_1(tag5_GC_W, GC_W_Lexicon, 1, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a49d213",
   "metadata": {},
   "source": [
    "## 2.7. Tagger 7 - IPCC Lexicon & Wikipedia Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebebb7fd",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be682ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag5_IPCC_W = tag_climate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa6ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the lexicon\n",
    "l1 = pd.read_excel('lexicons-used.xlsx', sheet_name = \"IPCC\", header = None)\n",
    "l2 = pd.read_excel('lexicons-used.xlsx', sheet_name = \"Wikipedia\", header = None)\n",
    "\n",
    "IPCC_W_Lexicon = pd.concat([l1, l2]).reset_index(drop = True)\n",
    "IPCC_W_Lexicon = pd.DataFrame(IPCC_W_Lexicon[0])\n",
    "IPCC_W_Lexicon.columns = [\"Lexicon\"]\n",
    "\n",
    "IPCC_W_Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bd585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag5_IPCC_W[\"Text\"] = tag5_IPCC_W[\"Text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8696e9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_metrics_1(tag5_IPCC_W, IPCC_W_Lexicon, 1, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1023c8e",
   "metadata": {},
   "source": [
    "## Tagger 8 - Wikipedia Lexicon & EPA Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed82b15a",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79451be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag8_W_EPA = tag_climate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2325a0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the lexicon\n",
    "l1 = pd.read_excel('lexicons-used.xlsx', sheet_name = \"Wikipedia\", header = None)\n",
    "l2 = pd.read_excel('lexicons-used.xlsx', sheet_name = \"EPA\", header = None)\n",
    "\n",
    "W_EPA_Lexicon = pd.concat([l1, l2]).reset_index(drop = True)\n",
    "W_EPA_Lexicon = pd.DataFrame(W_EPA_Lexicon[0])\n",
    "W_EPA_Lexicon.columns = [\"Lexicon\"]\n",
    "\n",
    "W_EPA_Lexicon = W_EPA_Lexicon.drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aa062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag8_W_EPA[\"Text\"] = tag8_W_EPA[\"Text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cb7834",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_metrics_1(tag8_W_EPA, W_EPA_Lexicon, 5, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0e8944",
   "metadata": {},
   "source": [
    "## 2.9. Tagger 9 - UNDP Lexicon & Wikipedia Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52382d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_W_UNDP = tag_climate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba85c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the lexicon\n",
    "l1 = pd.read_excel('lexicons-used.xlsx', sheet_name = \"Wikipedia\", header = None)\n",
    "l2 = pd.read_excel('lexicons-used.xlsx', sheet_name = \"UNDP\", header = None)\n",
    "\n",
    "W_UNDP_Lexicon = pd.concat([l1, l2]).reset_index(drop = True)\n",
    "W_UNDP_Lexicon = pd.DataFrame(W_UNDP_Lexicon[0])\n",
    "W_UNDP_Lexicon.columns = [\"Lexicon\"]\n",
    "\n",
    "W_UNDP_Lexicon = W_UNDP_Lexicon.drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e477d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_W_UNDP[\"Text\"] = tag_W_UNDP[\"Text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18cda8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_metrics_1(tag_W_UNDP, W_UNDP_Lexicon, 1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07c5f35",
   "metadata": {},
   "source": [
    "## 2.10. Tagger 10 - UNDP Lexicon & EPA Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aa640e",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40faf835",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_UNDP_EPA = tag_climate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781e12e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the lexicon\n",
    "l1 = pd.read_excel('lexicons-used.xlsx', sheet_name = \"EPA\", header = None)\n",
    "l2 = pd.read_excel('lexicons-used.xlsx', sheet_name = \"UNDP\", header = None)\n",
    "\n",
    "EPA_UNDP_Lexicon = pd.concat([l1, l2]).reset_index(drop = True)\n",
    "EPA_UNDP_Lexicon = pd.DataFrame(EPA_UNDP_Lexicon[0])\n",
    "EPA_UNDP_Lexicon.columns = [\"Lexicon\"]\n",
    "\n",
    "EPA_UNDP_Lexicon = EPA_UNDP_Lexicon.drop_duplicates().reset_index(drop = True)\n",
    "EPA_UNDP_Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff383b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_UNDP_EPA[\"Text\"] = tag_UNDP_EPA[\"Text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53171e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_metrics_1(tag_UNDP_EPA, EPA_UNDP_Lexicon, 10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dd61ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_metrics_2(tag_UNDP_EPA, EPA_UNDP_Lexicon, 0, 1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076cbba9",
   "metadata": {},
   "source": [
    "## 2.11. Tagger 11 - UNDP Lexicon & EPA Lexicon & Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b8d8a9",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd14c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_UNDP_EPA_W = tag_climate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c62f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the lexicon\n",
    "l1 = pd.read_excel('lexicons-used.xlsx', sheet_name = \"EPA\", header = None)\n",
    "l2 = pd.read_excel('lexicons-used.xlsx', sheet_name = \"UNDP\", header = None)\n",
    "l3 = pd.read_excel('lexicons-used.xlsx', sheet_name = \"Wikipedia\", header = None)\n",
    "\n",
    "W_EPA_UNDP_Lexicon = pd.concat([l1, l2, l3]).reset_index(drop = True)\n",
    "W_EPA_UNDP_Lexicon = pd.DataFrame(W_EPA_UNDP_Lexicon[0])\n",
    "W_EPA_UNDP_Lexicon.columns = [\"Lexicon\"]\n",
    "\n",
    "W_EPA_UNDP_Lexicon = W_EPA_UNDP_Lexicon.drop_duplicates().reset_index(drop = True)\n",
    "W_EPA_UNDP_Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c80ec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_UNDP_EPA_W[\"Text\"] = tag_UNDP_EPA_W[\"Text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173c8d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_metrics_2(tag_UNDP_EPA_W, W_EPA_UNDP_Lexicon, 1, 2, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c390d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_metrics_1(tag_UNDP_EPA_W, W_EPA_UNDP_Lexicon, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53737e8c",
   "metadata": {},
   "source": [
    "# 3. Tagging Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b72304",
   "metadata": {},
   "source": [
    "## 3.1. Import Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e77054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
