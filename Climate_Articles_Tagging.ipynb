{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03bc61ae",
   "metadata": {},
   "source": [
    "# 0. Packages and Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35166737",
   "metadata": {},
   "source": [
    "## 0.1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "cb19815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e8cedf",
   "metadata": {},
   "source": [
    "## 0.2. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "c30097ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-process text for lexicon based approaches\n",
    "def preprocess_text(text):\n",
    "    # remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # convert to lower case\n",
    "    text = text.lower()\n",
    "    # remove blank spaces\n",
    "    text = ' '.join(text.split())\n",
    "    # remove newline characters\n",
    "    text = text.replace('\\n', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "fa47879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function that take the dataframe, lexicon and n-gram value (how many n-grams should be considered) and determine the \n",
    "#count of words in dataframe text that match the lexicon\n",
    "def count_lexicon_words(text_df, lexicon):\n",
    "    lexicon = lexicon[\"Lexicon\"]\n",
    "    count = []\n",
    "    \n",
    "    for text in text_df[\"Text\"]:\n",
    "        lexicon_matches = 0\n",
    "    \n",
    "        for word in lexicon:\n",
    "            if word.lower() in text:\n",
    "                lexicon_matches += 1\n",
    "        \n",
    "        count.append(lexicon_matches)\n",
    "        \n",
    "    text_df[\"Lexicon Count\"] = count\n",
    "    \n",
    "    return(text_df)\n",
    "\n",
    "#create a function that used the lexicon approach to determine with the target is yes or no\n",
    "def lexicon_target_classifier(df, treshold):\n",
    "    target = []\n",
    "    \n",
    "    count = df[\"Lexicon Count\"]\n",
    "    \n",
    "    for c in count:\n",
    "        if c < treshold:\n",
    "            target.append(\"No\")\n",
    "        else:\n",
    "            target.append(\"Yes\")\n",
    "            \n",
    "    df[\"Target Lexicon\"] = target\n",
    "    return(df)\n",
    "\n",
    "#Combine both functions to classify articles based on the lexicon\n",
    "def lexicon_climate_classifier(text_df, lexicon, treshold):\n",
    "    df = count_lexicon_words(text_df, lexicon)\n",
    "    \n",
    "    return(lexicon_target_classifier(df, treshold))\n",
    "\n",
    "def threshold_metrics(df_text, lexicon, min_treshhold, max_treshhold):\n",
    "    for i in range(min_treshhold, max_treshhold + 1):\n",
    "        df = lexicon_climate_classifier(df_text, lexicon, i)\n",
    "        cross_table = pd.crosstab(df['Target'], df['Target Lexicon'], margins=True)\n",
    "        \n",
    "        # calculate classification metrics using scikit-learn\n",
    "        accuracy = (cross_table.iloc[0,0] + cross_table.iloc[1,1]) / cross_table.loc['All','All']\n",
    "        precision = cross_table.iloc[1,1] / cross_table.iloc[0,1] if cross_table.iloc[0,1] != 0 else 0\n",
    "        recall = cross_table.iloc[1,1] / cross_table.iloc[1,0] if cross_table.iloc[1,0] != 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "        # print the metrics\n",
    "        print(\"Threshhold:\", i)\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall:\", recall)\n",
    "        print(\"F1 score:\", f1_score)\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9f1114",
   "metadata": {},
   "source": [
    "Accuracy: This metric measures the overall performance of a model. It is defined as the number of correct predictions divided by the total number of predictions. Accuracy is a good metric to use when the classes are roughly balanced, meaning there are about the same number of positive and negative examples in the dataset.\n",
    "\n",
    "Precision: This metric measures how many of the positive predictions made by a model are actually correct. It is defined as the number of true positives divided by the total number of positive predictions. Precision is a good metric to use when we care more about avoiding false positives than false negatives.\n",
    "\n",
    "Recall: This metric measures how many of the positive examples in the dataset are correctly predicted by the model. It is defined as the number of true positives divided by the total number of actual positive examples. Recall is a good metric to use when we care more about avoiding false negatives than false positives.\n",
    "\n",
    "F1 score: This metric is a weighted average of precision and recall, where the weight is determined by the beta parameter. The most common value for beta is 1, which gives equal weight to precision and recall. The F1 score is a good metric to use when we want to balance precision and recall, and when the classes are imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b115e3a8",
   "metadata": {},
   "source": [
    "# 1. Import Label Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "d1943319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Link</th>\n",
       "      <th>Is_climate</th>\n",
       "      <th>Sentiment_Label</th>\n",
       "      <th>Climate_Change_Topic</th>\n",
       "      <th>Level_Climate_Change_Topic</th>\n",
       "      <th>doubt</th>\n",
       "      <th>Sentiment_Label_R</th>\n",
       "      <th>Climate_Change_Topic_R</th>\n",
       "      <th>Level_Climate_Change_Topic_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>More than a dozen state attorneys general gath...</td>\n",
       "      <td>https://www.washingtonpost.com/news/energy-env...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sen. Jeff Merkley of Oregon endorsed Bernie S...</td>\n",
       "      <td>http://www.wsj.com/articles/campaign-wire-1460...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Small</td>\n",
       "      <td>False</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When Carmen Luna moved to a neighborhood on t...</td>\n",
       "      <td>https://www.wsj.com/articles/mexico-city-strug...</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As ocean warming continues to trigger widespre...</td>\n",
       "      <td>https://www.washingtonpost.com/national/health...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PG&amp;E Corp. told California regulators that it...</td>\n",
       "      <td>https://www.wsj.com/articles/pg-e-equipment-mi...</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  More than a dozen state attorneys general gath...   \n",
       "1   Sen. Jeff Merkley of Oregon endorsed Bernie S...   \n",
       "2   When Carmen Luna moved to a neighborhood on t...   \n",
       "3  As ocean warming continues to trigger widespre...   \n",
       "4   PG&E Corp. told California regulators that it...   \n",
       "\n",
       "                                                Link  Is_climate  \\\n",
       "0  https://www.washingtonpost.com/news/energy-env...        True   \n",
       "1  http://www.wsj.com/articles/campaign-wire-1460...        True   \n",
       "2  https://www.wsj.com/articles/mexico-city-strug...        True   \n",
       "3  https://www.washingtonpost.com/national/health...        True   \n",
       "4  https://www.wsj.com/articles/pg-e-equipment-mi...        True   \n",
       "\n",
       "  Sentiment_Label Climate_Change_Topic Level_Climate_Change_Topic  doubt  \\\n",
       "0               1                  Yes                     Medium  False   \n",
       "1               0                  Yes                      Small  False   \n",
       "2              -1                  Yes                     Medium  False   \n",
       "3               1                  Yes                       High  False   \n",
       "4              -1                  Yes                     Medium  False   \n",
       "\n",
       "  Sentiment_Label_R Climate_Change_Topic_R Level_Climate_Change_Topic_R  \n",
       "0               TBD                    TBD                          TBD  \n",
       "1               TBD                    TBD                          TBD  \n",
       "2               TBD                    TBD                          TBD  \n",
       "3               TBD                    TBD                          TBD  \n",
       "4               TBD                    TBD                          TBD  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_climate_df = pd.read_parquet(\"Final_Label_Table.parquet\")\n",
    "tag_climate_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "4de29b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only keep the required columns\n",
    "tag_climate_df = tag_climate_df[[\"Text\", \"Climate_Change_Topic\", \"Level_Climate_Change_Topic\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "5511dabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the tabel\n",
    "tag_climate_df['Level_Climate_Change_Topic'] = tag_climate_df['Level_Climate_Change_Topic'].str.strip()\n",
    "tag_climate_df[tag_climate_df[\"Level_Climate_Change_Topic\"] == \"NA\"] = \"Na\"\n",
    "tag_climate_df[tag_climate_df[\"Level_Climate_Change_Topic\"] == \"0\"] = \"Na\"\n",
    "tag_climate_df[\"Target\"] = tag_climate_df[\"Level_Climate_Change_Topic\"].apply(lambda x: \"Yes\" if x in [\"High\", \"Medium\"] else \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "a73a5997",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_labels_hms = tag_climate_df.groupby(\"Level_Climate_Change_Topic\")[\"Text\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "e2678780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level_Climate_Change_Topic</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>High</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Medium</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Na</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Small</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Level_Climate_Change_Topic  Text\n",
       "0                       High    71\n",
       "1                     Medium    32\n",
       "2                         Na    43\n",
       "3                      Small    55"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview_labels_hms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "9161b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_labels = tag_climate_df.groupby(\"Target\")[\"Text\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "7c15a217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Target  Text\n",
       "0     No    98\n",
       "1    Yes   103"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "30d9f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#overview_labels_hms.to_csv(\"C:/Users/Boedt/OneDrive/Bureaublad/R Thesis/overview_tag_labels_hms\", index = False)\n",
    "#overview_labels.to_csv(\"C:/Users/Boedt/OneDrive/Bureaublad/R Thesis/overview_tag_labels\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "a3cfc0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Climate_Change_Topic</th>\n",
       "      <th>Level_Climate_Change_Topic</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>More than a dozen state attorneys general gath...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sen. Jeff Merkley of Oregon endorsed Bernie S...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Small</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When Carmen Luna moved to a neighborhood on t...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As ocean warming continues to trigger widespre...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PG&amp;E Corp. told California regulators that it...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>BEIJING—China suspended its relaxation of a 2...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Small</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>WASHINGTON—President-elect Joe Biden is neari...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>President Trump’s recent blowup over General ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>So much about the planet’s future will depend ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>As House Democrats geared up for their first i...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Small</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text Climate_Change_Topic  \\\n",
       "0    More than a dozen state attorneys general gath...                  Yes   \n",
       "1     Sen. Jeff Merkley of Oregon endorsed Bernie S...                  Yes   \n",
       "2     When Carmen Luna moved to a neighborhood on t...                  Yes   \n",
       "3    As ocean warming continues to trigger widespre...                  Yes   \n",
       "4     PG&E Corp. told California regulators that it...                  Yes   \n",
       "..                                                 ...                  ...   \n",
       "196   BEIJING—China suspended its relaxation of a 2...                 Yes    \n",
       "197   WASHINGTON—President-elect Joe Biden is neari...                  Yes   \n",
       "198   President Trump’s recent blowup over General ...                  Yes   \n",
       "199  So much about the planet’s future will depend ...                  Yes   \n",
       "200  As House Democrats geared up for their first i...                  Yes   \n",
       "\n",
       "    Level_Climate_Change_Topic Target  \n",
       "0                       Medium    Yes  \n",
       "1                        Small     No  \n",
       "2                       Medium    Yes  \n",
       "3                         High    Yes  \n",
       "4                       Medium    Yes  \n",
       "..                         ...    ...  \n",
       "196                      Small     No  \n",
       "197                       High    Yes  \n",
       "198                     Medium    Yes  \n",
       "199                       High    Yes  \n",
       "200                      Small     No  \n",
       "\n",
       "[201 rows x 4 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_climate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e44f9d4",
   "metadata": {},
   "source": [
    "# 2. Taggers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a701b65c",
   "metadata": {},
   "source": [
    "## 2.1. Tagger 1 - Global Change Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4076a4",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "3ed5d2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the dataframe in a different one, for the purpose of this lexicon. This way there is no confusion.\n",
    "tag1_Global_Change = tag_climate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "7204f120",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the lexicon\n",
    "Global_Change_Lexicon = pd.read_excel('lexicons-used.xlsx', sheet_name = \"Global Change\", header = None)\n",
    "Global_Change_Lexicon.columns = [\"Lexicon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "4aba830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the text\n",
    "tag1_Global_Change[\"Text\"] = tag1_Global_Change[\"Text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "2f50137a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshhold: 1\n",
      "Accuracy: 0.5323383084577115\n",
      "Precision: 1.0957446808510638\n",
      "Recall: 0\n",
      "F1 score: 0.0\n",
      "\n",
      "\n",
      "Threshhold: 2\n",
      "Accuracy: 0.6069651741293532\n",
      "Precision: 1.4444444444444444\n",
      "Recall: 3.12\n",
      "F1 score: 1.9746835443037973\n",
      "\n",
      "\n",
      "Threshhold: 3\n",
      "Accuracy: 0.6169154228855721\n",
      "Precision: 2.130434782608696\n",
      "Recall: 0.9074074074074074\n",
      "F1 score: 1.2727272727272727\n",
      "\n",
      "\n",
      "Threshhold: 4\n",
      "Accuracy: 0.5920398009950248\n",
      "Precision: 3.625\n",
      "Recall: 0.3918918918918919\n",
      "F1 score: 0.7073170731707317\n",
      "\n",
      "\n",
      "Threshhold: 5\n",
      "Accuracy: 0.5771144278606966\n",
      "Precision: 19.0\n",
      "Recall: 0.2261904761904762\n",
      "F1 score: 0.4470588235294118\n",
      "\n",
      "\n",
      "Threshhold: 6\n",
      "Accuracy: 0.527363184079602\n",
      "Precision: 9.0\n",
      "Recall: 0.09574468085106383\n",
      "F1 score: 0.1894736842105263\n",
      "\n",
      "\n",
      "Threshhold: 7\n",
      "Accuracy: 0.4975124378109453\n",
      "Precision: 0\n",
      "Recall: 0.019801980198019802\n",
      "F1 score: 0.0\n",
      "\n",
      "\n",
      "Threshhold: 8\n",
      "Accuracy: 0.4925373134328358\n",
      "Precision: 0\n",
      "Recall: 0.00980392156862745\n",
      "F1 score: 0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold_metrics(tag1_Global_Change, Global_Change_Lexicon, 1, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04c3e6e",
   "metadata": {},
   "source": [
    "## 2.2. Tagger 2 - IPCC Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58be8e15",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "075c2661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the dataframe in a different one, for the purpose of this lexicon. This way there is no confusion.\n",
    "tag2_IPCC = tag_climate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "66be1dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acceptability of policy or system change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adaptability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adaptation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adaptation behaviour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adaptation limits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>SDGs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>TCRE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>TOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>UNFCCC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>423 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Lexicon\n",
       "0    Acceptability of policy or system change\n",
       "1                                Adaptability\n",
       "2                                  Adaptation\n",
       "3                        Adaptation behaviour\n",
       "4                           Adaptation limits\n",
       "..                                        ...\n",
       "418                                        SD\n",
       "419                                      SDGs\n",
       "420                                      TCRE\n",
       "421                                       TOD\n",
       "422                                    UNFCCC\n",
       "\n",
       "[423 rows x 1 columns]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the lexicon\n",
    "IPCC_Lexicon = pd.read_excel('lexicons-used.xlsx', sheet_name = \"IPCC\", header = None)\n",
    "IPCC_Lexicon.columns = [\"Lexicon\"]\n",
    "\n",
    "IPCC_Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "a8b353f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the text\n",
    "tag2_IPCC[\"Text\"] = tag2_IPCC[\"Text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "0e8bde6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshhold: 1\n",
      "Accuracy: 0.527363184079602\n",
      "Precision: 1.0842105263157895\n",
      "Recall: 0\n",
      "F1 score: 0.0\n",
      "\n",
      "\n",
      "Threshhold: 2\n",
      "Accuracy: 0.527363184079602\n",
      "Precision: 1.0842105263157895\n",
      "Recall: 0\n",
      "F1 score: 0.0\n",
      "\n",
      "\n",
      "Threshhold: 3\n",
      "Accuracy: 0.527363184079602\n",
      "Precision: 1.0842105263157895\n",
      "Recall: 0\n",
      "F1 score: 0.0\n",
      "\n",
      "\n",
      "Threshhold: 4\n",
      "Accuracy: 0.527363184079602\n",
      "Precision: 1.0842105263157895\n",
      "Recall: 0\n",
      "F1 score: 0.0\n",
      "\n",
      "\n",
      "Threshhold: 5\n",
      "Accuracy: 0.5174129353233831\n",
      "Precision: 1.0638297872340425\n",
      "Recall: 33.333333333333336\n",
      "F1 score: 2.0618556701030926\n",
      "\n",
      "\n",
      "Threshhold: 6\n",
      "Accuracy: 0.5074626865671642\n",
      "Precision: 1.043010752688172\n",
      "Recall: 16.166666666666668\n",
      "F1 score: 1.9595959595959596\n",
      "\n",
      "\n",
      "Threshhold: 7\n",
      "Accuracy: 0.4925373134328358\n",
      "Precision: 1.010989010989011\n",
      "Recall: 8.363636363636363\n",
      "F1 score: 1.803921568627451\n",
      "\n",
      "\n",
      "Threshhold: 8\n",
      "Accuracy: 0.47761194029850745\n",
      "Precision: 0.978021978021978\n",
      "Recall: 6.357142857142857\n",
      "F1 score: 1.6952380952380952\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold_metrics(tag2_IPCC, IPCC_Lexicon, 1, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c5dc3d",
   "metadata": {},
   "source": [
    "## 2.3. Tagger 3 - Wikipedia Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3f7dbf",
   "metadata": {},
   "source": [
    "Uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "e18df070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the dataframe in a different one, for the purpose of this lexicon. This way there is no confusion.\n",
    "tag3_Wikipedia = tag_climate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "2822d156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexicon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100,000-year problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adaptation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>additionality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>albedo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anoxic event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>volcanism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>water vapor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>World Climate Report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Younger Dryas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Lexicon\n",
       "0    100,000-year problem\n",
       "1              adaptation\n",
       "2           additionality\n",
       "3                  albedo\n",
       "4            anoxic event\n",
       "..                    ...\n",
       "159             volcanism\n",
       "160           water vapor\n",
       "161               weather\n",
       "162  World Climate Report\n",
       "163         Younger Dryas\n",
       "\n",
       "[164 rows x 1 columns]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the lexicon\n",
    "Wikipedia_Lexicon = pd.read_excel('lexicons-used.xlsx', sheet_name = \"Wikipedia\", header = None)\n",
    "Wikipedia_Lexicon = pd.DataFrame(Wikipedia_Lexicon[0])\n",
    "Wikipedia_Lexicon.columns = [\"Lexicon\"]\n",
    "\n",
    "Wikipedia_Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "1342529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the text\n",
    "tag3_Wikipedia[\"Text\"] = tag3_Wikipedia[\"Text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "4fbbf280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshhold: 1\n",
      "Accuracy: 0.527363184079602\n",
      "Precision: 1.0842105263157895\n",
      "Recall: 0\n",
      "F1 score: 0.0\n",
      "\n",
      "\n",
      "Threshhold: 2\n",
      "Accuracy: 0.527363184079602\n",
      "Precision: 1.0842105263157895\n",
      "Recall: 0\n",
      "F1 score: 0.0\n",
      "\n",
      "\n",
      "Threshhold: 3\n",
      "Accuracy: 0.746268656716418\n",
      "Precision: 4.714285714285714\n",
      "Recall: 1.7837837837837838\n",
      "F1 score: 2.588235294117647\n",
      "\n",
      "\n",
      "Threshhold: 4\n",
      "Accuracy: 0.6567164179104478\n",
      "Precision: 18.0\n",
      "Recall: 0.5373134328358209\n",
      "F1 score: 1.0434782608695652\n",
      "\n",
      "\n",
      "Threshhold: 5\n",
      "Accuracy: 0.5671641791044776\n",
      "Precision: 17.0\n",
      "Recall: 0.19767441860465115\n",
      "F1 score: 0.3908045977011494\n",
      "\n",
      "\n",
      "Threshhold: 6\n",
      "Accuracy: 0.5174129353233831\n",
      "Precision: 0\n",
      "Recall: 0.061855670103092786\n",
      "F1 score: 0.0\n",
      "\n",
      "\n",
      "Threshhold: 7\n",
      "Accuracy: 0.4975124378109453\n",
      "Precision: 0\n",
      "Recall: 0.019801980198019802\n",
      "F1 score: 0.0\n",
      "\n",
      "\n",
      "Threshhold: 8\n",
      "Accuracy: 0.4975124378109453\n",
      "Precision: 0\n",
      "Recall: 0.019801980198019802\n",
      "F1 score: 0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold_metrics(tag3_Wikipedia, Wikipedia_Lexicon, 1, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885ba3e0",
   "metadata": {},
   "source": [
    "# 3. Tagging Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767a4c34",
   "metadata": {},
   "source": [
    "## 3.1. Import Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e8836e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
