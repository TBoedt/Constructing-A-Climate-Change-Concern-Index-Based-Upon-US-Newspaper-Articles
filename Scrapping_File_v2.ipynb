{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "285c4d9c",
   "metadata": {},
   "source": [
    "# 0. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d39ea7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from datetime import date, timedelta\n",
    "import random\n",
    "import threading\n",
    "import numpy\n",
    "import multiprocessing as np\n",
    "from multiprocessing import Pool\n",
    "import concurrent.futures\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91c53ad",
   "metadata": {},
   "source": [
    "# 1. Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e0c218",
   "metadata": {},
   "source": [
    "## 1.1. Loop Through Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1770ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daterange(start_date, end_date):\n",
    "    for n in range(int((end_date - start_date).days) + 1):\n",
    "        yield start_date + timedelta(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcdb837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Chrome()\n",
    "# driver.get(\"https://www.politico.com/search/20?adv=true&start=02/01/2016&end=02/01/2016\")\n",
    "# #print(driver.find_element(By.CSS_SELECTOR, \"a.button\").text)\n",
    "# print(driver.find_element(By.CSS_SELECTOR, \"a.button:nth-child(2)\").text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cd9278",
   "metadata": {},
   "source": [
    "# 2. Scraping News Media"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb1b56a",
   "metadata": {},
   "source": [
    "## 2.1. Wall Street Journal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746f9a4c",
   "metadata": {},
   "source": [
    "### 2.1.1. Function - Get URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b27213ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWallStreetJournalURLS(start_date, end_date, username, password):\n",
    "    #put dates in date format\n",
    "    start_date = datetime.strptime(start_date, \"%d/%m/%Y\")\n",
    "    end_date = datetime.strptime(end_date, \"%d/%m/%Y\")\n",
    "\n",
    "    #Define list of variables to store \n",
    "    WSJ_date = []\n",
    "    WSJ_link = []\n",
    "\n",
    "    #Go to the website\n",
    "    #fireFoxOptions = webdriver.FirefoxOptions()\n",
    "    #fireFoxOptions.add_argument('--ignore-certificate-errors')\n",
    "    #fireFoxOptions.add_argument('--allow-running-insecure-content')\n",
    "    #fireFoxOptions.add_argument(\"--headless\")\n",
    "    #fireFoxOptions.add_argument(\"--disable-gpu\")\n",
    "    #fireFoxOptions.add_argument(\"--no-sandbox\")\n",
    "    #user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.50 Safari/537.36'\n",
    "    #fireFoxOptions.add_argument(f'user-agent={user_agent}')\n",
    "    #driver_WSJ = webdriver.Firefox(options=fireFoxOptions)\n",
    "    driver_WSJ = webdriver.Firefox()\n",
    "    driver_WSJ.get(\"https://sso.accounts.dowjones.com/login-page?op=localop&scope=openid%20idp_id%20roles%20email%20given_name%20family_name%20djid%20djUsername%20djStatus%20trackid%20tags%20prts%20suuid%20createTimestamp&client_id=5hssEAdMy0mJTICnJNvC9TXEw3Va7jfO&response_type=code&redirect_uri=https%3A%2F%2Faccounts.wsj.com%2Fauth%2Fsso%2Flogin&nonce=ab6a473a-cfa6-4714-8fad-b6dff98f5f18&ui_locales=en-us-x-wsj-223-2&mars=-1&ns=prod%2Faccounts-wsj&state=8rChOTDzC_Y_AK-i.TJAixN_XjsWxwUEEPoHg2OPCaX6qRBu4nGSk5fqLliY4H0B5F7gj_57-XH-YBWGS&protocol=oauth2&client=5hssEAdMy0mJTICnJNvC9TXEw3Va7jfO#!/signin\")\n",
    "\n",
    "    #put in user_name:\n",
    "    time.sleep(3) #makes sure field is fully loaded\n",
    "    username_field = driver_WSJ.find_element(By.XPATH, \"/html/body/div[1]/div[2]/div/div/div/div[1]/div[1]/form/div[2]/div[1]/div[2]/input\")\n",
    "    username_field.send_keys(username)\n",
    "\n",
    "    #continue to password:\n",
    "    driver_WSJ.find_element(By.XPATH, \"/html/body/div[1]/div[2]/div/div/div/div[1]/div[1]/form/div[2]/div[6]/div[1]/button[2]\").click()\n",
    "\n",
    "    #input password:\n",
    "    time.sleep(3) #makes sure field is fully loaded\n",
    "    password_field = driver_WSJ.find_element(By.XPATH, \"//*[@id='password-login-password']\")\n",
    "    password_field.send_keys(password)\n",
    "\n",
    "    #click on sign in:\n",
    "    driver_WSJ.find_element(By.XPATH, \"//*[@id='password-login']/div/form/div/div[5]/div[1]/button\").click()\n",
    "\n",
    "    try:\n",
    "        #accept cookies\n",
    "        time.sleep(10)\n",
    "        driver_WSJ.switch_to.frame(WebDriverWait(driver_WSJ,30).until(EC.presence_of_element_located((By.ID, 'sp_message_iframe_718122'))))\n",
    "        driver_WSJ.find_element(By.CSS_SELECTOR, \"button.message-component:nth-child(2)\").click()\n",
    "        driver_WSJ.switch_to.default_content() \n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    scrape_time = time.time() #starting the timing\n",
    "\n",
    "    for single_date in daterange(start_date, end_date):\n",
    "        date = single_date.strftime(\"%d/%m/%Y\")\n",
    "        print(date)\n",
    "        year = \"%02d\" % (int(date.split('/')[2]),)\n",
    "        month = \"%02d\" % (int(date.split('/')[1]),)\n",
    "        day = \"%02d\" % (int(date.split('/')[0]),)\n",
    "        page = \"%02d\" % (1,) #we assume there is always at least one page\n",
    "        url = f\"https://www.wsj.com/news/archive/{year}/{month}/{day}?page={page}\"\n",
    "        test = 0\n",
    "        while(test < 100):\n",
    "            try:\n",
    "                driver_WSJ.get(url) #go to the page in the WSJ archive for the given date\n",
    "                break\n",
    "            except:\n",
    "                test += 1\n",
    "                time.sleep(10)\n",
    "\n",
    "        #check if there are multiple pages and if so, visit these as well\n",
    "        pages_load = 0\n",
    "        while(pages_load < 100):\n",
    "            try:\n",
    "                pages = WebDriverWait(driver_WSJ, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"WSJTheme--pagepicker-total--Kl350I1l \")))\n",
    "                page_total = re.findall(r'\\d+', pages.text)\n",
    "                nr_pages = int(page_total[0])\n",
    "                break\n",
    "            except:\n",
    "                pages_load += 1\n",
    "                driver_WSJ.get(url)\n",
    "\n",
    "        for p in range(1,nr_pages+1):\n",
    "            page = \"%02d\" % (p,)\n",
    "            url = f\"https://www.wsj.com/news/archive/{year}/{month}/{day}?page={page}\"\n",
    "            urls_load = 0\n",
    "            while(urls_load < 100):\n",
    "                try:\n",
    "                    driver_WSJ.get(url) #go to the page in the WSJ archive for the given date\n",
    "                    break\n",
    "                except:\n",
    "                    driver_WSJ.get(url)\n",
    "\n",
    "            #get the article urls for the articles on the other pages, if there are more than 1\n",
    "            articles = WebDriverWait(driver_WSJ,10).until(EC.presence_of_all_elements_located((By.TAG_NAME, \"article\")))\n",
    "            for a in range(0,len(articles)):\n",
    "                WSJ_link.append(articles[a].find_element(By.TAG_NAME, \"a\").get_attribute('href'))\n",
    "                WSJ_date.append(date)\n",
    "    \n",
    "    driver_WSJ.quit()\n",
    "    \n",
    "    WSJ = [\"Wall_Street_Journal\"] * len(WSJ_link)\n",
    "    data = {\"Date\" : WSJ_date, \"News Paper\" : WSJ, \"Link\" : WSJ_link}\n",
    "    Wall_Street_Journal = pd.DataFrame(data)\n",
    "\n",
    "    start_date = start_date.strftime(\"%d%m%Y\")\n",
    "    end_date = end_date.strftime(\"%d%m%Y\")\n",
    "    path = f\"Data/URLS/Wall_Street_Journal_{start_date}_{end_date}_URLS\"\n",
    "    Wall_Street_Journal.to_parquet(path) \n",
    "    \n",
    "    print(\"--- %s seconds ---\" % (time.time() - scrape_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217b3365",
   "metadata": {},
   "source": [
    "### 2.1.2. Function - Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f6db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWallStreetJournalArticles(username, password, dataframe):\n",
    "    WSJ_article_content = []\n",
    "    WSJ_title = []\n",
    "\n",
    "    #FIREFOX\n",
    "    #Declare the driver and go to website\n",
    "    #fireFoxOptions = webdriver.FirefoxOptions()\n",
    "    #fireFoxOptions.add_argument('--ignore-certificate-errors')\n",
    "    #fireFoxOptions.add_argument('--allow-running-insecure-content')\n",
    "    #fireFoxOptions.add_argument(\"--headless\")\n",
    "    #fireFoxOptions.add_argument(\"--disable-gpu\")\n",
    "    #fireFoxOptions.add_argument(\"--no-sandbox\")\n",
    "    #user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.50 Safari/537.36'\n",
    "    #fireFoxOptions.add_argument(f'user-agent={user_agent}')\n",
    "    #driver_WSJ = webdriver.Firefox(options=fireFoxOptions)\n",
    "    \n",
    "    #CHROME\n",
    "    # chrome_options = Options()\n",
    "    # chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "    # chrome_options.add_argument(\"--disable-extensions\")\n",
    "    # chrome_options.add_argument(\"--disable-gpu\")\n",
    "    # chrome_options.add_argument(\"--no-sandbox\") # linux only\n",
    "    # #chrome_options.add_argument(\"--headless\")\n",
    "    # user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36\"\n",
    "    # chrome_options.add_argument(f'user-agent={user_agent}')\n",
    "    # driver_WSJ = webdriver.Chrome(options=chrome_options)\n",
    "    driver_WSJ = webdriver.Chrome()\n",
    "    driver_WSJ.get(\"https://sso.accounts.dowjones.com/login-page?op=localop&scope=openid%20idp_id%20roles%20email%20given_name%20family_name%20djid%20djUsername%20djStatus%20trackid%20tags%20prts%20suuid%20updated_at&client_id=5hssEAdMy0mJTICnJNvC9TXEw3Va7jfO&response_type=code&redirect_uri=https%3A%2F%2Faccounts.wsj.com%2Fauth%2Fsso%2Flogin&nonce=5e93fe71-314a-44b9-bb2d-4a0e5a3167a4&ui_locales=en-us-x-wsj-223-2&mars=-1&ns=prod%2Faccounts-wsj&state=zJgHWictetlLHLG6.Uob1DvxnFA4kIkiqJAY80zp2N4FxS3WdBvV-VuTFdpM&protocol=oauth2&client=5hssEAdMy0mJTICnJNvC9TXEw3Va7jfO#!/signin\")\n",
    "\n",
    "    #put in user_name:\n",
    "    time.sleep(3) #makes sure field is fully loaded\n",
    "    username_field = driver_WSJ.find_element(By.XPATH, \"/html/body/div[1]/div[2]/div/div/div/div[1]/div[1]/form/div[2]/div[1]/div[2]/input\")\n",
    "    username_field.send_keys(username)\n",
    "\n",
    "    #continue to password:\n",
    "    driver_WSJ.find_element(By.XPATH, \"/html/body/div[1]/div[2]/div/div/div/div[1]/div[1]/form/div[2]/div[6]/div[1]/button[2]\").click()\n",
    "\n",
    "    #input password:\n",
    "    time.sleep(3) #makes sure field is fully loaded\n",
    "    password_field = driver_WSJ.find_element(By.XPATH, \"//*[@id='password-login-password']\")\n",
    "    password_field.send_keys(password)\n",
    "\n",
    "    #click on sign in:\n",
    "    driver_WSJ.find_element(By.XPATH, \"//*[@id='password-login']/div/form/div/div[5]/div[1]/button\").click()\n",
    "\n",
    "    try:\n",
    "        #accept cookies\n",
    "        time.sleep(20)\n",
    "        driver_WSJ.switch_to.default_content()\n",
    "        driver_WSJ.switch_to.frame(WebDriverWait(driver_WSJ,30).until(EC.presence_of_element_located((By.ID, 'sp_message_iframe_718122'))))\n",
    "        driver_WSJ.find_element(By.CSS_SELECTOR, \"button.message-component:nth-child(2)\").click()\n",
    "        print(\"accepted\")\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    scrape_time = time.time()\n",
    "    #go to all the articles and scrape the content\n",
    "    links  = list(dataframe[\"Link\"])\n",
    "    for u in range(0, len(links)):\n",
    "        trys = 0\n",
    "        while(trys < 1):\n",
    "            try:\n",
    "                driver_WSJ.get(links[u])\n",
    "                break\n",
    "            except:\n",
    "                trys += 1\n",
    "                time.sleep(10)\n",
    "\n",
    "        try:\n",
    "            content = driver_WSJ.find_element(By.TAG_NAME, 'article') \n",
    "            #extract the content and add to a variables\n",
    "            text = content.find_elements(By.TAG_NAME, 'p')\n",
    "            article_text = \"\"\n",
    "            for t in range(0,len(text)):\n",
    "                article_text += \" \" + text[t].text\n",
    "\n",
    "            WSJ_article_content.append(article_text) #add text to the list\n",
    "            #WSJ_article_content.append(content.text) #add text to the list\n",
    "\n",
    "        except: #we don't have access to the article\n",
    "            WSJ_article_content.append(\"NO ACCESS\")\n",
    "            pass #go back to page with all articles\n",
    "\n",
    "        try:\n",
    "            #collect the title as well\n",
    "            title = WebDriverWait(driver_WSJ,10).until(EC.presence_of_element_located((By.TAG_NAME, \"h1\"))).text\n",
    "            WSJ_title.append(title)\n",
    "        except:\n",
    "            try:\n",
    "                #there are 2 main formats in which the titles are present in the HTML\n",
    "                title = WebDriverWait(driver_WSJ,10).until(EC.presence_of_element_located((By.CLASS_NAME, \"bigTop__hed\"))).text\n",
    "                WSJ_title.append(title)\n",
    "\n",
    "            except:\n",
    "                #add error if there is some unexpected layout -> this way our arrays will be of the same length and we will be able\n",
    "                #to construct a dataframe in the end\n",
    "                WSJ_title.append(\"ERROR\")\n",
    "                pass\n",
    "\n",
    "    driver_WSJ.quit()\n",
    "\n",
    "    WSJ = [\"Wall_Street_Journal\"] * len(WSJ_article_content)\n",
    "    data = {\"Title\" : WSJ_title, \"Text\" : WSJ_article_content, \"Link\" : dataframe[\"Link\"]}\n",
    "    Wall_Street_Journal = pd.DataFrame(data)\n",
    "    Wall_Street_Journal = pd.merge(Wall_Street_Journal, dataframe, on = \"Link\")\n",
    "    \n",
    "    print(\"--- %s seconds ---\" % (time.time() - scrape_time))\n",
    "    return(Wall_Street_Journal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2cf9e1",
   "metadata": {},
   "source": [
    "## 2.2. Washington Post"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a6082c",
   "metadata": {},
   "source": [
    "### 2.2.1. Function - Get URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a32e3729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWashingtonPostURLS(start_date, end_date, username, password):\n",
    "    #put dates in date format\n",
    "    start_date = datetime.strptime(start_date, \"%d/%m/%Y\")   \n",
    "    end_date = datetime.strptime(end_date, \"%d/%m/%Y\")\n",
    "\n",
    "\n",
    "    #put them in correct format\n",
    "\n",
    "\n",
    "    #Declare all list variables for the output\n",
    "    WP_date = []\n",
    "    WP_link = []\n",
    "    \n",
    "    #FIREFOX\n",
    "    #Declare the driver and go to website\n",
    "    #fireFoxOptions = webdriver.FirefoxOptions()\n",
    "    #fireFoxOptions.add_argument('--ignore-certificate-errors')\n",
    "    #fireFoxOptions.add_argument('--allow-running-insecure-content')\n",
    "    #fireFoxOptions.add_argument(\"--headless\")\n",
    "    #fireFoxOptions.add_argument(\"--disable-gpu\")\n",
    "    #fireFoxOptions.add_argument(\"--no-sandbox\")\n",
    "    #user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.50 Safari/537.36'\n",
    "    #fireFoxOptions.add_argument(f'user-agent={user_agent}')\n",
    "    #driver = webdriver.Firefox(options=fireFoxOptions)\n",
    "    \n",
    "    #CHROME\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--disable-extensions\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\") # linux only\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36\"\n",
    "    chrome_options.add_argument(f'user-agent={user_agent}')\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver = webdriver.Chrome()\n",
    "    # Initialize the driver\n",
    "\n",
    "\n",
    "    #Go the the searchpage of the Washington Post\n",
    "    driver.get(\"https://www.washingtonpost.com/search/?query=+&facets=%7B%22time%22%3A%22all%22%2C%22sort%22%3A%22relevancy%22%2C%22section%22%3A%5B%5D%2C%22author%22%3A%5B%5D%7D\")\n",
    "    #Accept Cookies\n",
    "    try:\n",
    "        driver.save_screenshot(\"cookies.png\")\n",
    "        WebDriverWait(driver,20).until(EC.presence_of_element_located((By.ID, \"onetrust-accept-btn-handler\"))).click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #Log-in into Washington Post account\n",
    "    try: #it is possible that account is already logged in! \n",
    "        #Sign in into Washington Post account\n",
    "        #Click on Sign In\n",
    "        #WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='__next']/div[1]/nav/div[4]/div[2]/a/p\"))).click()\n",
    "        driver.get(\"https://www.washingtonpost.com/subscribe/signin/?next_url=https%3A%2F%2Fwww.washingtonpost.com&nid=top_pb_signin&arcId=&itid=nav_sign_in\")\n",
    "        time.sleep(5)\n",
    "        driver.save_screenshot(\"Login.png\")\n",
    "        #located username field\n",
    "        time.sleep(2) #field needs to completely load\n",
    "        username_field = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='username']\")))\n",
    "        username_field.send_keys(username) #send username\n",
    "        username_field.send_keys(Keys.RETURN) #press enter\n",
    "\n",
    "        #Located password field\n",
    "        time.sleep(2) #field needs to completely load\n",
    "        password_field = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='password']\")))\n",
    "        password_field.send_keys(password)\n",
    "        password_field.send_keys(Keys.ENTER)\n",
    "\n",
    "        #Go back to the search page\n",
    "        WebDriverWait(driver,10).until(EC.presence_of_element_located((By.CLASS_NAME, \"wpds-c-jlBemH \"))).click()\n",
    "        go_to_search = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.ID, \"query\")))\n",
    "        go_to_search.send_keys(search_term)\n",
    "        go_to_search.send_keys(Keys.ENTER)\n",
    "\n",
    "    except:\n",
    "        #you already logged-in -> continue \n",
    "        pass\n",
    "    \n",
    "    search_page_load = 0\n",
    "    while(search_page_load < 100):\n",
    "        try:\n",
    "            driver.get(\"https://www.washingtonpost.com/search/?query=+&facets=%7B%22time%22%3A%22all%22%2C%22sort%22%3A%22relevancy%22%2C%22section%22%3A%5B%5D%2C%22author%22%3A%5B%5D%7D\")\n",
    "            break\n",
    "        except:\n",
    "            search_page_load += 1\n",
    "            \n",
    "    scrape_time = time.time()\n",
    "    for single_date in daterange(start_date, end_date):\n",
    "        date = single_date.strftime(\"%m/%d/%y\")\n",
    "\n",
    "        #Locate the searchbar, send searchterm and press enter\n",
    "        \n",
    "        time.sleep(10)\n",
    "        driver.save_screenshot(\"Searchbar.png\")\n",
    "        searchbar = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.CLASS_NAME, \"aa-Input\")))\n",
    "        searchbar.send_keys(\" \")\n",
    "        searchbar.send_keys(Keys.ENTER)\n",
    "\n",
    "        #Select time period\n",
    "        #select periode specification\n",
    "        WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='main-content']/div[1]/section[2]/div[1]/button/div/div[2]/span\"))).click()\n",
    "\n",
    "        #select custom time\n",
    "        WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='main-content']/div[1]/section[2]/div[1]/div/div/div[1]/button/div/div[2]\"))).click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        #Send start date\n",
    "        WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='main-content']/div[1]/section[2]/div[1]/div/div/div[2]/div[1]/div/div/div[1]/input\"))).send_keys(date)\n",
    "\n",
    "        #Empty automatic end date\n",
    "        WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='main-content']/div[1]/section[2]/div[1]/div/div/div[2]/div[2]/div/div/div[1]/input\"))).clear()\n",
    "\n",
    "        #Send end date\n",
    "        WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='main-content']/div[1]/section[2]/div[1]/div/div/div[2]/div[2]/div/div/div[1]/input\"))).send_keys(date)\n",
    "\n",
    "        #Press Apply\n",
    "        WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='main-content']/div[1]/section[2]/div[1]/div/div/div[2]/button[2]\"))).click()\n",
    "        time.sleep(5)\n",
    "        driver.refresh()\n",
    "        #click to load more on the page untill no longer possible\n",
    "        loading = True\n",
    "        while(loading):\n",
    "            try:\n",
    "                WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='main-content']/div[1]/section[3]/button\"))).click()\n",
    "            except:\n",
    "                loading = False\n",
    "        \n",
    "        articles = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.TAG_NAME, \"article\")))\n",
    "\n",
    "        for a in range(0,len(articles)):\n",
    "            WP_link.append(articles[a].find_element(By.TAG_NAME, \"a\").get_attribute('href'))\n",
    "            WP_date.append(single_date.strftime(\"%d/%m/%Y\"))\n",
    "    \n",
    "    driver.quit()\n",
    "    \n",
    "    WP = [\"Washington_Post\"] * len(WP_link)\n",
    "    data = {\"Date\" : WP_date, \"News Paper\" : WP, \"Link\" : WP_link}\n",
    "    WashingtonPost = pd.DataFrame(data)\n",
    "\n",
    "    start_date = start_date.strftime(\"%d%m%Y\")\n",
    "    end_date = end_date.strftime(\"%d%m%Y\")\n",
    "    path = f\"Data/URLS/Washington_Post_{start_date}_{end_date}_URLS\"\n",
    "    #WashingtonPost.to_parquet(path) \n",
    "    return(WashingtonPost)\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - scrape_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c850d03",
   "metadata": {},
   "source": [
    "### 2.2.2. Function - Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cc19fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWashingtonPostArticles(username, password, dataframe):\n",
    "    WP_article_content = []\n",
    "    WP_title = []\n",
    "\n",
    "    #FIREFOX\n",
    "    #Declare the driver and go to website\n",
    "    #fireFoxOptions = webdriver.FirefoxOptions()\n",
    "    #fireFoxOptions.add_argument('--ignore-certificate-errors')\n",
    "    #fireFoxOptions.add_argument('--allow-running-insecure-content')\n",
    "    #fireFoxOptions.add_argument(\"--headless\")\n",
    "    #fireFoxOptions.add_argument(\"--disable-gpu\")\n",
    "    #fireFoxOptions.add_argument(\"--no-sandbox\")\n",
    "    #user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.50 Safari/537.36'\n",
    "    #fireFoxOptions.add_argument(f'user-agent={user_agent}')\n",
    "    #driver_WSJ = webdriver.Firefox(options=fireFoxOptions)\n",
    "\n",
    "    #CHROME\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--disable-extensions\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\") # linux only\n",
    "    #chrome_options.add_argument(\"--headless\")\n",
    "    user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36\"\n",
    "    chrome_options.add_argument(f'user-agent={user_agent}')\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    #driver = webdriver.Chrome()\n",
    "\n",
    "    #Go the the searchpage of the Washington Post\n",
    "    driver.get(\"https://www.washingtonpost.com/search/?query=+&facets=%7B%22time%22%3A%22all%22%2C%22sort%22%3A%22relevancy%22%2C%22section%22%3A%5B%5D%2C%22author%22%3A%5B%5D%7D\")\n",
    "\n",
    "    try:\n",
    "        #Accept Cookies\n",
    "        WebDriverWait(driver,10).until(EC.presence_of_element_located((By.ID, \"onetrust-accept-btn-handler\"))).click()\n",
    "    except:\n",
    "        print(\"no cookies\")\n",
    "        pass\n",
    "    #Log-in into Washington Post account\n",
    "    try: #it is possible that account is already logged in! \n",
    "\n",
    "        #Sign in into Washington Post account\n",
    "        #Click on Sign In\n",
    "        WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='__next']/div[1]/nav/div[4]/div[2]/a/p\"))).click()\n",
    "        print('signin attempted')\n",
    "        #located username field\n",
    "        time.sleep(2) #field needs to completely load\n",
    "        username_field = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='username']\")))\n",
    "        username_field.send_keys(username) #send username\n",
    "        username_field.send_keys(Keys.RETURN) #press enter\n",
    "\n",
    "        #Located password field\n",
    "        time.sleep(2) #field needs to completely load\n",
    "        password_field = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='password']\")))\n",
    "        password_field.send_keys(password)\n",
    "        password_field.send_keys(Keys.ENTER)\n",
    "\n",
    "        time.sleep(10)\n",
    "\n",
    "    except:\n",
    "        #you already logged-in -> continue \n",
    "        pass\n",
    "\n",
    "    scrape_time = time.time()\n",
    "    links = list(dataframe[\"Link\"])\n",
    "    for u in range(0, len(links)):\n",
    "            trys = 0\n",
    "            while(trys < 100):\n",
    "                try:\n",
    "                    #go to every article\n",
    "                    driver.get(links[u])\n",
    "                    break\n",
    "                except:\n",
    "                    trys += 1\n",
    "            try:\n",
    "                text = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.TAG_NAME, \"article\"))).text\n",
    "            except:\n",
    "                text = \"\"\n",
    "                \n",
    "            try:\n",
    "                text = text[text.index(\"Share\")+len(\"Share\")+1:text.rindex(\"Gift Article\")]\n",
    "                WP_article_content.append(text)\n",
    "            except:\n",
    "                try:\n",
    "                    text = text[text.index(\"Share\")+len(\"Share\")+1:text.rindex(\"Comments\")]\n",
    "                    WP_article_content.append(text)\n",
    "                except:\n",
    "                    try:\n",
    "                        text = text[text.index(\"tb.boedttibo\")+len(\"tb.boedttibo\")+1:text.rindex(\"Comments\")]\n",
    "                        WP_article_content.append(text)\n",
    "                    except:\n",
    "                        WP_article_content.append(text)\n",
    "                        pass\n",
    "            #idea is: We take the full text and before we have the article content the last pice of text is \"share\" and immediatly after the content\n",
    "            #we have \"comments\" this way we are able to only extract the article content\n",
    "            #the reasons for this is that each article has a more or less different html dependent on their \"type\"\n",
    "\n",
    "            #there are different formats of titles, in this order all titles are located\n",
    "            try:\n",
    "                title = driver.find_element(By.TAG_NAME, \"h1\").text\n",
    "                WP_title.append(title)\n",
    "            except:\n",
    "                WP_title.append(\"ERROR\")\n",
    "                pass\n",
    "\n",
    "    #Close driver\n",
    "    driver.quit()\n",
    "\n",
    "    #How long did the scraping took? \n",
    "    print(\"--- %s seconds ---\" % (time.time() - scrape_time))\n",
    "\n",
    "    #Create output file\n",
    "    #Make the dataframe\n",
    "    WP = [\"Washington Post\"] * len(WP_article_content)\n",
    "    data = {\"Title\" : WP_title, \"Text\" : WP_article_content, \"Date\" : dataframe[\"Date\"], \"News Paper\" : dataframe[\"News Paper\"], \"Link\" : dataframe[\"Link\"]}\n",
    "    WashingtonPost = pd.DataFrame(data)\n",
    "    return(WashingtonPost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d699e9f",
   "metadata": {},
   "source": [
    "## 2.3. New York Times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c29e7e",
   "metadata": {},
   "source": [
    "### 2.3.1. Function - Get URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec8d98ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNewYorkTimesURLS(start_date, end_date, username, password):\n",
    "    #put dates in date format\n",
    "    start_date = datetime.strptime(start_date, \"%d/%m/%Y\") \n",
    "    end_date = datetime.strptime(end_date, \"%d/%m/%Y\")\n",
    "\n",
    "    #Declare all list variables for the output\n",
    "    NYT_date = []\n",
    "    NYT_link = []\n",
    "\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "    chrome_options.add_argument(\"--disable-extensions\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\") # linux only\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36\"\n",
    "    chrome_options.add_argument(f'user-agent={user_agent}')\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(\"https://myaccount.nytimes.com/auth/login?response_type=cookie&client_id=vi&redirect_uri=https%3A%2F%2Fwww.nytimes.com%2Fsubscription%2Fonboarding-offer%3FcampaignId%3D7JFJX%26EXIT_URI%3Dhttps%253A%252F%252Fwww.nytimes.com%252F&asset=masthead\")\n",
    "    time.sleep(5)\n",
    "    driver.save_screenshot(\"test.png\")\n",
    "    #not a robot\n",
    "    input(\"Press Enter to continue...\")\n",
    "\n",
    "    #Select log-in field\n",
    "    login = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.ID, \"email\")))\n",
    "\n",
    "    #Send username\n",
    "    login.send_keys(username)\n",
    "\n",
    "    #Press continue\n",
    "    WebDriverWait(driver,10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#myAccountAuth > div > div > div > form > div > div.css-bho3kg-buttonWrapper-buttonStyles-Button > button\"))).click()\n",
    "\n",
    "    #Select password field\n",
    "    password_field = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.ID, \"password\")))\n",
    "\n",
    "    #send password\n",
    "    password_field.send_keys(password)\n",
    "\n",
    "    #Press continue\n",
    "    WebDriverWait(driver,10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#myAccountAuth > div > div > form > div > div.css-1nkv26b-buttonWrapper-buttonStyles-Button > button\"))).click()\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    #go to search page\n",
    "    search_page_loaded = 0\n",
    "    while(search_page_loaded < 100):\n",
    "        try:\n",
    "            driver.get(\"https://www.nytimes.com/search?dropmab=false&query=&sort=best\")\n",
    "            break\n",
    "        except:\n",
    "            search_page_loaded += 1\n",
    "\n",
    "    #Accept Cookies\n",
    "    try:\n",
    "        WebDriverWait(driver,5).until(EC.presence_of_element_located((By.CLASS_NAME, \"banner__container__cta--accept\"))).click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    scrape_time = time.time()\n",
    "    for single_date in daterange(start_date, end_date):\n",
    "        date = single_date.strftime(\"%Y%m%d\")\n",
    "\n",
    "        url = f\"https://www.nytimes.com/search?dropmab=false&endDate={date}&query=%20&sort=best&startDate={date}\"\n",
    "        url_loaded = 0\n",
    "        while(url_loaded < 100):\n",
    "            try:\n",
    "                driver.get(url)\n",
    "                break\n",
    "            except:\n",
    "                url_loaded += 1\n",
    "\n",
    "        #click to load more on the page untill no longer possible\n",
    "        loading = True\n",
    "        while(loading):\n",
    "            try:\n",
    "                WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='site-content']/div/div[2]/div[2]/div/button\"))).click()\n",
    "            except:\n",
    "                loading = False\n",
    "\n",
    "        articles = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"css-1l4w6pd\")))\n",
    "        dates = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"css-17ubb9w\")))\n",
    "\n",
    "        date_list = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"css-17ubb9w\")))\n",
    "        true_date = date_list[0].text\n",
    "        for a in range(0, len(articles)):\n",
    "            if(true_date == date_list[a].text):\n",
    "                NYT_link.append(articles[a].find_element(By.TAG_NAME, \"a\").get_attribute('href'))\n",
    "                NYT_date.append(single_date.strftime(\"%d/%m/%Y\"))\n",
    "    \n",
    "    driver.quit()\n",
    "    \n",
    "    NYT = [\"New_York_Times\"] * len(NYT_link)\n",
    "    data = {\"Date\" : NYT_date, \"News Paper\" : NYT, \"Link\" : NYT_link}\n",
    "    New_York_Times = pd.DataFrame(data)\n",
    "    \n",
    "    print(\"--- %s seconds ---\" % (time.time() - scrape_time))\n",
    "    \n",
    "    return(New_York_Times)\n",
    "    start_date = start_date.strftime(\"%d%m%Y\")\n",
    "    end_date = end_date.strftime(\"%d%m%Y\")\n",
    "    path = f\"Data/URLS/New_York_Times_{start_date}_{end_date}_URLS\"\n",
    "    New_York_Times.to_parquet(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce3650f",
   "metadata": {},
   "source": [
    "## 2.4. Politico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f600994",
   "metadata": {},
   "source": [
    "### 2.4.1. Function - Get URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "050ba84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPolitico(start_date, end_date):\n",
    "    #put dates in date format\n",
    "    end_date = datetime.strptime(end_date, \"%d/%m/%Y\")\n",
    "    start_date = datetime.strptime(start_date, \"%d/%m/%Y\")\n",
    "\n",
    "    #Declare all list variables for the output\n",
    "    P_date = []\n",
    "    P_link = []\n",
    "\n",
    "    fireFoxOptions = webdriver.FirefoxOptions()\n",
    "    fireFoxOptions.add_argument('--ignore-certificate-errors')\n",
    "    fireFoxOptions.add_argument('--allow-running-insecure-content')\n",
    "    fireFoxOptions.add_argument(\"--headless\")\n",
    "    fireFoxOptions.add_argument(\"--disable-gpu\")\n",
    "    fireFoxOptions.add_argument(\"--no-sandbox\")\n",
    "    user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.50 Safari/537.36'\n",
    "    fireFoxOptions.add_argument(f'user-agent={user_agent}')\n",
    "    driver = webdriver.Firefox(options=fireFoxOptions)\n",
    "\n",
    "    #go to the website\n",
    "    driver.get(\"https://www.politico.com/search?adv=true\")\n",
    "\n",
    "    #accept cookies\n",
    "    try:\n",
    "        WebDriverWait(driver,10).until(EC.presence_of_element_located((By.ID, \"onetrust-accept-btn-handler\"))).click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    scrape_time = time.time()\n",
    "    for single_date in daterange(start_date, end_date):\n",
    "        date = single_date.strftime(\"%m/%d/%Y\")\n",
    "        test = 0\n",
    "        while(test < 100):\n",
    "            try:\n",
    "                driver.get(f\"https://www.politico.com/search/1?adv=true&start={date}&end={date}\")\n",
    "                break\n",
    "            except:\n",
    "                test += 1\n",
    "                time.sleep(10)\n",
    "        articles = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.TAG_NAME, \"article\")))\n",
    "        for a in range(0, len(articles)):\n",
    "            P_link.append(articles[a].find_element(By.TAG_NAME, \"a\").get_attribute('href'))\n",
    "            P_date.append(date)\n",
    "\n",
    "        #get the number of pages to know how much you should click .pagination > ol:nth-child(2) > li:nth-child(3) > a:nth-child(1)\n",
    "        try:\n",
    "            nr_pages = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \".pagination > ol:nth-child(2) > li:nth-child(6) > a:nth-child(1)\"))).text\n",
    "        except:\n",
    "            nr_pages = 1\n",
    "            pass\n",
    "\n",
    "        for p in range(1, int(nr_pages)):\n",
    "            url = f\"https://www.politico.com/search/{p+1}?adv=true&start={date}&end={date}\"\n",
    "            driver.get(url)\n",
    "\n",
    "        articles = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.TAG_NAME, \"article\")))\n",
    "        for a in range(0, len(articles)):\n",
    "            P_link.append(articles[a].find_element(By.TAG_NAME, \"a\").get_attribute('href'))\n",
    "            P_date.append(single_date.strftime(\"%d/%m/%Y\"))\n",
    "\n",
    "    driver.quit()\n",
    "    print(\"--- %s seconds ---\" % (time.time() - scrape_time))\n",
    "\n",
    "    P = [\"Politico\"] * len(P_link)\n",
    "    data = {\"Date\" : P_date, \"News Paper\" : P, \"Link\" : P_link}\n",
    "    Politico = pd.DataFrame(data)\n",
    "\n",
    "    start_date = start_date.strftime(\"%d%m%Y\")\n",
    "    end_date = end_date.strftime(\"%d%m%Y\")\n",
    "    path = f\"Data/URLS/Politico_{start_date}_{end_date}_URLS\"\n",
    "    Politico.to_parquet(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0928dfb",
   "metadata": {},
   "source": [
    "# 3. Running Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc7e763",
   "metadata": {},
   "source": [
    "## 3.1. Wall Street Journal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa89ce63",
   "metadata": {},
   "source": [
    "## 3.2. Washington Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5515224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "WP_URLS = pd.read_parquet(\"Washington_Post_2017urls_to_scrape\").reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fc8ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #URLS_WP = pd.read_parquet(\"Washington_Post_2020_URLS\")\n",
    "# year=\"2016\"\n",
    "# URLS_WP = pd.read_parquet(\"Wall_Street_Journal_\"+year+\"_URLS(1)\")\n",
    "# URLS_WP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de2831a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>News Paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.wsj.com/articles/photos-of-the-day-...</td>\n",
       "      <td>Photos of the Day: Jan. 1</td>\n",
       "      <td>NO ACCESS</td>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.wsj.com/articles/chicago-marchers-m...</td>\n",
       "      <td>Chicago Marchers Mark Year of Violence</td>\n",
       "      <td>NO ACCESS</td>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.wsj.com/articles/re-energized-dolla...</td>\n",
       "      <td>Re-Energized Dollar Looms Over the Rest of the...</td>\n",
       "      <td>Write to Ira Iosebashvili a...</td>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.wsj.com/articles/new-jersey-town-ca...</td>\n",
       "      <td>New Jersey Town Calls on Uber to Solve Commute...</td>\n",
       "      <td>Write to Esther Fung at esther.fun...</td>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.wsj.com/articles/hawaiis-homeless-p...</td>\n",
       "      <td>Hawaii’s Homeless Problem Spurs Fixes, and a D...</td>\n",
       "      <td>Write to Alejandro Lazo at...</td>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38252</th>\n",
       "      <td>https://www.wsj.com/articles/funding-snapshot-...</td>\n",
       "      <td>Funding Snapshot: Mobile Video Startup LoopMe ...</td>\n",
       "      <td>NO ACCESS</td>\n",
       "      <td>07/03/2017</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38253</th>\n",
       "      <td>https://www.wsj.com/articles/sendgrid-acquires...</td>\n",
       "      <td>SendGrid Acquires Bizzy After Raising $33 Million</td>\n",
       "      <td>NO ACCESS</td>\n",
       "      <td>07/03/2017</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38254</th>\n",
       "      <td>https://www.wsj.com/articles/funding-snapshot-...</td>\n",
       "      <td>Funding Snapshot: Fintech Startup Current Clos...</td>\n",
       "      <td>NO ACCESS</td>\n",
       "      <td>07/03/2017</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38255</th>\n",
       "      <td>https://www.wsj.com/articles/funding-snapshot-...</td>\n",
       "      <td>Funding Snapshot: Farmer’s Business Network Se...</td>\n",
       "      <td>NO ACCESS</td>\n",
       "      <td>07/03/2017</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38256</th>\n",
       "      <td>https://www.wsj.com/articles/photos-of-the-day...</td>\n",
       "      <td>Photos of the Day: March 7</td>\n",
       "      <td>NO ACCESS</td>\n",
       "      <td>07/03/2017</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38257 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Link  \\\n",
       "0      http://www.wsj.com/articles/photos-of-the-day-...   \n",
       "1      http://www.wsj.com/articles/chicago-marchers-m...   \n",
       "2      http://www.wsj.com/articles/re-energized-dolla...   \n",
       "3      http://www.wsj.com/articles/new-jersey-town-ca...   \n",
       "4      http://www.wsj.com/articles/hawaiis-homeless-p...   \n",
       "...                                                  ...   \n",
       "38252  https://www.wsj.com/articles/funding-snapshot-...   \n",
       "38253  https://www.wsj.com/articles/sendgrid-acquires...   \n",
       "38254  https://www.wsj.com/articles/funding-snapshot-...   \n",
       "38255  https://www.wsj.com/articles/funding-snapshot-...   \n",
       "38256  https://www.wsj.com/articles/photos-of-the-day...   \n",
       "\n",
       "                                                   Title  \\\n",
       "0                              Photos of the Day: Jan. 1   \n",
       "1                 Chicago Marchers Mark Year of Violence   \n",
       "2      Re-Energized Dollar Looms Over the Rest of the...   \n",
       "3      New Jersey Town Calls on Uber to Solve Commute...   \n",
       "4      Hawaii’s Homeless Problem Spurs Fixes, and a D...   \n",
       "...                                                  ...   \n",
       "38252  Funding Snapshot: Mobile Video Startup LoopMe ...   \n",
       "38253  SendGrid Acquires Bizzy After Raising $33 Million   \n",
       "38254  Funding Snapshot: Fintech Startup Current Clos...   \n",
       "38255  Funding Snapshot: Farmer’s Business Network Se...   \n",
       "38256                         Photos of the Day: March 7   \n",
       "\n",
       "                                                    Text        Date  \\\n",
       "0                                              NO ACCESS  01/01/2017   \n",
       "1                                              NO ACCESS  01/01/2017   \n",
       "2                         Write to Ira Iosebashvili a...  01/01/2017   \n",
       "3                  Write to Esther Fung at esther.fun...  01/01/2017   \n",
       "4                          Write to Alejandro Lazo at...  01/01/2017   \n",
       "...                                                  ...         ...   \n",
       "38252                                          NO ACCESS  07/03/2017   \n",
       "38253                                          NO ACCESS  07/03/2017   \n",
       "38254                                          NO ACCESS  07/03/2017   \n",
       "38255                                          NO ACCESS  07/03/2017   \n",
       "38256                                          NO ACCESS  07/03/2017   \n",
       "\n",
       "                News Paper  \n",
       "0      Wall_Street_Journal  \n",
       "1      Wall_Street_Journal  \n",
       "2      Wall_Street_Journal  \n",
       "3      Wall_Street_Journal  \n",
       "4      Wall_Street_Journal  \n",
       "...                    ...  \n",
       "38252  Wall_Street_Journal  \n",
       "38253  Wall_Street_Journal  \n",
       "38254  Wall_Street_Journal  \n",
       "38255  Wall_Street_Journal  \n",
       "38256  Wall_Street_Journal  \n",
       "\n",
       "[38257 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URLS_WP = pd.read_parquet(\"Wall_Street_Journal_2017urls_to_scrape\")\n",
    "URLS_WP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adaf1e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update_2017 = getWashingtonPostArticles(\"tb.boedttibo@gmail.com\", \"ThesisR&T\", WP_URLS[1:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c344bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLS_WP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "400dbd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year = \"2016\"\n",
    "# source = 'Washington_Post_'\n",
    "# #source = \"Wall_Street_Journal_\"\n",
    "# ### check the most common results for error indicators\n",
    "# df = pd.read_parquet(source+year+\"_Articles\")\n",
    "# # print(df.size)\n",
    "# # pd.DataFrame(df['Text'].value_counts())\n",
    "\n",
    "# to_re_scrape = df[df['Text']== ''].reset_index().drop(['index'], axis=1)\n",
    "# URLS_WP = to_re_scrape\n",
    "# URLS_WP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ad7392e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accepted\n",
      "accepted\n",
      "accepted\n",
      "accepted\n",
      "--- 649.023964881897 seconds ---\n",
      "--- 966.1677751541138 seconds ---\n",
      "--- 994.9101903438568 seconds ---\n",
      "--- 1090.457921743393 seconds ---\n",
      "--------------------------\n",
      "--- 1126.9938366413116 seconds ---\n",
      "--------------------------\n",
      "2\n",
      "--------------------------\n",
      "accepted\n",
      "accepted\n",
      "accepted\n",
      "accepted\n"
     ]
    }
   ],
   "source": [
    "tijd = time.time()\n",
    "n=1\n",
    "# rescrape 3\n",
    "import concurrent.futures\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    while(n < 14):\n",
    "        k = 1000*n\n",
    "        # Submit the two instances of the scraping function to the executor\n",
    "        future1 = executor.submit(getWallStreetJournalArticles, \"reane.delaunoy@telenet.be\", \"REenJUC0MB0\", URLS_WP[k+1:k+250])\n",
    "        future2 = executor.submit(getWallStreetJournalArticles, \"reane.delaunoy@telenet.be\", \"REenJUC0MB0\", URLS_WP[k+251:k+500])\n",
    "        future3 = executor.submit(getWallStreetJournalArticles, \"reane.delaunoy@telenet.be\", \"REenJUC0MB0\", URLS_WP[k+501:k+750])\n",
    "        future4 = executor.submit(getWallStreetJournalArticles, \"reane.delaunoy@telenet.be\", \"REenJUC0MB0\", URLS_WP[k+751:k+1000])\n",
    "        # future1 = executor.submit(getWashingtonPostArticles,  \"tb.boedttibo@gmail.com\", \"ThesisR&T\", URLS_WP[k+1:k+250])\n",
    "        # future2 = executor.submit(getWashingtonPostArticles,  \"tb.boedttibo@gmail.com\", \"ThesisR&T\", URLS_WP[k+251:k+500])\n",
    "        # future3 = executor.submit(getWashingtonPostArticles,  \"tb.boedttibo@gmail.com\", \"ThesisR&T\", URLS_WP[k+501:k+750])\n",
    "        # future4 = executor.submit(getWashingtonPostArticles,  \"tb.boedttibo@gmail.com\", \"ThesisR&T\", URLS_WP[k+751:k+1000])\n",
    "        # Wait for the scraping functions to complete\n",
    "        concurrent.futures.wait([future1, future2, future3, future4])\n",
    "\n",
    "        print(\"--------------------------\")   \n",
    "        print(\"--- %s seconds ---\" % (time.time() - tijd))\n",
    "\n",
    "        result1= future1.result()\n",
    "        result2= future2.result()\n",
    "        result3= future3.result()\n",
    "        result4= future4.result()\n",
    "        frames = [result1, result2, result3, result4]\n",
    "        df = pd.concat(frames).reset_index(drop = True)\n",
    "        articles = pd.read_parquet(\"Wall_Street_Journal_2017_re-scraped\") \n",
    "        articles = pd.concat([articles, df]).reset_index(drop = True)\n",
    "        articles.to_parquet(\"Wall_Street_Journal_2017_re-scraped\")\n",
    "        #articles = pd.read_parquet(\"Washington_Post_\"+year+\"_Articles\")\n",
    "        #articles = pd.concat([articles, df]).reset_index(drop = True)\n",
    "        #articles.to_parquet(\"Washington_Post_\"+year+\"_Articles\")\n",
    "        n=n+1\n",
    "        print(\"--------------------------\")   \n",
    "        print(n)\n",
    "        print(\"--------------------------\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea6d4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_parquet(\"WSJ_missed_articles\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecddc2d8",
   "metadata": {},
   "source": [
    "result1= future1.result()\n",
    "result2= future2.result()\n",
    "result3= future3.result()\n",
    "result4= future4.result()\n",
    "frames = [result1, result2, result3, result4]\n",
    "df = pd.concat(frames).reset_index(drop = True)\n",
    "articles = pd.read_parquet(\"Washington_Post_2016_Articles\")\n",
    "articles = pd.concat([articles, df]).reset_index(drop = True)\n",
    "articles.to_parquet(\"Washington_Post_2016_Articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00e9a682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>News Paper</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>542</td>\n",
       "      <td>05/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/dr-gridloc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>792</td>\n",
       "      <td>06/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/opinions/whos-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1042</td>\n",
       "      <td>08/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/the-switch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1292</td>\n",
       "      <td>11/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/local/i-despise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1542</td>\n",
       "      <td>12/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/early-lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>48792</td>\n",
       "      <td>21/12/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/true-crime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>49042</td>\n",
       "      <td>23/12/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/national/for-wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>49292</td>\n",
       "      <td>27/12/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/lifestyle/magaz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>49542</td>\n",
       "      <td>29/12/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/sports/wp/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>49792</td>\n",
       "      <td>31/12/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/opinions/sidwel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index        Date       News Paper  \\\n",
       "0      542  05/01/2016  Washington_Post   \n",
       "1      792  06/01/2016  Washington_Post   \n",
       "2     1042  08/01/2016  Washington_Post   \n",
       "3     1292  11/01/2016  Washington_Post   \n",
       "4     1542  12/01/2016  Washington_Post   \n",
       "..     ...         ...              ...   \n",
       "193  48792  21/12/2016  Washington_Post   \n",
       "194  49042  23/12/2016  Washington_Post   \n",
       "195  49292  27/12/2016  Washington_Post   \n",
       "196  49542  29/12/2016  Washington_Post   \n",
       "197  49792  31/12/2016  Washington_Post   \n",
       "\n",
       "                                                  Link  \n",
       "0    https://www.washingtonpost.com/news/dr-gridloc...  \n",
       "1    https://www.washingtonpost.com/opinions/whos-r...  \n",
       "2    https://www.washingtonpost.com/news/the-switch...  \n",
       "3    https://www.washingtonpost.com/local/i-despise...  \n",
       "4    https://www.washingtonpost.com/news/early-lead...  \n",
       "..                                                 ...  \n",
       "193  https://www.washingtonpost.com/news/true-crime...  \n",
       "194  https://www.washingtonpost.com/national/for-wo...  \n",
       "195  https://www.washingtonpost.com/lifestyle/magaz...  \n",
       "196  https://www.washingtonpost.com/news/sports/wp/...  \n",
       "197  https://www.washingtonpost.com/opinions/sidwel...  \n",
       "\n",
       "[198 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which to re-scrape\n",
    "year = \"2016\"\n",
    "#source = 'Washington_Post_'\n",
    "source = \"Washington_Post_\"\n",
    "original_articles = pd.read_parquet(source+year+\"_Articles\")\n",
    "articles = pd.read_parquet(source+year+\"_Articles\")\n",
    "urls= pd.read_parquet(source+year+\"_URLS\")\n",
    "\n",
    "articles['Text'].replace('NO ACCESS', numpy.nan, inplace=True)\n",
    "articles['Text'].replace('404', numpy.nan, inplace=True)\n",
    "articles.dropna(subset=['Text'], inplace=True)\n",
    "\n",
    "df = pd.merge(urls, articles[['Link']], on=['Link','Link'], how=\"outer\", indicator=True\n",
    "              ).query('_merge==\"left_only\"').reset_index()\n",
    "to_re_scrape = df.loc[:, df.columns != '_merge']\n",
    "\n",
    "URLS_WP =to_re_scrape\n",
    "URLS_WP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3b7e9229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>News Paper</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>29/02/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/local/public-sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>By Kristen Hartke</td>\n",
       "      <td></td>\n",
       "      <td>29/02/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/national/health...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>29/02/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/sports/highscho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>This is what it's like to bake brownies when y...</td>\n",
       "      <td></td>\n",
       "      <td>29/02/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/national/health...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>By Gregory Lee Sullivan\\nFebruary 29, 2016</td>\n",
       "      <td></td>\n",
       "      <td>29/02/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/national/health...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49578</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/entertainment/b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49580</th>\n",
       "      <td>It’s high season for online dating — plot your...</td>\n",
       "      <td></td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/soloish/wp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49582</th>\n",
       "      <td>Odell Beckham Jr. vows to ‘learn’ from suspens...</td>\n",
       "      <td></td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/early-lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49583</th>\n",
       "      <td>Correction: An earlier version of this story h...</td>\n",
       "      <td></td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/local/dc-marche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49585</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/opinions/space-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11202 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Title Text        Date  \\\n",
       "7                                                              29/02/2016   \n",
       "8                                      By Kristen Hartke       29/02/2016   \n",
       "9                                                              29/02/2016   \n",
       "11     This is what it's like to bake brownies when y...       29/02/2016   \n",
       "12            By Gregory Lee Sullivan\\nFebruary 29, 2016       29/02/2016   \n",
       "...                                                  ...  ...         ...   \n",
       "49578                                                          01/01/2016   \n",
       "49580  It’s high season for online dating — plot your...       01/01/2016   \n",
       "49582  Odell Beckham Jr. vows to ‘learn’ from suspens...       01/01/2016   \n",
       "49583  Correction: An earlier version of this story h...       01/01/2016   \n",
       "49585                                                          01/01/2016   \n",
       "\n",
       "            News Paper                                               Link  \n",
       "7      Washington_Post  https://www.washingtonpost.com/local/public-sa...  \n",
       "8      Washington_Post  https://www.washingtonpost.com/national/health...  \n",
       "9      Washington_Post  https://www.washingtonpost.com/sports/highscho...  \n",
       "11     Washington_Post  https://www.washingtonpost.com/national/health...  \n",
       "12     Washington_Post  https://www.washingtonpost.com/national/health...  \n",
       "...                ...                                                ...  \n",
       "49578  Washington_Post  https://www.washingtonpost.com/entertainment/b...  \n",
       "49580  Washington_Post  https://www.washingtonpost.com/news/soloish/wp...  \n",
       "49582  Washington_Post  https://www.washingtonpost.com/news/early-lead...  \n",
       "49583  Washington_Post  https://www.washingtonpost.com/local/dc-marche...  \n",
       "49585  Washington_Post  https://www.washingtonpost.com/opinions/space-...  \n",
       "\n",
       "[11202 rows x 5 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#which to still scrape\n",
    "\n",
    "#df_empty = df[df['Text']==''].reset_index()\n",
    "# rescrape the ''1\\nComments\\n'' text ones\n",
    "# df_weird = df[df['Text']=='1\\nComments\\n'].reset_index()\n",
    "# df_weird\n",
    "#df_empty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e0d84f",
   "metadata": {},
   "source": [
    "#which to still scrape\n",
    "year = \"2016\"\n",
    "#source = 'Washington_Post_'\n",
    "source = \"Wall_Street_Journal_\"\n",
    "original_articles = pd.read_parquet(source+year+\"_Articles\")\n",
    "articles = pd.read_parquet(source+year+\"_Articles\")\n",
    "urls= pd.read_parquet(source+year+\"_URLS\")\n",
    "\n",
    "\n",
    "\n",
    "len(URLS_WP)\n",
    "articles\n",
    "\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3a9c74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(articles.duplicated(keep='last', subset = ['Link']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8733d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36428"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(articles['Title']== \"404\")\n",
    "len(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb21e2bd",
   "metadata": {},
   "source": [
    "## 3.3. New York Times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc311562",
   "metadata": {},
   "source": [
    "## 4. Clean scrapet articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70da76b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b04c4769",
   "metadata": {},
   "source": [
    "# 4. Analysing Scraping Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d476da0",
   "metadata": {},
   "source": [
    "## 4.1. Load in all Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffcb105",
   "metadata": {},
   "source": [
    "### Wall Street Journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8784dbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory path\n",
    "directory = \"C:/Users/Boedt/OneDrive/Bureaublad/Scraped_Articles/Wall Street Journal\"\n",
    "\n",
    "# Get a list of filenames in the directory\n",
    "filenames = os.listdir(directory)\n",
    "\n",
    "# Loop through the filenames and read each Parquet file into a DataFrame\n",
    "dfs = []\n",
    "for filename in filenames:\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    df = pd.read_parquet(filepath)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "WSJ_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4f06205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Link</th>\n",
       "      <th>Date</th>\n",
       "      <th>News Paper</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EU Approves Dell’s Takeover of EMC</td>\n",
       "      <td>BRUSSELS—The European Union on Monday approve...</td>\n",
       "      <td>http://www.wsj.com/articles/eu-approves-dells-...</td>\n",
       "      <td>29/02/2016</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Treasurys Headed for Another Monthly Gain</td>\n",
       "      <td>While Treasurys were boosted overnight by a 2...</td>\n",
       "      <td>http://www.wsj.com/articles/demand-for-austral...</td>\n",
       "      <td>29/02/2016</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Citi Reaches Deal for American Express’s Costc...</td>\n",
       "      <td>Citigroup Inc. C 1.18% reached a deal to buy ...</td>\n",
       "      <td>http://www.wsj.com/articles/citi-reaches-deal-...</td>\n",
       "      <td>29/02/2016</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jeff Immelt: GE ‘Underowned’ by Big Investors</td>\n",
       "      <td>Jeff Immelt says General Electric Co. GE 0.93...</td>\n",
       "      <td>http://www.wsj.com/articles/jeff-immelt-ge-und...</td>\n",
       "      <td>29/02/2016</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Eaton Vance Fund Launches but Isn’t Widely...</td>\n",
       "      <td>Eaton Vance Corp. hasn’t signed any major sec...</td>\n",
       "      <td>http://www.wsj.com/articles/new-eaton-vance-fu...</td>\n",
       "      <td>29/02/2016</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                 EU Approves Dell’s Takeover of EMC   \n",
       "1          Treasurys Headed for Another Monthly Gain   \n",
       "2  Citi Reaches Deal for American Express’s Costc...   \n",
       "3      Jeff Immelt: GE ‘Underowned’ by Big Investors   \n",
       "4  New Eaton Vance Fund Launches but Isn’t Widely...   \n",
       "\n",
       "                                                Text  \\\n",
       "0   BRUSSELS—The European Union on Monday approve...   \n",
       "1   While Treasurys were boosted overnight by a 2...   \n",
       "2   Citigroup Inc. C 1.18% reached a deal to buy ...   \n",
       "3   Jeff Immelt says General Electric Co. GE 0.93...   \n",
       "4   Eaton Vance Corp. hasn’t signed any major sec...   \n",
       "\n",
       "                                                Link        Date  \\\n",
       "0  http://www.wsj.com/articles/eu-approves-dells-...  29/02/2016   \n",
       "1  http://www.wsj.com/articles/demand-for-austral...  29/02/2016   \n",
       "2  http://www.wsj.com/articles/citi-reaches-deal-...  29/02/2016   \n",
       "3  http://www.wsj.com/articles/jeff-immelt-ge-und...  29/02/2016   \n",
       "4  http://www.wsj.com/articles/new-eaton-vance-fu...  29/02/2016   \n",
       "\n",
       "            News Paper  index  \n",
       "0  Wall_Street_Journal    NaN  \n",
       "1  Wall_Street_Journal    NaN  \n",
       "2  Wall_Street_Journal    NaN  \n",
       "3  Wall_Street_Journal    NaN  \n",
       "4  Wall_Street_Journal    NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WSJ_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80915afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set type of the date column to date\n",
    "WSJ_df[\"Date\"] = pd.to_datetime(WSJ_df['Date'], format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b34d3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the index column\n",
    "WSJ_df = WSJ_df.drop(\"index\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ab407e",
   "metadata": {},
   "source": [
    "### Washington Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20bc424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory path\n",
    "directory = \"C:/Users/Boedt/OneDrive/Bureaublad/Scraped_Articles/Washington Post\"\n",
    "\n",
    "# Get a list of filenames in the directory\n",
    "filenames = os.listdir(directory)\n",
    "\n",
    "# Loop through the filenames and read each Parquet file into a DataFrame\n",
    "dfs = []\n",
    "for filename in filenames:\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    df = pd.read_parquet(filepath)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "WP_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cf68cc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>News Paper</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daniel Winnik was ‘shocked’ to be traded to Ca...</td>\n",
       "      <td>Around 10:45 p.m., a Toronto number Daniel Win...</td>\n",
       "      <td>29/02/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/capitals-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JSOC commander tapped to lead Special Operatio...</td>\n",
       "      <td>Lt. Gen. Raymond “Tony” Thomas has been offici...</td>\n",
       "      <td>29/02/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/checkpoint...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chris Christie is setting himself up to be Rep...</td>\n",
       "      <td>Chris Christie is getting savaged for becoming...</td>\n",
       "      <td>29/02/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/the-fix/wp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lawsuit takes aim at asset forfeiture in Indiana</td>\n",
       "      <td>More here. Under the law, law enforcement agen...</td>\n",
       "      <td>29/02/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/the-watch/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Holly Holm says she won’t chase money with Ron...</td>\n",
       "      <td>Holly Holm fully understands that the most pro...</td>\n",
       "      <td>29/02/2016</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/early-lead...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Daniel Winnik was ‘shocked’ to be traded to Ca...   \n",
       "1  JSOC commander tapped to lead Special Operatio...   \n",
       "2  Chris Christie is setting himself up to be Rep...   \n",
       "3   Lawsuit takes aim at asset forfeiture in Indiana   \n",
       "4  Holly Holm says she won’t chase money with Ron...   \n",
       "\n",
       "                                                Text        Date  \\\n",
       "0  Around 10:45 p.m., a Toronto number Daniel Win...  29/02/2016   \n",
       "1  Lt. Gen. Raymond “Tony” Thomas has been offici...  29/02/2016   \n",
       "2  Chris Christie is getting savaged for becoming...  29/02/2016   \n",
       "3  More here. Under the law, law enforcement agen...  29/02/2016   \n",
       "4  Holly Holm fully understands that the most pro...  29/02/2016   \n",
       "\n",
       "        News Paper                                               Link  \n",
       "0  Washington_Post  https://www.washingtonpost.com/news/capitals-i...  \n",
       "1  Washington_Post  https://www.washingtonpost.com/news/checkpoint...  \n",
       "2  Washington_Post  https://www.washingtonpost.com/news/the-fix/wp...  \n",
       "3  Washington_Post  https://www.washingtonpost.com/news/the-watch/...  \n",
       "4  Washington_Post  https://www.washingtonpost.com/news/early-lead...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WP_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87acc593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set type of the date column to date\n",
    "WP_df[\"Date\"] = pd.to_datetime(WP_df['Date'], format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036473c3",
   "metadata": {},
   "source": [
    "## 4.2. Clean URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4cc52b",
   "metadata": {},
   "source": [
    "### Wall Street Journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e52ac3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "WSJ_duplicate_URLs = WSJ_df['Link'].value_counts()\n",
    "WSJ_duplicate_URLs = WSJ_duplicate_URLs[WSJ_duplicate_URLs > 1].reset_index()\n",
    "WSJ_duplicate_URLs.columns = ['Link', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bae5d1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.wsj.com/articles/why-apple-and-the-carriers-want-your-old-iphone-4279cc8d?mod=error_page'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WSJ_duplicate_URLs[\"Link\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ccd8eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Link</th>\n",
       "      <th>Date</th>\n",
       "      <th>News Paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Title, Text, Link, Date, News Paper]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WSJ_df[WSJ_df[\"Link\"] == WSJ_duplicate_URLs[\"Link\"][5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f24c32da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all the duplicate rows\n",
    "WSJ_df = WSJ_df.drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "55c68cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some URLs of the Wall Street Journal contain the string \"mod=error_page\". Once we look into this we see that these URLs lead us\n",
    "#to articles that where published on a date outside the scope. We assume that these were URLs where something went wrong during\n",
    "#the scraping process and thus we received an error URL instead. We first remove these URLs from the dataframe\n",
    "mask = ~ WSJ_df['Link'].str.contains('mod=error_page')\n",
    "WSJ_df = WSJ_df[mask].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510897c6",
   "metadata": {},
   "source": [
    "### Washington Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c110848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all duplicates\n",
    "WP_df = WP_df.drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c17c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "WP_duplicate_URLs = WP_df['Text'].value_counts()\n",
    "WP_duplicate_URLs = WP_duplicate_URLs[WP_duplicate_URLs > 1].reset_index()\n",
    "WP_duplicate_URLs.columns = ['Link', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a23138ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>33779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Photo</td>\n",
       "      <td>3714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0\\nComments\\n</td>\n",
       "      <td>1668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1\\nComments\\n</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2\\nComments\\n</td>\n",
       "      <td>556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3\\nComments\\n</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Opinions to start the day, in your inbox. Sign...</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021 Election: Complete coverage and analysis\\n</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4\\nComments\\n</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5\\nComments\\n</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Link  Count\n",
       "0                                                     33779\n",
       "1                                              Photo   3714\n",
       "2                                      0\\nComments\\n   1668\n",
       "3                                      1\\nComments\\n    683\n",
       "4                                      2\\nComments\\n    556\n",
       "5                                      3\\nComments\\n    454\n",
       "6  Opinions to start the day, in your inbox. Sign...    416\n",
       "7    2021 Election: Complete coverage and analysis\\n    401\n",
       "8                                      4\\nComments\\n    339\n",
       "9                                      5\\nComments\\n    297"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WP_duplicate_URLs[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27b50be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = WP_df[(WP_df[\"Text\"].str.split(\" \").str.len() == 1) & (WP_df[\"Text\"].str.contains(\"Comments\"))].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cc4880d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.washingtonpost.com/opinions/is-gmo-opposition-immoral/2018/01/01/2c9e6a54-ecc3-11e7-956e-baea358f9725_story.html'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(output[\"Link\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21b005b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>News Paper</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150038</th>\n",
       "      <td>‘Negotiating Public Services in the Congo’ is ...</td>\n",
       "      <td>0\\nComments\\n</td>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/politics/2020/0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Title           Text  \\\n",
       "150038  ‘Negotiating Public Services in the Congo’ is ...  0\\nComments\\n   \n",
       "\n",
       "             Date       News Paper  \\\n",
       "150038 2020-06-26  Washington_Post   \n",
       "\n",
       "                                                     Link  \n",
       "150038  https://www.washingtonpost.com/politics/2020/0...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WP_df[WP_df[\"Link\"] == list(output[\"Link\"])[12903]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e33de16",
   "metadata": {},
   "source": [
    "## 4.3. Unique URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7b339e",
   "metadata": {},
   "source": [
    "### Wall Street Journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff3d422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we create a two new columns with the year, month of the articles -> this way we can look at the amount of URLs\n",
    "#per year and per month\n",
    "\n",
    "WSJ_df[\"Year\"] = WSJ_df['Date'].dt.year\n",
    "WSJ_df[\"Month\"] = WSJ_df[\"Date\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d430379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Link</th>\n",
       "      <th>Date</th>\n",
       "      <th>News Paper</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EU Approves Dell’s Takeover of EMC</td>\n",
       "      <td>BRUSSELS—The European Union on Monday approve...</td>\n",
       "      <td>http://www.wsj.com/articles/eu-approves-dells-...</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Treasurys Headed for Another Monthly Gain</td>\n",
       "      <td>While Treasurys were boosted overnight by a 2...</td>\n",
       "      <td>http://www.wsj.com/articles/demand-for-austral...</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Citi Reaches Deal for American Express’s Costc...</td>\n",
       "      <td>Citigroup Inc. C 1.18% reached a deal to buy ...</td>\n",
       "      <td>http://www.wsj.com/articles/citi-reaches-deal-...</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                 EU Approves Dell’s Takeover of EMC   \n",
       "1          Treasurys Headed for Another Monthly Gain   \n",
       "2  Citi Reaches Deal for American Express’s Costc...   \n",
       "\n",
       "                                                Text  \\\n",
       "0   BRUSSELS—The European Union on Monday approve...   \n",
       "1   While Treasurys were boosted overnight by a 2...   \n",
       "2   Citigroup Inc. C 1.18% reached a deal to buy ...   \n",
       "\n",
       "                                                Link       Date  \\\n",
       "0  http://www.wsj.com/articles/eu-approves-dells-... 2016-02-29   \n",
       "1  http://www.wsj.com/articles/demand-for-austral... 2016-02-29   \n",
       "2  http://www.wsj.com/articles/citi-reaches-deal-... 2016-02-29   \n",
       "\n",
       "            News Paper  Year  Month  \n",
       "0  Wall_Street_Journal  2016      2  \n",
       "1  Wall_Street_Journal  2016      2  \n",
       "2  Wall_Street_Journal  2016      2  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WSJ_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d363bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_URLs_Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>58736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>49757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>28891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>36185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>32595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unique_URLs_Count\n",
       "Year                   \n",
       "2016              58736\n",
       "2017              49757\n",
       "2018              28891\n",
       "2019              36185\n",
       "2020              32595"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unique URLs per year -> same article on different date is unique URL\n",
    "WSJ_URLs_Year = WSJ_df.groupby([\"News Paper\",\"Year\", \"Date\"])[\"Link\"].nunique().reset_index(name='Unique_URLs_Count')\n",
    "WSJ_URLs_Year.groupby(\"Year\").sum(\"Unique_URLs_Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2346b1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News Paper</th>\n",
       "      <th>Year</th>\n",
       "      <th>Unique_URLs_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2016</td>\n",
       "      <td>58736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2017</td>\n",
       "      <td>49754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2018</td>\n",
       "      <td>28891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2019</td>\n",
       "      <td>36178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2020</td>\n",
       "      <td>32594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            News Paper  Year  Unique_URLs_Count\n",
       "0  Wall_Street_Journal  2016              58736\n",
       "1  Wall_Street_Journal  2017              49754\n",
       "2  Wall_Street_Journal  2018              28891\n",
       "3  Wall_Street_Journal  2019              36178\n",
       "4  Wall_Street_Journal  2020              32594"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unique URLs per year -> same article on different date is no unique URL\n",
    "WSJ_URLs_Year = WSJ_df.groupby([\"News Paper\",\"Year\"])[\"Link\"].nunique().reset_index(name='Unique_URLs_Count')\n",
    "WSJ_URLs_Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3edf9b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News Paper</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Unique_URLs_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>5203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>5699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>6372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>6877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>6438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>6350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>6297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>6389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>5960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>3097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>5583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>5152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>5073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>5395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>5301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>4658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>4729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>4656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>3557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>2301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>4255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>3961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>3972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>3520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>3951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>3699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>3232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>3121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>2921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>3077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>3124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>3149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>2966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>3093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>2956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>3368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>2745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>1768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>3466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>3246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>2981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>2986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>3018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>2825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>2831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>3090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>2708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>2750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             News Paper  Year  Month  Unique_URLs_Count\n",
       "0   Wall_Street_Journal  2016      2                 54\n",
       "1   Wall_Street_Journal  2016      3               5203\n",
       "2   Wall_Street_Journal  2016      4               5699\n",
       "3   Wall_Street_Journal  2016      5               6372\n",
       "4   Wall_Street_Journal  2016      6               6877\n",
       "5   Wall_Street_Journal  2016      7               6438\n",
       "6   Wall_Street_Journal  2016      8               6350\n",
       "7   Wall_Street_Journal  2016      9               6297\n",
       "8   Wall_Street_Journal  2016     10               6389\n",
       "9   Wall_Street_Journal  2016     11               5960\n",
       "10  Wall_Street_Journal  2016     12               3097\n",
       "11  Wall_Street_Journal  2017      1               5583\n",
       "12  Wall_Street_Journal  2017      2               5152\n",
       "13  Wall_Street_Journal  2017      3               5650\n",
       "14  Wall_Street_Journal  2017      4               5073\n",
       "15  Wall_Street_Journal  2017      5               5395\n",
       "16  Wall_Street_Journal  2017      6               5301\n",
       "17  Wall_Street_Journal  2017      7               4658\n",
       "18  Wall_Street_Journal  2017      8               4729\n",
       "19  Wall_Street_Journal  2017      9               4656\n",
       "20  Wall_Street_Journal  2017     10               3557\n",
       "21  Wall_Street_Journal  2017     11                  1\n",
       "22  Wall_Street_Journal  2018      5               2301\n",
       "23  Wall_Street_Journal  2018      6               4255\n",
       "24  Wall_Street_Journal  2018      7               3961\n",
       "25  Wall_Street_Journal  2018      8               3972\n",
       "26  Wall_Street_Journal  2018      9               3520\n",
       "27  Wall_Street_Journal  2018     10               3951\n",
       "28  Wall_Street_Journal  2018     11               3699\n",
       "29  Wall_Street_Journal  2018     12               3232\n",
       "30  Wall_Street_Journal  2019      1               3121\n",
       "31  Wall_Street_Journal  2019      2               2921\n",
       "32  Wall_Street_Journal  2019      3               3077\n",
       "33  Wall_Street_Journal  2019      4               3124\n",
       "34  Wall_Street_Journal  2019      5               3149\n",
       "35  Wall_Street_Journal  2019      6               2966\n",
       "36  Wall_Street_Journal  2019      7               3093\n",
       "37  Wall_Street_Journal  2019      8               2850\n",
       "38  Wall_Street_Journal  2019      9               2956\n",
       "39  Wall_Street_Journal  2019     10               3368\n",
       "40  Wall_Street_Journal  2019     11               2809\n",
       "41  Wall_Street_Journal  2019     12               2745\n",
       "42  Wall_Street_Journal  2020      1                926\n",
       "43  Wall_Street_Journal  2020      2               1768\n",
       "44  Wall_Street_Journal  2020      3               3466\n",
       "45  Wall_Street_Journal  2020      4               3246\n",
       "46  Wall_Street_Journal  2020      5               2981\n",
       "47  Wall_Street_Journal  2020      6               2986\n",
       "48  Wall_Street_Journal  2020      7               3018\n",
       "49  Wall_Street_Journal  2020      8               2825\n",
       "50  Wall_Street_Journal  2020      9               2831\n",
       "51  Wall_Street_Journal  2020     10               3090\n",
       "52  Wall_Street_Journal  2020     11               2708\n",
       "53  Wall_Street_Journal  2020     12               2750"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unique URLs per year\n",
    "WSJ_URLs_Month = WSJ_df.groupby([\"News Paper\",\"Year\", \"Month\"])[\"Link\"].nunique().reset_index(name='Unique_URLs_Count')\n",
    "WSJ_URLs_Month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2e0e8e",
   "metadata": {},
   "source": [
    "### Washington Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3c448fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we create a two new columns with the year, month of the articles -> this way we can look at the amount of URLs\n",
    "#per year and per month\n",
    "\n",
    "WP_df[\"Year\"] = WP_df['Date'].dt.year\n",
    "WP_df[\"Month\"] = WP_df[\"Date\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f20af619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>News Paper</th>\n",
       "      <th>Link</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daniel Winnik was ‘shocked’ to be traded to Ca...</td>\n",
       "      <td>Around 10:45 p.m., a Toronto number Daniel Win...</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/capitals-i...</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JSOC commander tapped to lead Special Operatio...</td>\n",
       "      <td>Lt. Gen. Raymond “Tony” Thomas has been offici...</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/checkpoint...</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chris Christie is setting himself up to be Rep...</td>\n",
       "      <td>Chris Christie is getting savaged for becoming...</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>https://www.washingtonpost.com/news/the-fix/wp...</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Daniel Winnik was ‘shocked’ to be traded to Ca...   \n",
       "1  JSOC commander tapped to lead Special Operatio...   \n",
       "2  Chris Christie is setting himself up to be Rep...   \n",
       "\n",
       "                                                Text       Date  \\\n",
       "0  Around 10:45 p.m., a Toronto number Daniel Win... 2016-02-29   \n",
       "1  Lt. Gen. Raymond “Tony” Thomas has been offici... 2016-02-29   \n",
       "2  Chris Christie is getting savaged for becoming... 2016-02-29   \n",
       "\n",
       "        News Paper                                               Link  Year  \\\n",
       "0  Washington_Post  https://www.washingtonpost.com/news/capitals-i...  2016   \n",
       "1  Washington_Post  https://www.washingtonpost.com/news/checkpoint...  2016   \n",
       "2  Washington_Post  https://www.washingtonpost.com/news/the-fix/wp...  2016   \n",
       "\n",
       "   Month  \n",
       "0      2  \n",
       "1      2  \n",
       "2      2  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WP_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "40f8e5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News Paper</th>\n",
       "      <th>Year</th>\n",
       "      <th>Unique_URLs_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>2016</td>\n",
       "      <td>49664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>2017</td>\n",
       "      <td>49800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>2018</td>\n",
       "      <td>27888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>2019</td>\n",
       "      <td>10233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Washington_Post</td>\n",
       "      <td>2020</td>\n",
       "      <td>13697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        News Paper  Year  Unique_URLs_Count\n",
       "0  Washington_Post  2016              49664\n",
       "1  Washington_Post  2017              49800\n",
       "2  Washington_Post  2018              27888\n",
       "3  Washington_Post  2019              10233\n",
       "4  Washington_Post  2020              13697"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unique URLs per year\n",
    "WP_URLs_Year = WP_df.groupby([\"News Paper\",\"Year\"])[\"Link\"].nunique().reset_index(name='Unique_URLs_Count')\n",
    "WP_URLs_Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca20ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique URLs per year\n",
    "WP_URLs_Month = WP_df.groupby([\"News Paper\",\"Year\", \"Month\"])[\"Link\"].nunique().reset_index(name='Unique_URLs_Count')\n",
    "#WP_URLs_Month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47e8194",
   "metadata": {},
   "source": [
    "## 4.4. Clean Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd72e2ed",
   "metadata": {},
   "source": [
    "### Wall Street Journal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ad049b",
   "metadata": {},
   "source": [
    "#### Remove all articles which we don't have access to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7432c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "WSJ_df = pd.read_parquet(\"WSJ_missed_articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06af56a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all articles that have the text \"NO ACCESS\" -> we didn't have access to these\n",
    "remove_NO_ACCESS = ~ WSJ_df[\"Text\"].str.contains(\"NO ACCESS\")\n",
    "WSJ_df = WSJ_df[remove_NO_ACCESS].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7f7ce5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35614"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WSJ_df.drop_duplicates().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "500fb79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title         18844\n",
       "Text          18720\n",
       "Link          31652\n",
       "Date            661\n",
       "News Paper        1\n",
       "Year              5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WSJ_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342a7c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5190b1d",
   "metadata": {},
   "source": [
    "#### Empty text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a683ed",
   "metadata": {},
   "source": [
    "Articles where we didn't collect text -> was either rescraped, or there was no text to begin with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9853a611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all blank space in the text\n",
    "remove_blank_text_df = WSJ_df\n",
    "remove_blank_text_df[\"Text\"] = remove_blank_text_df['Text'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86b8aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "WSJ_df = WSJ_df.drop(remove_blank_text_df[remove_blank_text_df[\"Text\"] == \"\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a543071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19292"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WSJ_df.drop_duplicates().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "835ef5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title         18483\n",
       "Text          18715\n",
       "Link          19129\n",
       "Date            560\n",
       "News Paper        1\n",
       "Year              5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WSJ_df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4770c8",
   "metadata": {},
   "source": [
    "#### Other text that failed to be collected or is not usefull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15603be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These articles text only contains the end of the article, but we didn't scrape the article itself\n",
    "WSJ_df = WSJ_df[~WSJ_df[\"Text\"].str.startswith('Write to')].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e78a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "WSJ_df.drop_duplicates().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc21502",
   "metadata": {},
   "outputs": [],
   "source": [
    "WSJ_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3c518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some articles had a PDF you had to download\n",
    "WSJ_df = WSJ_df[WSJ_df[\"Text\"] != \"Download PDF\"].reset_index(drop = True)\n",
    "WSJ_df = WSJ_df[WSJ_df[\"Text\"] != \"See Solution Download PDF\"].reset_index(drop = True)\n",
    "WSJ_df = WSJ_df[WSJ_df[\"Text\"] != \"Download PDF See Solution\"].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142ff060",
   "metadata": {},
   "source": [
    "### Washington Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279e963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "WSJ_df.groupby([\"News Paper\",\"Year\", \"Date\"])[\"Link\"].nunique().reset_index(name='Unique_URLs_Count').groupby(\"Year\").sum(\"Unique_URLs_Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5713ac6a",
   "metadata": {},
   "source": [
    "## 4.5. Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d01bef7",
   "metadata": {},
   "source": [
    "### Wall Street Journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "921f26ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "734d2711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title         18844\n",
       "Text          18720\n",
       "Link          31652\n",
       "Date            661\n",
       "News Paper        1\n",
       "Year              5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning first scrape\n",
    "\n",
    "WSJ_df = pd.read_parquet(\"WSJ_missed_articles\")\n",
    "#Remove all articles that have the text \"NO ACCESS\" -> we didn't have access to these\n",
    "remove_NO_ACCESS = ~ WSJ_df[\"Text\"].str.contains(\"NO ACCESS\")\n",
    "WSJ_df = WSJ_df[remove_NO_ACCESS].reset_index(drop = True)\n",
    "WSJ_df.drop_duplicates().shape[0]\n",
    "WSJ_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7a4cfce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title         18483\n",
       "Text          18715\n",
       "Link          19129\n",
       "Date            560\n",
       "News Paper        1\n",
       "Year              5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Empty text\n",
    "#Articles where we didn't collect text -> was either rescraped, or there was no text to begin with\n",
    "#Remove all blank space in the text\n",
    "remove_blank_text_df = WSJ_df\n",
    "remove_blank_text_df[\"Text\"] = remove_blank_text_df['Text'].str.strip()\n",
    "WSJ_df = WSJ_df.drop(remove_blank_text_df[remove_blank_text_df[\"Text\"] == \"\"].index).reset_index(drop=True)\n",
    "WSJ_df.drop_duplicates().shape[0]\n",
    "WSJ_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc171a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>News Paper</th>\n",
       "      <th>Link</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-06-16</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>http://www.wsj.com/articles/phil-mickelson-and...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>2016-12-29</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>http://www.wsj.com/articles/what-1917-set-in-m...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>2016-12-29</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>http://www.wsj.com/articles/ukraine-must-make-...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>2016-12-29</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>http://www.wsj.com/articles/faith-that-upholds...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>2016-12-29</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>http://www.wsj.com/articles/free-speech-and-an...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35328</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>https://www.wsj.com/articles/coronavirus-pande...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35329</th>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>https://www.wsj.com/articles/weve-hardly-gotte...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35330</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>https://www.wsj.com/articles/pep-talk-for-poli...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35331</th>\n",
       "      <td>2020-06-03</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>https://www.wsj.com/articles/he-knew-george-fl...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35332</th>\n",
       "      <td>2020-06-05</td>\n",
       "      <td>Wall_Street_Journal</td>\n",
       "      <td>https://www.wsj.com/articles/insecure-yvonne-o...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32909 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date           News Paper  \\\n",
       "0     2016-06-16  Wall_Street_Journal   \n",
       "1879  2016-12-29  Wall_Street_Journal   \n",
       "1880  2016-12-29  Wall_Street_Journal   \n",
       "1882  2016-12-29  Wall_Street_Journal   \n",
       "1883  2016-12-29  Wall_Street_Journal   \n",
       "...          ...                  ...   \n",
       "35328 2020-05-15  Wall_Street_Journal   \n",
       "35329 2020-05-29  Wall_Street_Journal   \n",
       "35330 2020-06-01  Wall_Street_Journal   \n",
       "35331 2020-06-03  Wall_Street_Journal   \n",
       "35332 2020-06-05  Wall_Street_Journal   \n",
       "\n",
       "                                                    Link  Year  \n",
       "0      http://www.wsj.com/articles/phil-mickelson-and...  2016  \n",
       "1879   http://www.wsj.com/articles/what-1917-set-in-m...  2016  \n",
       "1880   http://www.wsj.com/articles/ukraine-must-make-...  2016  \n",
       "1882   http://www.wsj.com/articles/faith-that-upholds...  2016  \n",
       "1883   http://www.wsj.com/articles/free-speech-and-an...  2016  \n",
       "...                                                  ...   ...  \n",
       "35328  https://www.wsj.com/articles/coronavirus-pande...  2020  \n",
       "35329  https://www.wsj.com/articles/weve-hardly-gotte...  2020  \n",
       "35330  https://www.wsj.com/articles/pep-talk-for-poli...  2020  \n",
       "35331  https://www.wsj.com/articles/he-knew-george-fl...  2020  \n",
       "35332  https://www.wsj.com/articles/insecure-yvonne-o...  2020  \n",
       "\n",
       "[32909 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WSJ_df\n",
    "URL = pd.read_parquet(\"WSJ_missed_URLs\")\n",
    "URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "013b284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "WSJ_df.to_parquet('WSJ_missed_articlesV2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ffea970",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(URL, WSJ_df, on=['Link', 'Date', 'News Paper', 'Year'], how=\"outer\", indicator=True).query('_merge==\"left_only\"').reset_index(drop= True).drop(['Title', 'Text', '_merge'], axis=1)\n",
    "df\n",
    "df.to_parquet('WSJ_missed_URLsV2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e85556cd639849d6c1361db0a433433fe588bb9e07514b044682fe76c87df726"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
